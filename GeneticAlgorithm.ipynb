{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-vCOLWeL6Wdm",
        "VQXO_rvZ6Wds",
        "BQNq7Nob6Wdx",
        "2WfdldjR6Wdz"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVFVcf8I6Wdd"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.models import save_model, load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        " \n",
        " \n",
        "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, Adamax, Ftrl, Nadam"
      ],
      "id": "UVFVcf8I6Wdd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SIpKcEI62eU",
        "outputId": "1501dbad-e903-410c-b262-b1c346fbbcc7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "1SIpKcEI62eU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJtSNUZt7B1o"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/drive/My Drive/LEI')"
      ],
      "id": "wJtSNUZt7B1o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncxQT73h7FPG"
      },
      "source": [
        "!unzip -q '/content/drive/My Drive/LEI/Data'"
      ],
      "id": "ncxQT73h7FPG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vCOLWeL6Wdm"
      },
      "source": [
        "#### Load Symptom Dataset"
      ],
      "id": "-vCOLWeL6Wdm"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "MwHxpIqf6Wds"
      },
      "source": [
        "data = pd.read_csv('./Data/dataset.csv', sep = ',')"
      ],
      "id": "MwHxpIqf6Wds",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQXO_rvZ6Wds"
      },
      "source": [
        "####  Load Symptom Severity "
      ],
      "id": "VQXO_rvZ6Wds"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6omEcrgs6Wdw"
      },
      "source": [
        "severity = pd.read_csv('./Data/Symptom-severity.csv')"
      ],
      "id": "6omEcrgs6Wdw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQNq7Nob6Wdx"
      },
      "source": [
        "####  Load Exam Mapping"
      ],
      "id": "BQNq7Nob6Wdx"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6a7DSax6Wdy"
      },
      "source": [
        "mapping = pd.read_csv('./Data/map.csv', sep = ';')"
      ],
      "id": "K6a7DSax6Wdy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WfdldjR6Wdz"
      },
      "source": [
        "# Pre-processing"
      ],
      "id": "2WfdldjR6Wdz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjOZnXa06Wdz"
      },
      "source": [
        "### One-hot encoding of Symptoms + Mapping the severity of the symptoms"
      ],
      "id": "sjOZnXa06Wdz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vzh0i9J76Wd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a649156-5dc8-474e-ffc9-02778e1c205e"
      },
      "source": [
        "symptomsCols = pd.unique(data.drop('Disease',1).values.flatten())\n",
        "onlySymptomsCols=[]\n",
        "for elem in (symptomsCols[symptomsCols==symptomsCols]):\n",
        "    onlySymptomsCols.append(elem.replace(' ',''))\n",
        "\n",
        "weightsFromSymptom = dict()\n",
        "\n",
        "indexing = severity.to_dict()['Symptom']\n",
        "weights = severity.to_dict()['Weight']\n",
        "for elem in indexing:\n",
        "    weightsFromSymptom[indexing[elem].replace(' ','')]=weights[elem]\n",
        "\n",
        "for elem in onlySymptomsCols:\n",
        "    if(elem.replace(' ', '') not in indexing.values()):\n",
        "        weightsFromSymptom[elem.replace(' ','')]=1\n",
        "\n",
        "symptomsCols = np.insert(onlySymptomsCols, 0, 'Disease')\n",
        "symptomsCols\n",
        "\n",
        "dataf = []\n",
        "for elem in data.values:\n",
        "    line=[]\n",
        "    line.append(elem[0])\n",
        "    elemlist=[]\n",
        "    oldline = elem.tolist()\n",
        "    for e in (oldline):\n",
        "        if(e==e):\n",
        "            elemlist.append(e.replace(' ', ''))\n",
        "    del elemlist[0]\n",
        "    for symptom in onlySymptomsCols:\n",
        "        if(elemlist.count(symptom)>0):\n",
        "            weight = weightsFromSymptom[symptom.replace(' ','')]\n",
        "            line.append(weight)\n",
        "        else:\n",
        "            line.append(0)\n",
        "    dataf.append(line)\n",
        "\n",
        "processedDataf = pd.DataFrame(data=dataf, columns=symptomsCols)\n",
        "processedDataf.to_csv(\"./Data/processed.csv\", index=False )\n",
        "processedDataf"
      ],
      "id": "Vzh0i9J76Wd2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Disease</th>\n",
              "      <th>itching</th>\n",
              "      <th>skinrash</th>\n",
              "      <th>nodalskineruptions</th>\n",
              "      <th>dischromicpatches</th>\n",
              "      <th>continuoussneezing</th>\n",
              "      <th>shivering</th>\n",
              "      <th>chills</th>\n",
              "      <th>wateringfromeyes</th>\n",
              "      <th>stomachpain</th>\n",
              "      <th>acidity</th>\n",
              "      <th>ulcersontongue</th>\n",
              "      <th>vomiting</th>\n",
              "      <th>cough</th>\n",
              "      <th>chestpain</th>\n",
              "      <th>yellowishskin</th>\n",
              "      <th>nausea</th>\n",
              "      <th>lossofappetite</th>\n",
              "      <th>abdominalpain</th>\n",
              "      <th>yellowingofeyes</th>\n",
              "      <th>burningmicturition</th>\n",
              "      <th>spottingurination</th>\n",
              "      <th>passageofgases</th>\n",
              "      <th>internalitching</th>\n",
              "      <th>indigestion</th>\n",
              "      <th>musclewasting</th>\n",
              "      <th>patchesinthroat</th>\n",
              "      <th>highfever</th>\n",
              "      <th>extramaritalcontacts</th>\n",
              "      <th>fatigue</th>\n",
              "      <th>weightloss</th>\n",
              "      <th>restlessness</th>\n",
              "      <th>lethargy</th>\n",
              "      <th>irregularsugarlevel</th>\n",
              "      <th>blurredanddistortedvision</th>\n",
              "      <th>obesity</th>\n",
              "      <th>excessivehunger</th>\n",
              "      <th>increasedappetite</th>\n",
              "      <th>polyuria</th>\n",
              "      <th>sunkeneyes</th>\n",
              "      <th>...</th>\n",
              "      <th>bloodystool</th>\n",
              "      <th>irritationinanus</th>\n",
              "      <th>cramps</th>\n",
              "      <th>bruising</th>\n",
              "      <th>swollenlegs</th>\n",
              "      <th>swollenbloodvessels</th>\n",
              "      <th>prominentveinsoncalf</th>\n",
              "      <th>weightgain</th>\n",
              "      <th>coldhandsandfeets</th>\n",
              "      <th>moodswings</th>\n",
              "      <th>puffyfaceandeyes</th>\n",
              "      <th>enlargedthyroid</th>\n",
              "      <th>brittlenails</th>\n",
              "      <th>swollenextremeties</th>\n",
              "      <th>abnormalmenstruation</th>\n",
              "      <th>muscleweakness</th>\n",
              "      <th>anxiety</th>\n",
              "      <th>slurredspeech</th>\n",
              "      <th>palpitations</th>\n",
              "      <th>dryingandtinglinglips</th>\n",
              "      <th>kneepain</th>\n",
              "      <th>hipjointpain</th>\n",
              "      <th>swellingjoints</th>\n",
              "      <th>painfulwalking</th>\n",
              "      <th>movementstiffness</th>\n",
              "      <th>spinningmovements</th>\n",
              "      <th>unsteadiness</th>\n",
              "      <th>pusfilledpimples</th>\n",
              "      <th>blackheads</th>\n",
              "      <th>scurring</th>\n",
              "      <th>bladderdiscomfort</th>\n",
              "      <th>foulsmellofurine</th>\n",
              "      <th>continuousfeelofurine</th>\n",
              "      <th>skinpeeling</th>\n",
              "      <th>silverlikedusting</th>\n",
              "      <th>smalldentsinnails</th>\n",
              "      <th>inflammatorynails</th>\n",
              "      <th>blister</th>\n",
              "      <th>redsorearoundnose</th>\n",
              "      <th>yellowcrustooze</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fungal infection</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fungal infection</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fungal infection</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Fungal infection</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Fungal infection</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4915</th>\n",
              "      <td>(vertigo) Paroymsal  Positional Vertigo</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4916</th>\n",
              "      <td>Acne</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4917</th>\n",
              "      <td>Urinary tract infection</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4918</th>\n",
              "      <td>Psoriasis</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4919</th>\n",
              "      <td>Impetigo</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4920 rows Ã— 132 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      Disease  ...  yellowcrustooze\n",
              "0                            Fungal infection  ...                0\n",
              "1                            Fungal infection  ...                0\n",
              "2                            Fungal infection  ...                0\n",
              "3                            Fungal infection  ...                0\n",
              "4                            Fungal infection  ...                0\n",
              "...                                       ...  ...              ...\n",
              "4915  (vertigo) Paroymsal  Positional Vertigo  ...                0\n",
              "4916                                     Acne  ...                0\n",
              "4917                  Urinary tract infection  ...                0\n",
              "4918                                Psoriasis  ...                0\n",
              "4919                                 Impetigo  ...                1\n",
              "\n",
              "[4920 rows x 132 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmx8dA2r6Wd3"
      },
      "source": [
        "### One-hot encoding of exams and diseases"
      ],
      "id": "Kmx8dA2r6Wd3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "EgI20Uw16Wd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80187e98-0057-41b1-9b6b-78bd33366b9a"
      },
      "source": [
        "mapeamentoCols = pd.unique(mapping.drop('Disease',1).values.flatten())\n",
        "\n",
        "onlyTestCols=[]\n",
        "onlyTestCols = mapeamentoCols[mapeamentoCols==mapeamentoCols]\n",
        "dfCols = np.insert(onlyTestCols, 0, 'Disease')\n",
        "\n",
        "dfValues = []\n",
        "for elem in mapping.values:\n",
        "    line=[]\n",
        "    line.append(elem[0])\n",
        "    elemlist= elem.tolist()\n",
        "    del elemlist[0]\n",
        "    for test in onlyTestCols:\n",
        "        if(elemlist.count(test)>0):\n",
        "            line.append(1)\n",
        "        else:\n",
        "            line.append(0)\n",
        "    dfValues.append(line)\n",
        "\n",
        "testsDf = pd.DataFrame(data=dfValues, columns=dfCols)\n",
        "testsDf.to_csv(\"./Data/mapProcessed.csv\", index=False)\n",
        "\n",
        "testsDf"
      ],
      "id": "EgI20Uw16Wd4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Disease</th>\n",
              "      <th>Blood Tests</th>\n",
              "      <th>Skin biopsy</th>\n",
              "      <th>Patch test</th>\n",
              "      <th>Complete blood count (CBC)</th>\n",
              "      <th>Polymerase chain reaction (PCR)</th>\n",
              "      <th>Skin Prick Test (SPT)</th>\n",
              "      <th>Intradermal Skin Test</th>\n",
              "      <th>Physical Examination</th>\n",
              "      <th>TSH test</th>\n",
              "      <th>T4 test</th>\n",
              "      <th>Thyroid scan</th>\n",
              "      <th>Thyroid ultrasound</th>\n",
              "      <th>Esophagram</th>\n",
              "      <th>Esophageal manometry</th>\n",
              "      <th>pH monitoring</th>\n",
              "      <th>Endoscopy</th>\n",
              "      <th>Biopsy of upper disgestive system</th>\n",
              "      <th>X-ray of upper digestive system</th>\n",
              "      <th>Serum bilirubin test</th>\n",
              "      <th>Serum albumin test</th>\n",
              "      <th>Serum alkaline phosphatase test</th>\n",
              "      <th>Serum aminotransferases (transaminases)</th>\n",
              "      <th>Prothrombin time (PTT) test</th>\n",
              "      <th>Alanine transaminase (ALT) test</th>\n",
              "      <th>Liver Ultrasound</th>\n",
              "      <th>Liver Biopsy</th>\n",
              "      <th>MRI Scan</th>\n",
              "      <th>CT Scan</th>\n",
              "      <th>X-ray</th>\n",
              "      <th>Electronystagmography (ENG)</th>\n",
              "      <th>Videonystagmography (VNG)</th>\n",
              "      <th>Fasting plasma glucose (FPG) test</th>\n",
              "      <th>Hemoglobin A1C test</th>\n",
              "      <th>Random plasma glucose (RPG) test</th>\n",
              "      <th>Blood Test</th>\n",
              "      <th>Electrocardiogram (ECG)</th>\n",
              "      <th>Echocardiogram</th>\n",
              "      <th>Ambulatory monitoring</th>\n",
              "      <th>Urine analysis</th>\n",
              "      <th>...</th>\n",
              "      <th>Western Blot</th>\n",
              "      <th>Brain MRI Scan</th>\n",
              "      <th>Carotid Ultrasound</th>\n",
              "      <th>Cerebral angiogram</th>\n",
              "      <th>Stool tests</th>\n",
              "      <th>Bone marrow test</th>\n",
              "      <th>Tissue culture</th>\n",
              "      <th>KOH prep</th>\n",
              "      <th>Fungal culture</th>\n",
              "      <th>Antigent and Antibody testing</th>\n",
              "      <th>Sputum test</th>\n",
              "      <th>Susceptability testing</th>\n",
              "      <th>Gram Strain</th>\n",
              "      <th>Sinus X-ray</th>\n",
              "      <th>Electroencephalogram</th>\n",
              "      <th>Eye Exam</th>\n",
              "      <th>Spirometry</th>\n",
              "      <th>Exhaled nitric oxide test</th>\n",
              "      <th>Peak flow meter test</th>\n",
              "      <th>Liver CT Scan</th>\n",
              "      <th>Liver MRI Scan</th>\n",
              "      <th>Biopsy</th>\n",
              "      <th>Ultrasound</th>\n",
              "      <th>Dengue NS1 antigen test</th>\n",
              "      <th>Serological tests</th>\n",
              "      <th>IgG antibody testing</th>\n",
              "      <th>Nucleic acid amplification tests (NAATs)</th>\n",
              "      <th>Coronary catheterization (angiogram)</th>\n",
              "      <th>Cardiac CT</th>\n",
              "      <th>Cardiac MRI</th>\n",
              "      <th>Pleural fluid culture</th>\n",
              "      <th>Pulse oximetry</th>\n",
              "      <th>Anti-cyclic citrullinated peptide (anti-CCP)</th>\n",
              "      <th>Erythrocyte sedimentation rate (ESR)</th>\n",
              "      <th>C-reactive protein (CRP)</th>\n",
              "      <th>Antinuclear antibody (ANA)</th>\n",
              "      <th>HLA-B27</th>\n",
              "      <th>Stool culture</th>\n",
              "      <th>Antigen Tests</th>\n",
              "      <th>Mantoux tuberculin skin test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Drug Reaction</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Malaria</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Allergy</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hypothyroidism</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Psoriasis</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>GERD</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Chronic cholestasis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>hepatitis A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Osteoarthristis</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(vertigo) Paroymsal  Positional Vertigo</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Hypoglycemia</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Acne</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Diabetes</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Impetigo</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Hypertension</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Peptic ulcer diseae</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Dimorphic hemmorhoids(piles)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Common Cold</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Chicken pox</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Cervical spondylosis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Hyperthyroidism</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Urinary tract infection</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Varicose veins</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>AIDS</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Paralysis (brain hemorrhage)</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Typhoid</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Hepatitis B</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Fungal infection</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Hepatitis C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Migraine</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Bronchial Asthma</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Alcoholic hepatitis</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Jaundice</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Hepatitis E</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Dengue</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Hepatitis D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Heart attack</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Pneumonia</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Arthritis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Gastroenteritis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Tuberculosis</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41 rows Ã— 103 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Disease  ...  Mantoux tuberculin skin test\n",
              "0                             Drug Reaction  ...                             0\n",
              "1                                   Malaria  ...                             0\n",
              "2                                   Allergy  ...                             0\n",
              "3                            Hypothyroidism  ...                             0\n",
              "4                                 Psoriasis  ...                             0\n",
              "5                                      GERD  ...                             0\n",
              "6                       Chronic cholestasis  ...                             0\n",
              "7                               hepatitis A  ...                             0\n",
              "8                           Osteoarthristis  ...                             0\n",
              "9   (vertigo) Paroymsal  Positional Vertigo  ...                             0\n",
              "10                             Hypoglycemia  ...                             0\n",
              "11                                     Acne  ...                             0\n",
              "12                                 Diabetes  ...                             0\n",
              "13                                 Impetigo  ...                             0\n",
              "14                             Hypertension  ...                             0\n",
              "15                      Peptic ulcer diseae  ...                             0\n",
              "16             Dimorphic hemmorhoids(piles)  ...                             0\n",
              "17                              Common Cold  ...                             0\n",
              "18                              Chicken pox  ...                             0\n",
              "19                     Cervical spondylosis  ...                             0\n",
              "20                          Hyperthyroidism  ...                             0\n",
              "21                  Urinary tract infection  ...                             0\n",
              "22                           Varicose veins  ...                             0\n",
              "23                                     AIDS  ...                             0\n",
              "24             Paralysis (brain hemorrhage)  ...                             0\n",
              "25                                  Typhoid  ...                             0\n",
              "26                              Hepatitis B  ...                             0\n",
              "27                         Fungal infection  ...                             0\n",
              "28                              Hepatitis C  ...                             0\n",
              "29                                 Migraine  ...                             0\n",
              "30                         Bronchial Asthma  ...                             0\n",
              "31                      Alcoholic hepatitis  ...                             0\n",
              "32                                 Jaundice  ...                             0\n",
              "33                              Hepatitis E  ...                             0\n",
              "34                                   Dengue  ...                             0\n",
              "35                              Hepatitis D  ...                             0\n",
              "36                             Heart attack  ...                             0\n",
              "37                                Pneumonia  ...                             0\n",
              "38                                Arthritis  ...                             0\n",
              "39                          Gastroenteritis  ...                             0\n",
              "40                             Tuberculosis  ...                             1\n",
              "\n",
              "[41 rows x 103 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPqm3h3-6Wd7"
      },
      "source": [
        "## Dataframe with all Symptoms + Exams associated with a Disease"
      ],
      "id": "hPqm3h3-6Wd7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZZXumWe6Wd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81c083e6-fb49-4c3a-fd43-d1a70bcc266d"
      },
      "source": [
        "finalDfCols= np.concatenate([onlyTestCols,onlySymptomsCols])\n",
        "\n",
        "dfValues = []\n",
        "for elem in processedDataf.values:\n",
        "    for testLine in testsDf.values:\n",
        "        if(testLine[0]==elem[0]):\n",
        "            line= np.concatenate([testLine[1:], elem[1:]])\n",
        "            dfValues.append(line)\n",
        "\n",
        "finalDf = pd.DataFrame(data=dfValues, columns=finalDfCols)\n",
        "finalDf.to_csv(\"./Data/final.csv\", index=False)\n",
        "finalDf"
      ],
      "id": "SZZXumWe6Wd7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Blood Tests</th>\n",
              "      <th>Skin biopsy</th>\n",
              "      <th>Patch test</th>\n",
              "      <th>Complete blood count (CBC)</th>\n",
              "      <th>Polymerase chain reaction (PCR)</th>\n",
              "      <th>Skin Prick Test (SPT)</th>\n",
              "      <th>Intradermal Skin Test</th>\n",
              "      <th>Physical Examination</th>\n",
              "      <th>TSH test</th>\n",
              "      <th>T4 test</th>\n",
              "      <th>Thyroid scan</th>\n",
              "      <th>Thyroid ultrasound</th>\n",
              "      <th>Esophagram</th>\n",
              "      <th>Esophageal manometry</th>\n",
              "      <th>pH monitoring</th>\n",
              "      <th>Endoscopy</th>\n",
              "      <th>Biopsy of upper disgestive system</th>\n",
              "      <th>X-ray of upper digestive system</th>\n",
              "      <th>Serum bilirubin test</th>\n",
              "      <th>Serum albumin test</th>\n",
              "      <th>Serum alkaline phosphatase test</th>\n",
              "      <th>Serum aminotransferases (transaminases)</th>\n",
              "      <th>Prothrombin time (PTT) test</th>\n",
              "      <th>Alanine transaminase (ALT) test</th>\n",
              "      <th>Liver Ultrasound</th>\n",
              "      <th>Liver Biopsy</th>\n",
              "      <th>MRI Scan</th>\n",
              "      <th>CT Scan</th>\n",
              "      <th>X-ray</th>\n",
              "      <th>Electronystagmography (ENG)</th>\n",
              "      <th>Videonystagmography (VNG)</th>\n",
              "      <th>Fasting plasma glucose (FPG) test</th>\n",
              "      <th>Hemoglobin A1C test</th>\n",
              "      <th>Random plasma glucose (RPG) test</th>\n",
              "      <th>Blood Test</th>\n",
              "      <th>Electrocardiogram (ECG)</th>\n",
              "      <th>Echocardiogram</th>\n",
              "      <th>Ambulatory monitoring</th>\n",
              "      <th>Urine analysis</th>\n",
              "      <th>Upper gastrointestinal endoscopy</th>\n",
              "      <th>...</th>\n",
              "      <th>bloodystool</th>\n",
              "      <th>irritationinanus</th>\n",
              "      <th>cramps</th>\n",
              "      <th>bruising</th>\n",
              "      <th>swollenlegs</th>\n",
              "      <th>swollenbloodvessels</th>\n",
              "      <th>prominentveinsoncalf</th>\n",
              "      <th>weightgain</th>\n",
              "      <th>coldhandsandfeets</th>\n",
              "      <th>moodswings</th>\n",
              "      <th>puffyfaceandeyes</th>\n",
              "      <th>enlargedthyroid</th>\n",
              "      <th>brittlenails</th>\n",
              "      <th>swollenextremeties</th>\n",
              "      <th>abnormalmenstruation</th>\n",
              "      <th>muscleweakness</th>\n",
              "      <th>anxiety</th>\n",
              "      <th>slurredspeech</th>\n",
              "      <th>palpitations</th>\n",
              "      <th>dryingandtinglinglips</th>\n",
              "      <th>kneepain</th>\n",
              "      <th>hipjointpain</th>\n",
              "      <th>swellingjoints</th>\n",
              "      <th>painfulwalking</th>\n",
              "      <th>movementstiffness</th>\n",
              "      <th>spinningmovements</th>\n",
              "      <th>unsteadiness</th>\n",
              "      <th>pusfilledpimples</th>\n",
              "      <th>blackheads</th>\n",
              "      <th>scurring</th>\n",
              "      <th>bladderdiscomfort</th>\n",
              "      <th>foulsmellofurine</th>\n",
              "      <th>continuousfeelofurine</th>\n",
              "      <th>skinpeeling</th>\n",
              "      <th>silverlikedusting</th>\n",
              "      <th>smalldentsinnails</th>\n",
              "      <th>inflammatorynails</th>\n",
              "      <th>blister</th>\n",
              "      <th>redsorearoundnose</th>\n",
              "      <th>yellowcrustooze</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4675</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4676</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4677</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4678</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4679</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4680 rows Ã— 233 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Blood Tests  Skin biopsy  ...  redsorearoundnose  yellowcrustooze\n",
              "0               1            0  ...                  0                0\n",
              "1               1            0  ...                  0                0\n",
              "2               1            0  ...                  0                0\n",
              "3               1            0  ...                  0                0\n",
              "4               1            0  ...                  0                0\n",
              "...           ...          ...  ...                ...              ...\n",
              "4675            0            0  ...                  0                0\n",
              "4676            1            0  ...                  0                0\n",
              "4677            1            0  ...                  0                0\n",
              "4678            0            1  ...                  0                0\n",
              "4679            0            0  ...                  1                1\n",
              "\n",
              "[4680 rows x 233 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "vdpjPpQW6Wd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e359b3a6-c724-4598-95f5-4cbb294001d5"
      },
      "source": [
        "print(onlyTestCols)\n",
        "print(len(onlyTestCols))\n",
        "print(len(onlySymptomsCols))"
      ],
      "id": "vdpjPpQW6Wd8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Blood Tests' 'Skin biopsy' 'Patch test' 'Complete blood count (CBC)'\n",
            " 'Polymerase chain reaction (PCR)' 'Skin Prick Test (SPT)'\n",
            " 'Intradermal Skin Test' 'Physical Examination' 'TSH test' 'T4 test'\n",
            " 'Thyroid scan' 'Thyroid ultrasound' 'Esophagram' 'Esophageal manometry'\n",
            " 'pH monitoring' 'Endoscopy' 'Biopsy of upper disgestive system'\n",
            " 'X-ray of upper digestive system' 'Serum bilirubin test'\n",
            " 'Serum albumin test' 'Serum alkaline phosphatase test'\n",
            " 'Serum aminotransferases (transaminases)' 'Prothrombin time (PTT) test'\n",
            " 'Alanine transaminase (ALT) test' 'Liver Ultrasound' 'Liver Biopsy'\n",
            " 'MRI Scan' 'CT Scan' 'X-ray' 'Electronystagmography (ENG)'\n",
            " 'Videonystagmography (VNG)' 'Fasting plasma glucose (FPG) test'\n",
            " 'Hemoglobin A1C test' 'Random plasma glucose (RPG) test' 'Blood Test'\n",
            " 'Electrocardiogram (ECG)' 'Echocardiogram' 'Ambulatory monitoring'\n",
            " 'Urine analysis' 'Upper gastrointestinal endoscopy'\n",
            " 'Upper gastrointestinal biopsy' 'CT scan' 'Helicobacter pylori tests'\n",
            " 'Anoscopy' 'Rigid proctosigmoidoscopy' 'Colonoscopy'\n",
            " 'Flexible sigmoidoscopy' 'Barium X-ray' 'Throat Culture' 'Chest X-ray'\n",
            " 'Neck X-ray' 'Myelophagy' 'Electromyography (EMG)'\n",
            " 'Radioiodine uptake test' 'Thyroid antibody tests' 'Urine Culture'\n",
            " 'Susceptibility testing' 'Venous duplex scanning'\n",
            " 'Trendelenburg test (tourniquet test)' 'ELISA Test' 'Saliva Test'\n",
            " 'Viral Load Test' 'Western Blot' 'Brain MRI Scan' 'Carotid Ultrasound'\n",
            " 'Cerebral angiogram' 'Stool tests' 'Bone marrow test' 'Tissue culture'\n",
            " 'KOH prep' 'Fungal culture' 'Antigent and Antibody testing' 'Sputum test'\n",
            " 'Susceptability testing' 'Gram Strain' 'Sinus X-ray'\n",
            " 'Electroencephalogram' 'Eye Exam' 'Spirometry'\n",
            " 'Exhaled nitric oxide test' 'Peak flow meter test' 'Liver CT Scan'\n",
            " 'Liver MRI Scan' 'Biopsy' 'Ultrasound' 'Dengue NS1 antigen test'\n",
            " 'Serological tests' 'IgG antibody testing'\n",
            " 'Nucleic acid amplification tests (NAATs)'\n",
            " 'Coronary catheterization (angiogram)' 'Cardiac CT' 'Cardiac MRI'\n",
            " 'Pleural fluid culture' 'Pulse oximetry'\n",
            " 'Anti-cyclic citrullinated peptide (anti-CCP)'\n",
            " 'Erythrocyte sedimentation rate (ESR)' 'C-reactive protein (CRP)'\n",
            " 'Antinuclear antibody (ANA)' 'HLA-B27' 'Stool culture' 'Antigen Tests'\n",
            " 'Mantoux tuberculin skin test']\n",
            "102\n",
            "131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "hJvgwmRH6Wd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b1285b4-06e1-4a3f-d3b6-9c4db62060fb"
      },
      "source": [
        "print('Number of Symptoms:', len(severity['Symptom']))\n",
        "\n",
        "for elem in (severity['Symptom'].tolist()) :\n",
        "        if(elem  not in onlySymptomsCols  ):\n",
        "            print(elem)"
      ],
      "id": "hJvgwmRH6Wd9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Symptoms: 131\n",
            "skin_rash\n",
            "nodal_skin_eruptions\n",
            "continuous_sneezing\n",
            "joint_pain\n",
            "stomach_pain\n",
            "ulcers_on_tongue\n",
            "muscle_wasting\n",
            "burning_micturition\n",
            "spotting_urination\n",
            "weight_gain\n",
            "cold_hands_and_feets\n",
            "mood_swings\n",
            "weight_loss\n",
            "patches_in_throat\n",
            "irregular_sugar_level\n",
            "high_fever\n",
            "sunken_eyes\n",
            "yellowish_skin\n",
            "dark_urine\n",
            "loss_of_appetite\n",
            "pain_behind_the_eyes\n",
            "back_pain\n",
            "abdominal_pain\n",
            "mild_fever\n",
            "yellow_urine\n",
            "yellowing_of_eyes\n",
            "acute_liver_failure\n",
            "fluid_overload\n",
            "swelling_of_stomach\n",
            "swelled_lymph_nodes\n",
            "blurred_and_distorted_vision\n",
            "throat_irritation\n",
            "redness_of_eyes\n",
            "sinus_pressure\n",
            "runny_nose\n",
            "chest_pain\n",
            "weakness_in_limbs\n",
            "fast_heart_rate\n",
            "pain_during_bowel_movements\n",
            "pain_in_anal_region\n",
            "bloody_stool\n",
            "irritation_in_anus\n",
            "neck_pain\n",
            "swollen_legs\n",
            "swollen_blood_vessels\n",
            "puffy_face_and_eyes\n",
            "enlarged_thyroid\n",
            "brittle_nails\n",
            "swollen_extremeties\n",
            "excessive_hunger\n",
            "extra_marital_contacts\n",
            "drying_and_tingling_lips\n",
            "slurred_speech\n",
            "knee_pain\n",
            "hip_joint_pain\n",
            "muscle_weakness\n",
            "stiff_neck\n",
            "swelling_joints\n",
            "movement_stiffness\n",
            "spinning_movements\n",
            "loss_of_balance\n",
            "weakness_of_one_body_side\n",
            "loss_of_smell\n",
            "bladder_discomfort\n",
            "foul_smell_ofurine\n",
            "continuous_feel_of_urine\n",
            "passage_of_gases\n",
            "internal_itching\n",
            "toxic_look_(typhos)\n",
            "muscle_pain\n",
            "altered_sensorium\n",
            "red_spots_over_body\n",
            "belly_pain\n",
            "abnormal_menstruation\n",
            "dischromic_patches\n",
            "watering_from_eyes\n",
            "increased_appetite\n",
            "family_history\n",
            "mucoid_sputum\n",
            "rusty_sputum\n",
            "lack_of_concentration\n",
            "visual_disturbances\n",
            "receiving_blood_transfusion\n",
            "receiving_unsterile_injections\n",
            "stomach_bleeding\n",
            "distention_of_abdomen\n",
            "history_of_alcohol_consumption\n",
            "blood_in_sputum\n",
            "prominent_veins_on_calf\n",
            "painful_walking\n",
            "pus_filled_pimples\n",
            "skin_peeling\n",
            "silver_like_dusting\n",
            "small_dents_in_nails\n",
            "inflammatory_nails\n",
            "red_sore_around_nose\n",
            "yellow_crust_ooze\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xvByU5l6Wd9"
      },
      "source": [
        "### Split the data"
      ],
      "id": "9xvByU5l6Wd9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfFWLi1h6Wd-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "480054f0-390e-4109-9c37-3726216b132e"
      },
      "source": [
        "symptomCount = len(onlySymptomsCols)\n",
        "testCount = len(onlyTestCols)\n",
        "\n",
        "#print(testCount)\n",
        "#print(symptomCount)\n",
        "\n",
        "[train,test] = train_test_split(finalDf,random_state=420)\n",
        "trainA = np.array(train)\n",
        "trainAX = trainA[:,testCount:]\n",
        "trainAY = trainA[:,:testCount]\n",
        "\n",
        "trainX=train.iloc[:,testCount:]\n",
        "trainY=train.iloc[:,:testCount]\n",
        "print(trainY[0:5])\n",
        "\n",
        "testX=test.iloc[:,testCount:]\n",
        "testY=test.iloc[:,:testCount]\n"
      ],
      "id": "dfFWLi1h6Wd-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Blood Tests  Skin biopsy  ...  Antigen Tests  Mantoux tuberculin skin test\n",
            "1870            1            0  ...              0                             0\n",
            "373             0            1  ...              0                             0\n",
            "781             1            0  ...              0                             0\n",
            "825             1            1  ...              0                             0\n",
            "1667            0            0  ...              0                             0\n",
            "\n",
            "[5 rows x 102 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H60e5rk6WeH"
      },
      "source": [
        "# Genetic Algorithm"
      ],
      "id": "9H60e5rk6WeH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB2MGOPG6Wd-"
      },
      "source": [
        "def createModel(cl, aFunc, optFunc, lossFunc, lr, drop):\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    baseNoNeurs=2048+1024\n",
        "    \n",
        "    # first layer\n",
        "    model.add(Dense(baseNoNeurs, input_shape=(symptomCount,)))\n",
        "    model.add(Activation(aFunc))   \n",
        "\n",
        "    # middle layers  \n",
        "    mult = np.random.choice([0.5, 2])\n",
        "    \n",
        "    for i in range(int(cl)):\n",
        "        model.add(Dense(baseNoNeurs*mult))\n",
        "        model.add(Activation(aFunc))\n",
        "        model.add(Dropout(drop))\n",
        "\n",
        "    # output layer\n",
        "    model.add(Dense(testCount))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    if(optFunc == 'SGD'): optFunc = SGD(learning_rate=lr)\n",
        "    elif(optFunc == 'Adam'): optFunc = Adam(learning_rate=lr)\n",
        "    elif(optFunc == 'Adagrad'): optFunc = Adagrad(learning_rate=lr)\n",
        "    elif(optFunc == 'RMSprop'): optFunc = RMSprop(learning_rate=lr)\n",
        "    elif(optFunc == 'Adadelta'): optFunc = Adadelta(learning_rate=lr)\n",
        "    elif(optFunc == 'Adamax'): optFunc = Adamax(learning_rate=lr)\n",
        "    elif(optFunc == 'Ftrl'): optFunc = Ftrl(learning_rate=lr)\n",
        "    elif(optFunc == 'Nadam'): optFunc = Nadam(learning_rate=lr)\n",
        "\n",
        "\n",
        "    #compile model\n",
        "    model.compile(optFunc, loss=lossFunc, metrics=['accuracy', tf.metrics.CategoricalAccuracy()])\n",
        "    \n",
        "    #model.summary()\n",
        "\n",
        "    return model\n"
      ],
      "id": "CB2MGOPG6Wd-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJPekeJq6WeH"
      },
      "source": [
        "# Create the initial population\n",
        "def createNewPopulation():\n",
        "    population=[]\n",
        "    \n",
        "    for i in range(10):\n",
        "        c=[]\n",
        "        # number of middle  layers\n",
        "        c.append(np.random.randint(low=1, high=6))\n",
        "        # activation function\n",
        "        c.append(np.random.randint(low=0, high=8))\n",
        "        # optimizer\n",
        "        c.append(np.random.randint(low=0, high=8))\n",
        "        # loss function\n",
        "        c.append(np.random.randint(low=0, high=2))\n",
        "        # learning rate \n",
        "        c.append(np.random.choice([0.00001, 0.0001, 0.001]))\n",
        "        # dropout\n",
        "        c.append(np.random.choice([0.15, 0.25, 0.3, 0.5]))\n",
        "        \n",
        "        population.append(c)\n",
        "        \n",
        "    return np.array(population)\n",
        "\n",
        "# Update the models parameters\n",
        "def updateModelParameters(params):\n",
        "    if((params[1]) == 0): aFunc = 'relu'\n",
        "    if((params[1]) == 1): aFunc = 'selu'\n",
        "    if((params[1]) == 2): aFunc = 'softmax'\n",
        "    if((params[1]) == 3): aFunc = 'sigmoid'\n",
        "    if((params[1]) == 4): aFunc = 'softplus'\n",
        "    if((params[1]) == 5): aFunc = 'softsign'\n",
        "    if((params[1]) == 6): aFunc = 'tanh'\n",
        "    if((params[1]) == 7): aFunc = 'elu'\n",
        "\n",
        "    if((params[2]) == 0): optFunc = 'SGD'\n",
        "    if((params[2]) == 1): optFunc = 'Adam'\n",
        "    if((params[2]) == 2): optFunc = 'Adagrad'\n",
        "    if((params[2]) == 3): optFunc = 'RMSprop'\n",
        "    if((params[2]) == 4): optFunc = 'Adadelta'\n",
        "    if((params[2]) == 5): optFunc = 'Adamax'\n",
        "    if((params[2]) == 6): optFunc = 'Ftrl'\n",
        "    if((params[2]) == 7): optFunc = 'Nadam'\n",
        "        \n",
        "    if((params[3]) == 0): loss = 'categorical_hinge'\n",
        "    if((params[3]) == 1): loss = 'categorical_crossentropy'\n",
        "\n",
        "    model = createModel(params[0], aFunc,  optFunc, loss, params[4], params[5])\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Selection of the best individuals to create the next generation\n",
        "def selectMatingPool(p, fitness, pFitness, numParents):\n",
        "    pFitness = []\n",
        "    parents = np.empty((numParents, p.shape[1]))\n",
        "    for parent_num in range(numParents):\n",
        "        pFitness.append(np.max(fitness))\n",
        "        max_fitness_idx = np.where(fitness == np.max(fitness))\n",
        "        max_fitness_idx = max_fitness_idx[0][0]\n",
        "        parents[parent_num, :] = p[max_fitness_idx, :]\n",
        "        fitness[max_fitness_idx] = -99\n",
        "    return parents, pFitness\n",
        "\n",
        "# The new offspring will have its first half of its genes taken from the first parent \n",
        "# and its second half of its genes taken from the second parent\n",
        "def crossover(parents, offspringSize):\n",
        "    offspring = np.empty(offspringSize)\n",
        "    crossover_point = np.uint8(offspringSize[1]/2)\n",
        "\n",
        "    for k in range(offspringSize[0]):\n",
        "        parent1_idx = k%parents.shape[0]\n",
        "        parent2_idx = (k+1)%parents.shape[0]\n",
        "        offspring[k, 0:crossover_point] = parents[parent1_idx, 0:crossover_point]\n",
        "        offspring[k, crossover_point:] = parents[parent2_idx, crossover_point:]\n",
        "    return offspring\n",
        "\n",
        "\n",
        "# Mutation changes a single gene in each offspring randomly\n",
        "def mutation(offspringCrossover):\n",
        "    for idx in range(offspringCrossover.shape[0]):\n",
        "        \n",
        "        # select which gene to mutate\n",
        "        select_gene = np.random.randint(low=0, high=6)\n",
        "        \n",
        "        # mutate number of middle layers\n",
        "        if(select_gene == 0): \n",
        "            random_value = np.random.randint(low=1, high=6)\n",
        "            offspringCrossover[idx,0] = random_value\n",
        "       # activation function mutation\n",
        "        if(select_gene == 1):\n",
        "            random_value = np.random.randint(low=0, high=8)\n",
        "            offspringCrossover[idx,1] = random_value\n",
        "       # optimization function mutation   \n",
        "        if(select_gene == 2):\n",
        "            random_value = np.random.randint(low=0, high=8)\n",
        "            offspringCrossover[idx,2] = random_value\n",
        "       # loss function mutation\n",
        "        if(select_gene == 3):\n",
        "            random_value = np.random.randint(low=0, high=2)\n",
        "            offspringCrossover[idx,3] = random_value\n",
        "       # learning rate mutation\n",
        "        if(select_gene == 4):\n",
        "            random_value = np.random.choice([0.00001, 0.0001, 0.001])\n",
        "            offspringCrossover[idx,4] = random_value\n",
        "       # dropout mutation\n",
        "        if(select_gene == 5):\n",
        "            random_value = np.random.choice([0.15, 0.25, 0.3, 0.5])\n",
        "            offspringCrossover[idx,5] = random_value\n",
        "                 \n",
        "    return offspringCrossover\n",
        "\n",
        "def printChromossomeStructure(c):   \n",
        "    if((c[1]) == 0): aFunc = 'relu'\n",
        "    if((c[1]) == 1): aFunc = 'selu'\n",
        "    if((c[1]) == 2): aFunc = 'softmax'\n",
        "    if((c[1]) == 3): aFunc = 'sigmoid'\n",
        "    if((c[1]) == 4): aFunc = 'softplus'\n",
        "    if((c[1]) == 5): aFunc = 'softsign'\n",
        "    if((c[1]) == 6): aFunc = 'tanh'\n",
        "    if((c[1]) == 7): aFunc = 'elu'\n",
        "\n",
        "    if((c[2]) == 0): optFunc = 'SGD'\n",
        "    if((c[2]) == 1): optFunc = 'Adam'\n",
        "    if((c[2]) == 2): optFunc = 'Adagrad'\n",
        "    if((c[2]) == 3): optFunc = 'RMSprop'\n",
        "    if((c[2]) == 4): optFunc = 'Adadelta'\n",
        "    if((c[2]) == 5): optFunc = 'Adamax'\n",
        "    if((c[2]) == 6): optFunc = 'Ftrl'\n",
        "    if((c[2]) == 7): optFunc = 'Nadam'\n",
        "\n",
        "    if((c[3]) == 0): loss = 'categorical_hinge'\n",
        "    if((c[3]) == 1): loss = 'categorical_crossentropy'\n",
        "\n",
        "    print(\"Middle layers: {} |\".format(int(c[0])), \"Activation: {} |\".format(aFunc),          \n",
        "          \"Optimization: {} |\".format(optFunc), \"Loss: {} |\".format(loss), \n",
        "          \"LR: {} |\".format(c[4]), \"Dropout: {} |\".format(float(c[5]), '\\t'))\n",
        "    \n",
        "def printChromossomes(cr):\n",
        "    for c in cr:\n",
        "      printChromossomeStructure(c)\n"
      ],
      "id": "LJPekeJq6WeH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9zZtcOPcjjt"
      },
      "source": [
        "def realAccuracies(model, predictions):\n",
        "    thresh =(predictions.max()+ predictions.min())/2\n",
        "    predictions[predictions>thresh]=1\n",
        "    predictions[predictions<=thresh]=0\n",
        "    \n",
        "    correctByLine=[]\n",
        "\n",
        "    for i in range(len(testY)):\n",
        "        matches = predictions[i]==testY.to_numpy()[i]\n",
        "        correctByLine.append(len(matches[matches==True])/len(matches))\n",
        "    return(len(np.nonzero([x for x in correctByLine if x!=1])[0]))"
      ],
      "id": "V9zZtcOPcjjt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMrICzst6WeJ"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', patience=50)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
        "\n",
        "\n",
        "def chromosomeEvaluation(c):\n",
        "    scores = []\n",
        "    \n",
        "    model = updateModelParameters(c)\n",
        "\n",
        "    history = model.fit(trainX, trainY, epochs=200, batch_size=10, verbose=1, validation_data=(testX,testY), callbacks=[es, mc])\n",
        "\n",
        "    score = model.evaluate(testX, testY, verbose=1)\n",
        "\n",
        "    predictions = model.predict(testX.to_numpy())\n",
        "    realAcc = realAccuracies(model, predictions)\n",
        "\n",
        "    return score[1], realAcc"
      ],
      "id": "WMrICzst6WeJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnjc25UM6WeN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f68d4e3-469f-411e-9bf3-fc76ce3bb2d1"
      },
      "source": [
        "population = createNewPopulation()\n",
        "\n",
        "print(\"Initial population:\")\n",
        "printChromossomes(population)\n",
        "\n",
        "#number of parents mating each generation\n",
        "num_parents_mating = 5\n",
        "# number of geneations\n",
        "num_generations = 10\n",
        "# number of genes for each chromosome\n",
        "num_genes = 6\n",
        "# number of chromosomes for each population\n",
        "num_chromosomes = 10\n",
        "# population size\n",
        "pop_size=(num_chromosomes,num_genes)\n",
        "# fitness values of the chromosome of the last generation\n",
        "fitness_values = []\n",
        "# fitness values of the chromosomes of the last generation\n",
        "last_fitness_values = []\n",
        "\n",
        "gen = 0\n",
        "cromo = 0\n",
        "\n",
        "parents=[]\n",
        "parents_fitness = []\n",
        "\n",
        "performances=[]\n",
        "hiperparameters=[]\n",
        "\n",
        "for generation in range(num_generations):\n",
        "    gen+=1\n",
        "    cromo = 0\n",
        "    best_perf_per_gen = -1\n",
        "    \n",
        "    for chromosome in population:\n",
        "        known=False\n",
        "        cromo+=1\n",
        "        score=-1\n",
        "        parentNumber=0\n",
        "        \n",
        "        # If it's a known chromosome we dont need to train it again\n",
        "        for savedCromo in parents:\n",
        "            parentNumber+=1\n",
        "            if (np.array_equal(chromosome,savedCromo)):\n",
        "                score = parents_fitness[parentNumber-1]\n",
        "                known = True\n",
        "        \n",
        "        # If it's a new chromosome we need to train the model\n",
        "        if (score < 0):\n",
        "            accuracy, realAcc  = chromosomeEvaluation(chromosome)\n",
        "            realAccN = realAcc/10000\n",
        "            print(realAcc)\n",
        "            score = accuracy - (accuracy*realAccN)\n",
        "            \n",
        "        if(not known):\n",
        "            print(\"Generation-{}\".format(gen),\"Chromosome-{}:\".format(cromo))\n",
        "            printChromossomeStructure(chromosome)\n",
        "            print(\"\\tScore {:.2f}\".format(score),\" | Accuracy: {:.2f}\".format(accuracy))\n",
        "        else:\n",
        "            print(\"Generation-{}\".format(gen),\"Chromosome-{}\".format(cromo),\"scored {:.2f}\".format(score), \" (Chromosome already known)\")\n",
        "\n",
        "        \n",
        "        # Keep the scores in fitness_values\n",
        "        fitness_values.append(score)\n",
        "        \n",
        "        # Getting the best hyperparameters per generation to check the evolution at the end\n",
        "        if(best_perf_per_gen < score):\n",
        "            best_perf_per_gen = score\n",
        "            best_cromo_per_gen = chromosome\n",
        "                   \n",
        "    performances.append(best_perf_per_gen)\n",
        "    hiperparameters.append(best_cromo_per_gen)\n",
        "   \n",
        "    print(performances,\"Best accuracies of each generation\")\n",
        "    print(hiperparameters,\"Best of each generation\")\n",
        "    \n",
        "    # Store last generation in other array because fitness_values is changed by the select_mating_pool\n",
        "    if(gen == num_generations):\n",
        "        for i in fitness_values:\n",
        "            last_fitness_values.append(i)\n",
        "        print(last_fitness_values,\"Last Fitness Values\")\n",
        "    \n",
        "    parents,parents_fitness = selectMatingPool(population,fitness_values,parents_fitness,num_parents_mating)\n",
        "\n",
        "    # Crossover to generate the next generation\n",
        "    offspring_size=(pop_size[0]-parents.shape[0], num_genes)\n",
        "    offspring_crossover = crossover(parents, offspring_size)\n",
        "\n",
        "    # Mutate the cromossomes\n",
        "    offspring_mutation = mutation(offspring_crossover)\n",
        "\n",
        "    # Create the new population\n",
        "    population[0:parents.shape[0], :] = parents\n",
        "    population[parents.shape[0]:, :] = offspring_mutation\n",
        "    \n",
        "    # Reset fitness_values\n",
        "    fitness_values=[]\n",
        "\n",
        "bestSolution = population[last_fitness_values.index(np.max(last_fitness_values))]\n",
        "print(\"The best hyperparameters obtained are:\")\n",
        "printChromossomeStructure(bestSolution)\n",
        "print(\"with a score of\",np.max(last_fitness_values))"
      ],
      "id": "wnjc25UM6WeN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mA saÃ­da de streaming foi truncada nas Ãºltimas 5000 linhas.\u001b[0m\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0442 - accuracy: 0.7420 - categorical_accuracy: 0.7420 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 18/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0490 - accuracy: 0.7539 - categorical_accuracy: 0.7539 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 19/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0510 - accuracy: 0.7401 - categorical_accuracy: 0.7401 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 20/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0419 - accuracy: 0.7511 - categorical_accuracy: 0.7511 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 21/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0382 - accuracy: 0.7495 - categorical_accuracy: 0.7495 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 22/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0386 - accuracy: 0.7473 - categorical_accuracy: 0.7473 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 23/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0501 - accuracy: 0.7516 - categorical_accuracy: 0.7516 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 24/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0483 - accuracy: 0.7389 - categorical_accuracy: 0.7389 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 25/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0450 - accuracy: 0.7408 - categorical_accuracy: 0.7408 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 26/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0521 - accuracy: 0.7410 - categorical_accuracy: 0.7410 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 27/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0525 - accuracy: 0.7302 - categorical_accuracy: 0.7302 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 28/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0456 - accuracy: 0.7509 - categorical_accuracy: 0.7509 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 29/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0545 - accuracy: 0.7396 - categorical_accuracy: 0.7396 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 30/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0463 - accuracy: 0.7509 - categorical_accuracy: 0.7509 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 31/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0498 - accuracy: 0.7414 - categorical_accuracy: 0.7414 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 32/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0587 - accuracy: 0.7327 - categorical_accuracy: 0.7327 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 33/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0463 - accuracy: 0.7543 - categorical_accuracy: 0.7543 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 34/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0406 - accuracy: 0.7431 - categorical_accuracy: 0.7431 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 35/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0507 - accuracy: 0.7416 - categorical_accuracy: 0.7416 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 36/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0507 - accuracy: 0.7392 - categorical_accuracy: 0.7392 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 37/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0481 - accuracy: 0.7353 - categorical_accuracy: 0.7353 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 38/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0487 - accuracy: 0.7499 - categorical_accuracy: 0.7499 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 39/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0494 - accuracy: 0.7389 - categorical_accuracy: 0.7389 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 40/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0555 - accuracy: 0.7222 - categorical_accuracy: 0.7222 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 41/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0580 - accuracy: 0.7441 - categorical_accuracy: 0.7441 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 42/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0603 - accuracy: 0.7403 - categorical_accuracy: 0.7403 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 43/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0504 - accuracy: 0.7437 - categorical_accuracy: 0.7437 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 44/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0471 - accuracy: 0.7424 - categorical_accuracy: 0.7424 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 45/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0472 - accuracy: 0.7336 - categorical_accuracy: 0.7336 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 46/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0516 - accuracy: 0.7452 - categorical_accuracy: 0.7452 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 47/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0489 - accuracy: 0.7484 - categorical_accuracy: 0.7484 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 48/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0485 - accuracy: 0.7389 - categorical_accuracy: 0.7389 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 49/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0610 - accuracy: 0.7330 - categorical_accuracy: 0.7330 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 50/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0346 - accuracy: 0.7528 - categorical_accuracy: 0.7528 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 51/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0440 - accuracy: 0.7463 - categorical_accuracy: 0.7463 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 52/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0509 - accuracy: 0.7459 - categorical_accuracy: 0.7459 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 53/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0480 - accuracy: 0.7521 - categorical_accuracy: 0.7521 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 54/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0564 - accuracy: 0.7370 - categorical_accuracy: 0.7370 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 55/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0477 - accuracy: 0.7419 - categorical_accuracy: 0.7419 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 56/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0517 - accuracy: 0.7372 - categorical_accuracy: 0.7372 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 57/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0484 - accuracy: 0.7421 - categorical_accuracy: 0.7421 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 58/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0493 - accuracy: 0.7342 - categorical_accuracy: 0.7342 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 59/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0552 - accuracy: 0.7489 - categorical_accuracy: 0.7489 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 60/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0480 - accuracy: 0.7488 - categorical_accuracy: 0.7488 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 61/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0428 - accuracy: 0.7437 - categorical_accuracy: 0.7437 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 62/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0468 - accuracy: 0.7463 - categorical_accuracy: 0.7463 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 63/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0565 - accuracy: 0.7384 - categorical_accuracy: 0.7384 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 64/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0509 - accuracy: 0.7428 - categorical_accuracy: 0.7428 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 65/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0477 - accuracy: 0.7525 - categorical_accuracy: 0.7525 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 66/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0416 - accuracy: 0.7414 - categorical_accuracy: 0.7414 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 67/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0544 - accuracy: 0.7443 - categorical_accuracy: 0.7443 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 68/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0495 - accuracy: 0.7449 - categorical_accuracy: 0.7449 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 69/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0464 - accuracy: 0.7364 - categorical_accuracy: 0.7364 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 70/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0458 - accuracy: 0.7570 - categorical_accuracy: 0.7570 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 71/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0503 - accuracy: 0.7429 - categorical_accuracy: 0.7429 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 72/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0500 - accuracy: 0.7510 - categorical_accuracy: 0.7510 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 73/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0498 - accuracy: 0.7428 - categorical_accuracy: 0.7428 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 74/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0485 - accuracy: 0.7537 - categorical_accuracy: 0.7537 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 75/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0519 - accuracy: 0.7525 - categorical_accuracy: 0.7525 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 76/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0449 - accuracy: 0.7411 - categorical_accuracy: 0.7411 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 77/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0481 - accuracy: 0.7420 - categorical_accuracy: 0.7420 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 78/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0407 - accuracy: 0.7368 - categorical_accuracy: 0.7368 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 79/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0508 - accuracy: 0.7292 - categorical_accuracy: 0.7292 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 80/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0511 - accuracy: 0.7427 - categorical_accuracy: 0.7427 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 81/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0390 - accuracy: 0.7415 - categorical_accuracy: 0.7415 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 82/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0479 - accuracy: 0.7415 - categorical_accuracy: 0.7415 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 83/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0431 - accuracy: 0.7399 - categorical_accuracy: 0.7399 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 84/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0623 - accuracy: 0.7413 - categorical_accuracy: 0.7413 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 85/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0514 - accuracy: 0.7392 - categorical_accuracy: 0.7392 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 86/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0602 - accuracy: 0.7390 - categorical_accuracy: 0.7390 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 87/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0488 - accuracy: 0.7397 - categorical_accuracy: 0.7397 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 88/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0483 - accuracy: 0.7410 - categorical_accuracy: 0.7410 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 89/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0490 - accuracy: 0.7517 - categorical_accuracy: 0.7517 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 90/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0485 - accuracy: 0.7411 - categorical_accuracy: 0.7411 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 91/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0466 - accuracy: 0.7416 - categorical_accuracy: 0.7416 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 92/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0542 - accuracy: 0.7454 - categorical_accuracy: 0.7454 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 93/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0496 - accuracy: 0.7503 - categorical_accuracy: 0.7503 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 94/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0476 - accuracy: 0.7464 - categorical_accuracy: 0.7464 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 95/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0482 - accuracy: 0.7340 - categorical_accuracy: 0.7340 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 96/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0480 - accuracy: 0.7415 - categorical_accuracy: 0.7415 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 97/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0550 - accuracy: 0.7461 - categorical_accuracy: 0.7461 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 98/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0591 - accuracy: 0.7403 - categorical_accuracy: 0.7403 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 99/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0504 - accuracy: 0.7407 - categorical_accuracy: 0.7407 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 100/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0505 - accuracy: 0.7268 - categorical_accuracy: 0.7268 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 101/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0518 - accuracy: 0.7474 - categorical_accuracy: 0.7474 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 102/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0426 - accuracy: 0.7411 - categorical_accuracy: 0.7411 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 103/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0563 - accuracy: 0.7442 - categorical_accuracy: 0.7442 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 104/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0508 - accuracy: 0.7352 - categorical_accuracy: 0.7352 - val_loss: 0.0564 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.7436 - categorical_accuracy: 0.7436\n",
            "1102\n",
            "Generation-7 Chromosome-6:\n",
            "Middle layers: 2 | Activation: softsign | Optimization: Adam | Loss: categorical_hinge | LR: 0.0001 | Dropout: 0.3 |\n",
            "\tScore 0.66  | Accuracy: 0.74\n",
            "Epoch 1/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.9461 - accuracy: 0.1379 - categorical_accuracy: 0.1379 - val_loss: 0.6790 - val_accuracy: 0.5906 - val_categorical_accuracy: 0.5906\n",
            "Epoch 2/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6762 - accuracy: 0.5389 - categorical_accuracy: 0.5389 - val_loss: 0.6149 - val_accuracy: 0.6564 - val_categorical_accuracy: 0.6564\n",
            "Epoch 3/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.5893 - accuracy: 0.6578 - categorical_accuracy: 0.6578 - val_loss: 0.5027 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 4/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.4817 - accuracy: 0.7142 - categorical_accuracy: 0.7142 - val_loss: 0.4015 - val_accuracy: 0.7410 - val_categorical_accuracy: 0.7410\n",
            "Epoch 5/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.3865 - accuracy: 0.7401 - categorical_accuracy: 0.7401 - val_loss: 0.3591 - val_accuracy: 0.7632 - val_categorical_accuracy: 0.7632\n",
            "Epoch 6/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.3564 - accuracy: 0.7555 - categorical_accuracy: 0.7555 - val_loss: 0.3136 - val_accuracy: 0.7906 - val_categorical_accuracy: 0.7906\n",
            "Epoch 7/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.2988 - accuracy: 0.7865 - categorical_accuracy: 0.7865 - val_loss: 0.2744 - val_accuracy: 0.7923 - val_categorical_accuracy: 0.7923\n",
            "Epoch 8/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.2656 - accuracy: 0.7743 - categorical_accuracy: 0.7743 - val_loss: 0.2354 - val_accuracy: 0.7906 - val_categorical_accuracy: 0.7906\n",
            "Epoch 9/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.2105 - accuracy: 0.7912 - categorical_accuracy: 0.7912 - val_loss: 0.1862 - val_accuracy: 0.7880 - val_categorical_accuracy: 0.7880\n",
            "Epoch 10/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.1784 - accuracy: 0.7808 - categorical_accuracy: 0.7808 - val_loss: 0.1471 - val_accuracy: 0.7915 - val_categorical_accuracy: 0.7915\n",
            "Epoch 11/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.1425 - accuracy: 0.7831 - categorical_accuracy: 0.7831 - val_loss: 0.1270 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 12/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.1130 - accuracy: 0.7896 - categorical_accuracy: 0.7896 - val_loss: 0.1136 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 13/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.1096 - accuracy: 0.7929 - categorical_accuracy: 0.7929 - val_loss: 0.1065 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 14/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.1024 - accuracy: 0.7874 - categorical_accuracy: 0.7874 - val_loss: 0.1021 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 15/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0963 - accuracy: 0.7805 - categorical_accuracy: 0.7805 - val_loss: 0.0993 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 16/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0904 - accuracy: 0.7824 - categorical_accuracy: 0.7824 - val_loss: 0.0970 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 17/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0892 - accuracy: 0.7866 - categorical_accuracy: 0.7866 - val_loss: 0.0950 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 18/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0916 - accuracy: 0.7963 - categorical_accuracy: 0.7963 - val_loss: 0.0932 - val_accuracy: 0.7974 - val_categorical_accuracy: 0.7974\n",
            "Epoch 19/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0807 - accuracy: 0.7893 - categorical_accuracy: 0.7893 - val_loss: 0.0914 - val_accuracy: 0.7974 - val_categorical_accuracy: 0.7974\n",
            "Epoch 20/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.1031 - accuracy: 0.7851 - categorical_accuracy: 0.7851 - val_loss: 0.0894 - val_accuracy: 0.7974 - val_categorical_accuracy: 0.7974\n",
            "Epoch 21/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0776 - accuracy: 0.8006 - categorical_accuracy: 0.8006 - val_loss: 0.0861 - val_accuracy: 0.7974 - val_categorical_accuracy: 0.7974\n",
            "Epoch 22/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0720 - accuracy: 0.7990 - categorical_accuracy: 0.7990 - val_loss: 0.0819 - val_accuracy: 0.7974 - val_categorical_accuracy: 0.7974\n",
            "Epoch 23/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0668 - accuracy: 0.7894 - categorical_accuracy: 0.7894 - val_loss: 0.0768 - val_accuracy: 0.7974 - val_categorical_accuracy: 0.7974\n",
            "Epoch 24/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0764 - accuracy: 0.7852 - categorical_accuracy: 0.7852 - val_loss: 0.0743 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 25/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0638 - accuracy: 0.7935 - categorical_accuracy: 0.7935 - val_loss: 0.0723 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 26/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0700 - accuracy: 0.7882 - categorical_accuracy: 0.7882 - val_loss: 0.0713 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 27/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0591 - accuracy: 0.7860 - categorical_accuracy: 0.7860 - val_loss: 0.0704 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 28/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0600 - accuracy: 0.7921 - categorical_accuracy: 0.7921 - val_loss: 0.0700 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 29/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0637 - accuracy: 0.7974 - categorical_accuracy: 0.7974 - val_loss: 0.0694 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 30/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0573 - accuracy: 0.7970 - categorical_accuracy: 0.7970 - val_loss: 0.0689 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 31/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0601 - accuracy: 0.7761 - categorical_accuracy: 0.7761 - val_loss: 0.0685 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 32/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0635 - accuracy: 0.7977 - categorical_accuracy: 0.7977 - val_loss: 0.0679 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 33/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0604 - accuracy: 0.7752 - categorical_accuracy: 0.7752 - val_loss: 0.0675 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 34/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0602 - accuracy: 0.7877 - categorical_accuracy: 0.7877 - val_loss: 0.0672 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 35/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0519 - accuracy: 0.8112 - categorical_accuracy: 0.8112 - val_loss: 0.0669 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 36/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0643 - accuracy: 0.7910 - categorical_accuracy: 0.7910 - val_loss: 0.0665 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 37/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0560 - accuracy: 0.7957 - categorical_accuracy: 0.7957 - val_loss: 0.0664 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 38/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0495 - accuracy: 0.8018 - categorical_accuracy: 0.8018 - val_loss: 0.0658 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 39/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0531 - accuracy: 0.7975 - categorical_accuracy: 0.7975 - val_loss: 0.0656 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 40/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0556 - accuracy: 0.7937 - categorical_accuracy: 0.7937 - val_loss: 0.0653 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 41/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0527 - accuracy: 0.8055 - categorical_accuracy: 0.8055 - val_loss: 0.0648 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 42/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0537 - accuracy: 0.7955 - categorical_accuracy: 0.7955 - val_loss: 0.0645 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 43/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0462 - accuracy: 0.7925 - categorical_accuracy: 0.7925 - val_loss: 0.0642 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 44/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0680 - accuracy: 0.7843 - categorical_accuracy: 0.7843 - val_loss: 0.0639 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 45/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0518 - accuracy: 0.7956 - categorical_accuracy: 0.7956 - val_loss: 0.0637 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 46/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0467 - accuracy: 0.7970 - categorical_accuracy: 0.7970 - val_loss: 0.0634 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 47/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0514 - accuracy: 0.7932 - categorical_accuracy: 0.7932 - val_loss: 0.0632 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 48/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0466 - accuracy: 0.7910 - categorical_accuracy: 0.7910 - val_loss: 0.0629 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 49/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0533 - accuracy: 0.7971 - categorical_accuracy: 0.7971 - val_loss: 0.0628 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 50/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0594 - accuracy: 0.7921 - categorical_accuracy: 0.7921 - val_loss: 0.0626 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 51/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0539 - accuracy: 0.7881 - categorical_accuracy: 0.7881 - val_loss: 0.0623 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 52/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0518 - accuracy: 0.7937 - categorical_accuracy: 0.7937 - val_loss: 0.0622 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 53/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0566 - accuracy: 0.7788 - categorical_accuracy: 0.7788 - val_loss: 0.0620 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 54/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0496 - accuracy: 0.7997 - categorical_accuracy: 0.7997 - val_loss: 0.0618 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 55/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0533 - accuracy: 0.7783 - categorical_accuracy: 0.7783 - val_loss: 0.0617 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 56/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0550 - accuracy: 0.8031 - categorical_accuracy: 0.8031 - val_loss: 0.0615 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 57/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0608 - accuracy: 0.8044 - categorical_accuracy: 0.8044 - val_loss: 0.0614 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 58/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0538 - accuracy: 0.7964 - categorical_accuracy: 0.7964 - val_loss: 0.0613 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 59/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0543 - accuracy: 0.8041 - categorical_accuracy: 0.8041 - val_loss: 0.0612 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 60/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0560 - accuracy: 0.7894 - categorical_accuracy: 0.7894 - val_loss: 0.0610 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 61/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0578 - accuracy: 0.7961 - categorical_accuracy: 0.7961 - val_loss: 0.0610 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 62/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0489 - accuracy: 0.7943 - categorical_accuracy: 0.7943 - val_loss: 0.0608 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 63/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0494 - accuracy: 0.7846 - categorical_accuracy: 0.7846 - val_loss: 0.0607 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 64/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0626 - accuracy: 0.7911 - categorical_accuracy: 0.7911 - val_loss: 0.0607 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 65/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0650 - accuracy: 0.7799 - categorical_accuracy: 0.7799 - val_loss: 0.0606 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 66/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0499 - accuracy: 0.8024 - categorical_accuracy: 0.8024 - val_loss: 0.0604 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 67/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0587 - accuracy: 0.7806 - categorical_accuracy: 0.7806 - val_loss: 0.0603 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 68/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0526 - accuracy: 0.7824 - categorical_accuracy: 0.7824 - val_loss: 0.0603 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 69/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0588 - accuracy: 0.7973 - categorical_accuracy: 0.7973 - val_loss: 0.0602 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 70/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0548 - accuracy: 0.7911 - categorical_accuracy: 0.7911 - val_loss: 0.0601 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 71/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0507 - accuracy: 0.7894 - categorical_accuracy: 0.7894 - val_loss: 0.0600 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 72/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0479 - accuracy: 0.8034 - categorical_accuracy: 0.8034 - val_loss: 0.0599 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 73/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0685 - accuracy: 0.7819 - categorical_accuracy: 0.7819 - val_loss: 0.0598 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 74/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0477 - accuracy: 0.7921 - categorical_accuracy: 0.7921 - val_loss: 0.0598 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 75/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0517 - accuracy: 0.7960 - categorical_accuracy: 0.7960 - val_loss: 0.0597 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 76/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0563 - accuracy: 0.7878 - categorical_accuracy: 0.7878 - val_loss: 0.0596 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 77/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0605 - accuracy: 0.7847 - categorical_accuracy: 0.7847 - val_loss: 0.0595 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 78/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0476 - accuracy: 0.7961 - categorical_accuracy: 0.7961 - val_loss: 0.0595 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 79/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0531 - accuracy: 0.7758 - categorical_accuracy: 0.7758 - val_loss: 0.0594 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 80/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0578 - accuracy: 0.7949 - categorical_accuracy: 0.7949 - val_loss: 0.0594 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 81/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0473 - accuracy: 0.7890 - categorical_accuracy: 0.7890 - val_loss: 0.0593 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 82/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0493 - accuracy: 0.7921 - categorical_accuracy: 0.7921 - val_loss: 0.0592 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 83/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0494 - accuracy: 0.8065 - categorical_accuracy: 0.8065 - val_loss: 0.0592 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 84/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0505 - accuracy: 0.7959 - categorical_accuracy: 0.7959 - val_loss: 0.0591 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 85/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0575 - accuracy: 0.7866 - categorical_accuracy: 0.7866 - val_loss: 0.0591 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 86/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0608 - accuracy: 0.7912 - categorical_accuracy: 0.7912 - val_loss: 0.0590 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 87/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0527 - accuracy: 0.7812 - categorical_accuracy: 0.7812 - val_loss: 0.0590 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 88/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0539 - accuracy: 0.7860 - categorical_accuracy: 0.7860 - val_loss: 0.0589 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 89/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0461 - accuracy: 0.7937 - categorical_accuracy: 0.7937 - val_loss: 0.0589 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 90/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0554 - accuracy: 0.7959 - categorical_accuracy: 0.7959 - val_loss: 0.0588 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 91/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0547 - accuracy: 0.7958 - categorical_accuracy: 0.7958 - val_loss: 0.0588 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 92/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0607 - accuracy: 0.7718 - categorical_accuracy: 0.7718 - val_loss: 0.0587 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 93/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0599 - accuracy: 0.8087 - categorical_accuracy: 0.8087 - val_loss: 0.0587 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 94/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0463 - accuracy: 0.8088 - categorical_accuracy: 0.8088 - val_loss: 0.0586 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 95/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0537 - accuracy: 0.7827 - categorical_accuracy: 0.7827 - val_loss: 0.0586 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 96/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0497 - accuracy: 0.7943 - categorical_accuracy: 0.7943 - val_loss: 0.0585 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 97/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0545 - accuracy: 0.7976 - categorical_accuracy: 0.7976 - val_loss: 0.0585 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 98/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0466 - accuracy: 0.7873 - categorical_accuracy: 0.7873 - val_loss: 0.0585 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 99/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0599 - accuracy: 0.7824 - categorical_accuracy: 0.7824 - val_loss: 0.0584 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 100/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0560 - accuracy: 0.8064 - categorical_accuracy: 0.8064 - val_loss: 0.0584 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 101/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0507 - accuracy: 0.7859 - categorical_accuracy: 0.7859 - val_loss: 0.0584 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 102/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0516 - accuracy: 0.8053 - categorical_accuracy: 0.8053 - val_loss: 0.0583 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 103/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0405 - accuracy: 0.7963 - categorical_accuracy: 0.7963 - val_loss: 0.0583 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 104/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0585 - accuracy: 0.8049 - categorical_accuracy: 0.8049 - val_loss: 0.0582 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 105/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0465 - accuracy: 0.7990 - categorical_accuracy: 0.7990 - val_loss: 0.0582 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 106/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0511 - accuracy: 0.7922 - categorical_accuracy: 0.7922 - val_loss: 0.0582 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 107/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0501 - accuracy: 0.7941 - categorical_accuracy: 0.7941 - val_loss: 0.0582 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 108/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0443 - accuracy: 0.7969 - categorical_accuracy: 0.7969 - val_loss: 0.0581 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 109/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0608 - accuracy: 0.7847 - categorical_accuracy: 0.7847 - val_loss: 0.0581 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 110/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0494 - accuracy: 0.7855 - categorical_accuracy: 0.7855 - val_loss: 0.0581 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 111/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0490 - accuracy: 0.7925 - categorical_accuracy: 0.7925 - val_loss: 0.0580 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 112/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0488 - accuracy: 0.8039 - categorical_accuracy: 0.8039 - val_loss: 0.0580 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 113/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0473 - accuracy: 0.7914 - categorical_accuracy: 0.7914 - val_loss: 0.0580 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 114/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0561 - accuracy: 0.7960 - categorical_accuracy: 0.7960 - val_loss: 0.0579 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 115/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0479 - accuracy: 0.7987 - categorical_accuracy: 0.7987 - val_loss: 0.0579 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 116/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0454 - accuracy: 0.7926 - categorical_accuracy: 0.7926 - val_loss: 0.0579 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 117/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0595 - accuracy: 0.7864 - categorical_accuracy: 0.7864 - val_loss: 0.0579 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 118/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0591 - accuracy: 0.8029 - categorical_accuracy: 0.8029 - val_loss: 0.0579 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 119/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0474 - accuracy: 0.7926 - categorical_accuracy: 0.7926 - val_loss: 0.0578 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 120/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0546 - accuracy: 0.8000 - categorical_accuracy: 0.8000 - val_loss: 0.0578 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 121/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0475 - accuracy: 0.7896 - categorical_accuracy: 0.7896 - val_loss: 0.0578 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 122/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0591 - accuracy: 0.7950 - categorical_accuracy: 0.7950 - val_loss: 0.0578 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 123/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0579 - accuracy: 0.7805 - categorical_accuracy: 0.7805 - val_loss: 0.0578 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 124/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0513 - accuracy: 0.8066 - categorical_accuracy: 0.8066 - val_loss: 0.0577 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 125/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0650 - accuracy: 0.7999 - categorical_accuracy: 0.7999 - val_loss: 0.0577 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 126/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0545 - accuracy: 0.7897 - categorical_accuracy: 0.7897 - val_loss: 0.0577 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 127/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0563 - accuracy: 0.7789 - categorical_accuracy: 0.7789 - val_loss: 0.0577 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 128/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0477 - accuracy: 0.7921 - categorical_accuracy: 0.7921 - val_loss: 0.0577 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 129/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0587 - accuracy: 0.7797 - categorical_accuracy: 0.7797 - val_loss: 0.0577 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 130/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0534 - accuracy: 0.7978 - categorical_accuracy: 0.7978 - val_loss: 0.0577 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 131/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0459 - accuracy: 0.7931 - categorical_accuracy: 0.7931 - val_loss: 0.0576 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 132/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0440 - accuracy: 0.7853 - categorical_accuracy: 0.7853 - val_loss: 0.0576 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 133/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0552 - accuracy: 0.7871 - categorical_accuracy: 0.7871 - val_loss: 0.0576 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 134/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0484 - accuracy: 0.7946 - categorical_accuracy: 0.7946 - val_loss: 0.0576 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 135/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0527 - accuracy: 0.7960 - categorical_accuracy: 0.7960 - val_loss: 0.0576 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 136/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0446 - accuracy: 0.7946 - categorical_accuracy: 0.7946 - val_loss: 0.0576 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 137/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0505 - accuracy: 0.7994 - categorical_accuracy: 0.7994 - val_loss: 0.0575 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 138/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0489 - accuracy: 0.7752 - categorical_accuracy: 0.7752 - val_loss: 0.0575 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 139/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0439 - accuracy: 0.7931 - categorical_accuracy: 0.7931 - val_loss: 0.0575 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 140/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0519 - accuracy: 0.8016 - categorical_accuracy: 0.8016 - val_loss: 0.0575 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 141/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0539 - accuracy: 0.7953 - categorical_accuracy: 0.7953 - val_loss: 0.0575 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 142/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0517 - accuracy: 0.7909 - categorical_accuracy: 0.7909 - val_loss: 0.0575 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 143/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0527 - accuracy: 0.7883 - categorical_accuracy: 0.7883 - val_loss: 0.0575 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 144/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0594 - accuracy: 0.7886 - categorical_accuracy: 0.7886 - val_loss: 0.0575 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 145/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0476 - accuracy: 0.7920 - categorical_accuracy: 0.7920 - val_loss: 0.0574 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 146/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0491 - accuracy: 0.7991 - categorical_accuracy: 0.7991 - val_loss: 0.0574 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 147/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0482 - accuracy: 0.7919 - categorical_accuracy: 0.7919 - val_loss: 0.0574 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 148/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0436 - accuracy: 0.7992 - categorical_accuracy: 0.7992 - val_loss: 0.0574 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 149/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0576 - accuracy: 0.7906 - categorical_accuracy: 0.7906 - val_loss: 0.0574 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 150/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0502 - accuracy: 0.7927 - categorical_accuracy: 0.7927 - val_loss: 0.0574 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 151/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0571 - accuracy: 0.7952 - categorical_accuracy: 0.7952 - val_loss: 0.0574 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 152/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0448 - accuracy: 0.7968 - categorical_accuracy: 0.7968 - val_loss: 0.0574 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 153/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0454 - accuracy: 0.7818 - categorical_accuracy: 0.7818 - val_loss: 0.0574 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 154/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0462 - accuracy: 0.7922 - categorical_accuracy: 0.7922 - val_loss: 0.0574 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 155/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0456 - accuracy: 0.7991 - categorical_accuracy: 0.7991 - val_loss: 0.0573 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 156/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0524 - accuracy: 0.7775 - categorical_accuracy: 0.7775 - val_loss: 0.0573 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 157/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0500 - accuracy: 0.7983 - categorical_accuracy: 0.7983 - val_loss: 0.0573 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 158/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0517 - accuracy: 0.7850 - categorical_accuracy: 0.7850 - val_loss: 0.0573 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 159/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0503 - accuracy: 0.7965 - categorical_accuracy: 0.7965 - val_loss: 0.0573 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 160/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0498 - accuracy: 0.7977 - categorical_accuracy: 0.7977 - val_loss: 0.0573 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 161/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0526 - accuracy: 0.7936 - categorical_accuracy: 0.7936 - val_loss: 0.0573 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 162/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0430 - accuracy: 0.7991 - categorical_accuracy: 0.7991 - val_loss: 0.0573 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 163/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0625 - accuracy: 0.7809 - categorical_accuracy: 0.7809 - val_loss: 0.0573 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 164/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0431 - accuracy: 0.7967 - categorical_accuracy: 0.7967 - val_loss: 0.0573 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 165/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0517 - accuracy: 0.7928 - categorical_accuracy: 0.7928 - val_loss: 0.0573 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 166/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0514 - accuracy: 0.7969 - categorical_accuracy: 0.7969 - val_loss: 0.0573 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 167/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0449 - accuracy: 0.7964 - categorical_accuracy: 0.7964 - val_loss: 0.0573 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 168/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0565 - accuracy: 0.7884 - categorical_accuracy: 0.7884 - val_loss: 0.0572 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 169/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0531 - accuracy: 0.7996 - categorical_accuracy: 0.7996 - val_loss: 0.0572 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 170/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0532 - accuracy: 0.7881 - categorical_accuracy: 0.7881 - val_loss: 0.0572 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 171/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0515 - accuracy: 0.8033 - categorical_accuracy: 0.8033 - val_loss: 0.0572 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 172/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0470 - accuracy: 0.7882 - categorical_accuracy: 0.7882 - val_loss: 0.0572 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 173/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0511 - accuracy: 0.7927 - categorical_accuracy: 0.7927 - val_loss: 0.0572 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 174/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0461 - accuracy: 0.7844 - categorical_accuracy: 0.7844 - val_loss: 0.0572 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 175/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0490 - accuracy: 0.7903 - categorical_accuracy: 0.7903 - val_loss: 0.0572 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 176/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0469 - accuracy: 0.7934 - categorical_accuracy: 0.7934 - val_loss: 0.0572 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 177/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0464 - accuracy: 0.7986 - categorical_accuracy: 0.7986 - val_loss: 0.0572 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 178/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0507 - accuracy: 0.7902 - categorical_accuracy: 0.7902 - val_loss: 0.0572 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 179/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0470 - accuracy: 0.7980 - categorical_accuracy: 0.7980 - val_loss: 0.0572 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 180/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0490 - accuracy: 0.7903 - categorical_accuracy: 0.7903 - val_loss: 0.0572 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 181/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0465 - accuracy: 0.7843 - categorical_accuracy: 0.7843 - val_loss: 0.0572 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 182/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0519 - accuracy: 0.7922 - categorical_accuracy: 0.7922 - val_loss: 0.0572 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 183/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0529 - accuracy: 0.8024 - categorical_accuracy: 0.8024 - val_loss: 0.0571 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 184/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0474 - accuracy: 0.7962 - categorical_accuracy: 0.7962 - val_loss: 0.0571 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 185/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0484 - accuracy: 0.7957 - categorical_accuracy: 0.7957 - val_loss: 0.0571 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 186/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0556 - accuracy: 0.7835 - categorical_accuracy: 0.7835 - val_loss: 0.0571 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 187/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0465 - accuracy: 0.7935 - categorical_accuracy: 0.7935 - val_loss: 0.0571 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 188/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0470 - accuracy: 0.7831 - categorical_accuracy: 0.7831 - val_loss: 0.0571 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 189/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0433 - accuracy: 0.7989 - categorical_accuracy: 0.7989 - val_loss: 0.0571 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 190/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0521 - accuracy: 0.7880 - categorical_accuracy: 0.7880 - val_loss: 0.0571 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 191/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0529 - accuracy: 0.7866 - categorical_accuracy: 0.7866 - val_loss: 0.0571 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 192/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0496 - accuracy: 0.7986 - categorical_accuracy: 0.7986 - val_loss: 0.0571 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 193/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0550 - accuracy: 0.7887 - categorical_accuracy: 0.7887 - val_loss: 0.0571 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 194/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.0462 - accuracy: 0.7889 - categorical_accuracy: 0.7889 - val_loss: 0.0571 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 195/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0639 - accuracy: 0.7902 - categorical_accuracy: 0.7902 - val_loss: 0.0571 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 196/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0410 - accuracy: 0.7840 - categorical_accuracy: 0.7840 - val_loss: 0.0571 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 197/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0471 - accuracy: 0.7828 - categorical_accuracy: 0.7828 - val_loss: 0.0571 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 198/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0370 - accuracy: 0.8047 - categorical_accuracy: 0.8047 - val_loss: 0.0571 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 199/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0434 - accuracy: 0.7920 - categorical_accuracy: 0.7920 - val_loss: 0.0571 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "Epoch 200/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.0511 - accuracy: 0.7917 - categorical_accuracy: 0.7917 - val_loss: 0.0571 - val_accuracy: 0.8000 - val_categorical_accuracy: 0.8000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.8000 - categorical_accuracy: 0.8000\n",
            "1102\n",
            "Generation-7 Chromosome-7:\n",
            "Middle layers: 2 | Activation: selu | Optimization: SGD | Loss: categorical_hinge | LR: 0.001 | Dropout: 0.15 |\n",
            "\tScore 0.71  | Accuracy: 0.80\n",
            "Epoch 1/200\n",
            "351/351 [==============================] - 5s 14ms/step - loss: 0.9893 - accuracy: 0.0203 - categorical_accuracy: 0.0203 - val_loss: 0.9849 - val_accuracy: 0.0248 - val_categorical_accuracy: 0.0248\n",
            "Epoch 2/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9880 - accuracy: 0.0252 - categorical_accuracy: 0.0252 - val_loss: 0.9841 - val_accuracy: 0.0248 - val_categorical_accuracy: 0.0248\n",
            "Epoch 3/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9868 - accuracy: 0.0249 - categorical_accuracy: 0.0249 - val_loss: 0.9834 - val_accuracy: 0.0248 - val_categorical_accuracy: 0.0248\n",
            "Epoch 4/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9884 - accuracy: 0.0204 - categorical_accuracy: 0.0204 - val_loss: 0.9827 - val_accuracy: 0.0256 - val_categorical_accuracy: 0.0256\n",
            "Epoch 5/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9861 - accuracy: 0.0252 - categorical_accuracy: 0.0252 - val_loss: 0.9820 - val_accuracy: 0.0256 - val_categorical_accuracy: 0.0256\n",
            "Epoch 6/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9862 - accuracy: 0.0215 - categorical_accuracy: 0.0215 - val_loss: 0.9814 - val_accuracy: 0.0274 - val_categorical_accuracy: 0.0274\n",
            "Epoch 7/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9859 - accuracy: 0.0291 - categorical_accuracy: 0.0291 - val_loss: 0.9807 - val_accuracy: 0.0291 - val_categorical_accuracy: 0.0291\n",
            "Epoch 8/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.9846 - accuracy: 0.0274 - categorical_accuracy: 0.0274 - val_loss: 0.9800 - val_accuracy: 0.0291 - val_categorical_accuracy: 0.0291\n",
            "Epoch 9/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9839 - accuracy: 0.0308 - categorical_accuracy: 0.0308 - val_loss: 0.9793 - val_accuracy: 0.0436 - val_categorical_accuracy: 0.0436\n",
            "Epoch 10/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9840 - accuracy: 0.0489 - categorical_accuracy: 0.0489 - val_loss: 0.9786 - val_accuracy: 0.0453 - val_categorical_accuracy: 0.0453\n",
            "Epoch 11/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9828 - accuracy: 0.0417 - categorical_accuracy: 0.0417 - val_loss: 0.9779 - val_accuracy: 0.0632 - val_categorical_accuracy: 0.0632\n",
            "Epoch 12/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9824 - accuracy: 0.0440 - categorical_accuracy: 0.0440 - val_loss: 0.9772 - val_accuracy: 0.0684 - val_categorical_accuracy: 0.0684\n",
            "Epoch 13/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9820 - accuracy: 0.0521 - categorical_accuracy: 0.0521 - val_loss: 0.9765 - val_accuracy: 0.1085 - val_categorical_accuracy: 0.1085\n",
            "Epoch 14/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9818 - accuracy: 0.0591 - categorical_accuracy: 0.0591 - val_loss: 0.9758 - val_accuracy: 0.1350 - val_categorical_accuracy: 0.1350\n",
            "Epoch 15/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9807 - accuracy: 0.0662 - categorical_accuracy: 0.0662 - val_loss: 0.9750 - val_accuracy: 0.1453 - val_categorical_accuracy: 0.1453\n",
            "Epoch 16/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9789 - accuracy: 0.0833 - categorical_accuracy: 0.0833 - val_loss: 0.9742 - val_accuracy: 0.1641 - val_categorical_accuracy: 0.1641\n",
            "Epoch 17/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9788 - accuracy: 0.0982 - categorical_accuracy: 0.0982 - val_loss: 0.9734 - val_accuracy: 0.1957 - val_categorical_accuracy: 0.1957\n",
            "Epoch 18/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9779 - accuracy: 0.1031 - categorical_accuracy: 0.1031 - val_loss: 0.9725 - val_accuracy: 0.2205 - val_categorical_accuracy: 0.2205\n",
            "Epoch 19/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9773 - accuracy: 0.1238 - categorical_accuracy: 0.1238 - val_loss: 0.9715 - val_accuracy: 0.2650 - val_categorical_accuracy: 0.2650\n",
            "Epoch 20/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9763 - accuracy: 0.1459 - categorical_accuracy: 0.1459 - val_loss: 0.9705 - val_accuracy: 0.2752 - val_categorical_accuracy: 0.2752\n",
            "Epoch 21/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9752 - accuracy: 0.1581 - categorical_accuracy: 0.1581 - val_loss: 0.9694 - val_accuracy: 0.2812 - val_categorical_accuracy: 0.2812\n",
            "Epoch 22/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9743 - accuracy: 0.1711 - categorical_accuracy: 0.1711 - val_loss: 0.9683 - val_accuracy: 0.2821 - val_categorical_accuracy: 0.2821\n",
            "Epoch 23/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9730 - accuracy: 0.1810 - categorical_accuracy: 0.1810 - val_loss: 0.9670 - val_accuracy: 0.2991 - val_categorical_accuracy: 0.2991\n",
            "Epoch 24/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9716 - accuracy: 0.2067 - categorical_accuracy: 0.2067 - val_loss: 0.9658 - val_accuracy: 0.3034 - val_categorical_accuracy: 0.3034\n",
            "Epoch 25/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9710 - accuracy: 0.2155 - categorical_accuracy: 0.2155 - val_loss: 0.9643 - val_accuracy: 0.3256 - val_categorical_accuracy: 0.3256\n",
            "Epoch 26/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9691 - accuracy: 0.2341 - categorical_accuracy: 0.2341 - val_loss: 0.9628 - val_accuracy: 0.3291 - val_categorical_accuracy: 0.3291\n",
            "Epoch 27/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9689 - accuracy: 0.2511 - categorical_accuracy: 0.2511 - val_loss: 0.9610 - val_accuracy: 0.3624 - val_categorical_accuracy: 0.3624\n",
            "Epoch 28/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9668 - accuracy: 0.2707 - categorical_accuracy: 0.2707 - val_loss: 0.9591 - val_accuracy: 0.3667 - val_categorical_accuracy: 0.3667\n",
            "Epoch 29/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9629 - accuracy: 0.3025 - categorical_accuracy: 0.3025 - val_loss: 0.9570 - val_accuracy: 0.4043 - val_categorical_accuracy: 0.4043\n",
            "Epoch 30/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9607 - accuracy: 0.3198 - categorical_accuracy: 0.3198 - val_loss: 0.9546 - val_accuracy: 0.4085 - val_categorical_accuracy: 0.4085\n",
            "Epoch 31/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.9608 - accuracy: 0.3136 - categorical_accuracy: 0.3136 - val_loss: 0.9518 - val_accuracy: 0.4239 - val_categorical_accuracy: 0.4239\n",
            "Epoch 32/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9574 - accuracy: 0.3453 - categorical_accuracy: 0.3453 - val_loss: 0.9486 - val_accuracy: 0.4231 - val_categorical_accuracy: 0.4231\n",
            "Epoch 33/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9535 - accuracy: 0.3586 - categorical_accuracy: 0.3586 - val_loss: 0.9449 - val_accuracy: 0.4291 - val_categorical_accuracy: 0.4291\n",
            "Epoch 34/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9528 - accuracy: 0.3600 - categorical_accuracy: 0.3600 - val_loss: 0.9408 - val_accuracy: 0.4504 - val_categorical_accuracy: 0.4504\n",
            "Epoch 35/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9462 - accuracy: 0.4000 - categorical_accuracy: 0.4000 - val_loss: 0.9361 - val_accuracy: 0.4547 - val_categorical_accuracy: 0.4547\n",
            "Epoch 36/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9408 - accuracy: 0.4139 - categorical_accuracy: 0.4139 - val_loss: 0.9307 - val_accuracy: 0.4590 - val_categorical_accuracy: 0.4590\n",
            "Epoch 37/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9359 - accuracy: 0.4087 - categorical_accuracy: 0.4087 - val_loss: 0.9248 - val_accuracy: 0.4590 - val_categorical_accuracy: 0.4590\n",
            "Epoch 38/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9316 - accuracy: 0.4227 - categorical_accuracy: 0.4227 - val_loss: 0.9182 - val_accuracy: 0.4607 - val_categorical_accuracy: 0.4607\n",
            "Epoch 39/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9276 - accuracy: 0.4323 - categorical_accuracy: 0.4323 - val_loss: 0.9110 - val_accuracy: 0.4709 - val_categorical_accuracy: 0.4709\n",
            "Epoch 40/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9188 - accuracy: 0.4561 - categorical_accuracy: 0.4561 - val_loss: 0.9035 - val_accuracy: 0.4778 - val_categorical_accuracy: 0.4778\n",
            "Epoch 41/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9083 - accuracy: 0.4583 - categorical_accuracy: 0.4583 - val_loss: 0.8957 - val_accuracy: 0.4778 - val_categorical_accuracy: 0.4778\n",
            "Epoch 42/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9018 - accuracy: 0.4533 - categorical_accuracy: 0.4533 - val_loss: 0.8875 - val_accuracy: 0.4778 - val_categorical_accuracy: 0.4778\n",
            "Epoch 43/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.8913 - accuracy: 0.4743 - categorical_accuracy: 0.4743 - val_loss: 0.8790 - val_accuracy: 0.4778 - val_categorical_accuracy: 0.4778\n",
            "Epoch 44/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.8884 - accuracy: 0.4714 - categorical_accuracy: 0.4714 - val_loss: 0.8703 - val_accuracy: 0.4778 - val_categorical_accuracy: 0.4778\n",
            "Epoch 45/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.8773 - accuracy: 0.4772 - categorical_accuracy: 0.4772 - val_loss: 0.8614 - val_accuracy: 0.4778 - val_categorical_accuracy: 0.4778\n",
            "Epoch 46/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.8711 - accuracy: 0.4773 - categorical_accuracy: 0.4773 - val_loss: 0.8522 - val_accuracy: 0.4803 - val_categorical_accuracy: 0.4803\n",
            "Epoch 47/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.8572 - accuracy: 0.4716 - categorical_accuracy: 0.4716 - val_loss: 0.8429 - val_accuracy: 0.4803 - val_categorical_accuracy: 0.4803\n",
            "Epoch 48/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.8498 - accuracy: 0.4610 - categorical_accuracy: 0.4610 - val_loss: 0.8334 - val_accuracy: 0.4846 - val_categorical_accuracy: 0.4846\n",
            "Epoch 49/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.8444 - accuracy: 0.4820 - categorical_accuracy: 0.4820 - val_loss: 0.8239 - val_accuracy: 0.4846 - val_categorical_accuracy: 0.4846\n",
            "Epoch 50/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.8273 - accuracy: 0.4659 - categorical_accuracy: 0.4659 - val_loss: 0.8146 - val_accuracy: 0.4838 - val_categorical_accuracy: 0.4838\n",
            "Epoch 51/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.8236 - accuracy: 0.4815 - categorical_accuracy: 0.4815 - val_loss: 0.8058 - val_accuracy: 0.4855 - val_categorical_accuracy: 0.4855\n",
            "Epoch 52/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.8261 - accuracy: 0.4746 - categorical_accuracy: 0.4746 - val_loss: 0.7976 - val_accuracy: 0.4855 - val_categorical_accuracy: 0.4855\n",
            "Epoch 53/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7961 - accuracy: 0.4962 - categorical_accuracy: 0.4962 - val_loss: 0.7899 - val_accuracy: 0.4863 - val_categorical_accuracy: 0.4863\n",
            "Epoch 54/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7979 - accuracy: 0.4783 - categorical_accuracy: 0.4783 - val_loss: 0.7828 - val_accuracy: 0.4863 - val_categorical_accuracy: 0.4863\n",
            "Epoch 55/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7894 - accuracy: 0.4866 - categorical_accuracy: 0.4866 - val_loss: 0.7763 - val_accuracy: 0.5017 - val_categorical_accuracy: 0.5017\n",
            "Epoch 56/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7762 - accuracy: 0.5013 - categorical_accuracy: 0.5013 - val_loss: 0.7705 - val_accuracy: 0.5017 - val_categorical_accuracy: 0.5017\n",
            "Epoch 57/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7891 - accuracy: 0.4709 - categorical_accuracy: 0.4709 - val_loss: 0.7653 - val_accuracy: 0.5017 - val_categorical_accuracy: 0.5017\n",
            "Epoch 58/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7602 - accuracy: 0.4953 - categorical_accuracy: 0.4953 - val_loss: 0.7607 - val_accuracy: 0.5017 - val_categorical_accuracy: 0.5017\n",
            "Epoch 59/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7765 - accuracy: 0.4826 - categorical_accuracy: 0.4826 - val_loss: 0.7566 - val_accuracy: 0.5017 - val_categorical_accuracy: 0.5017\n",
            "Epoch 60/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7644 - accuracy: 0.4941 - categorical_accuracy: 0.4941 - val_loss: 0.7528 - val_accuracy: 0.5017 - val_categorical_accuracy: 0.5017\n",
            "Epoch 61/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7645 - accuracy: 0.4846 - categorical_accuracy: 0.4846 - val_loss: 0.7494 - val_accuracy: 0.5017 - val_categorical_accuracy: 0.5017\n",
            "Epoch 62/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.7567 - accuracy: 0.4901 - categorical_accuracy: 0.4901 - val_loss: 0.7464 - val_accuracy: 0.5034 - val_categorical_accuracy: 0.5034\n",
            "Epoch 63/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7563 - accuracy: 0.4941 - categorical_accuracy: 0.4941 - val_loss: 0.7437 - val_accuracy: 0.5034 - val_categorical_accuracy: 0.5034\n",
            "Epoch 64/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7522 - accuracy: 0.4866 - categorical_accuracy: 0.4866 - val_loss: 0.7411 - val_accuracy: 0.5034 - val_categorical_accuracy: 0.5034\n",
            "Epoch 65/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7526 - accuracy: 0.4985 - categorical_accuracy: 0.4985 - val_loss: 0.7388 - val_accuracy: 0.5034 - val_categorical_accuracy: 0.5034\n",
            "Epoch 66/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7485 - accuracy: 0.4903 - categorical_accuracy: 0.4903 - val_loss: 0.7366 - val_accuracy: 0.5034 - val_categorical_accuracy: 0.5034\n",
            "Epoch 67/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7422 - accuracy: 0.5015 - categorical_accuracy: 0.5015 - val_loss: 0.7347 - val_accuracy: 0.5034 - val_categorical_accuracy: 0.5034\n",
            "Epoch 68/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7490 - accuracy: 0.4821 - categorical_accuracy: 0.4821 - val_loss: 0.7328 - val_accuracy: 0.5034 - val_categorical_accuracy: 0.5034\n",
            "Epoch 69/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7601 - accuracy: 0.4752 - categorical_accuracy: 0.4752 - val_loss: 0.7310 - val_accuracy: 0.5034 - val_categorical_accuracy: 0.5034\n",
            "Epoch 70/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7348 - accuracy: 0.4971 - categorical_accuracy: 0.4971 - val_loss: 0.7294 - val_accuracy: 0.5034 - val_categorical_accuracy: 0.5034\n",
            "Epoch 71/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7310 - accuracy: 0.5027 - categorical_accuracy: 0.5027 - val_loss: 0.7278 - val_accuracy: 0.5034 - val_categorical_accuracy: 0.5034\n",
            "Epoch 72/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7354 - accuracy: 0.4953 - categorical_accuracy: 0.4953 - val_loss: 0.7263 - val_accuracy: 0.5043 - val_categorical_accuracy: 0.5043\n",
            "Epoch 73/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7392 - accuracy: 0.4853 - categorical_accuracy: 0.4853 - val_loss: 0.7249 - val_accuracy: 0.5043 - val_categorical_accuracy: 0.5043\n",
            "Epoch 74/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7500 - accuracy: 0.4772 - categorical_accuracy: 0.4772 - val_loss: 0.7235 - val_accuracy: 0.5043 - val_categorical_accuracy: 0.5043\n",
            "Epoch 75/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7348 - accuracy: 0.4965 - categorical_accuracy: 0.4965 - val_loss: 0.7222 - val_accuracy: 0.5043 - val_categorical_accuracy: 0.5043\n",
            "Epoch 76/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7407 - accuracy: 0.4889 - categorical_accuracy: 0.4889 - val_loss: 0.7209 - val_accuracy: 0.5043 - val_categorical_accuracy: 0.5043\n",
            "Epoch 77/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7195 - accuracy: 0.5084 - categorical_accuracy: 0.5084 - val_loss: 0.7196 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 78/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7119 - accuracy: 0.5046 - categorical_accuracy: 0.5046 - val_loss: 0.7184 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 79/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7265 - accuracy: 0.4999 - categorical_accuracy: 0.4999 - val_loss: 0.7172 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 80/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7260 - accuracy: 0.5003 - categorical_accuracy: 0.5003 - val_loss: 0.7161 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 81/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7268 - accuracy: 0.5033 - categorical_accuracy: 0.5033 - val_loss: 0.7150 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 82/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7333 - accuracy: 0.4996 - categorical_accuracy: 0.4996 - val_loss: 0.7139 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 83/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7129 - accuracy: 0.5049 - categorical_accuracy: 0.5049 - val_loss: 0.7128 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 84/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7005 - accuracy: 0.5160 - categorical_accuracy: 0.5160 - val_loss: 0.7118 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 85/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7101 - accuracy: 0.5039 - categorical_accuracy: 0.5039 - val_loss: 0.7108 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 86/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7199 - accuracy: 0.5076 - categorical_accuracy: 0.5076 - val_loss: 0.7097 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 87/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7303 - accuracy: 0.4992 - categorical_accuracy: 0.4992 - val_loss: 0.7087 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 88/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7227 - accuracy: 0.4954 - categorical_accuracy: 0.4954 - val_loss: 0.7078 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 89/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7239 - accuracy: 0.4982 - categorical_accuracy: 0.4982 - val_loss: 0.7068 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 90/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7251 - accuracy: 0.4957 - categorical_accuracy: 0.4957 - val_loss: 0.7058 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 91/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7040 - accuracy: 0.5040 - categorical_accuracy: 0.5040 - val_loss: 0.7049 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 92/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7148 - accuracy: 0.5144 - categorical_accuracy: 0.5144 - val_loss: 0.7040 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 93/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7092 - accuracy: 0.5039 - categorical_accuracy: 0.5039 - val_loss: 0.7031 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 94/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7133 - accuracy: 0.5002 - categorical_accuracy: 0.5002 - val_loss: 0.7022 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 95/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.7075 - accuracy: 0.5121 - categorical_accuracy: 0.5121 - val_loss: 0.7013 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 96/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.6998 - accuracy: 0.5200 - categorical_accuracy: 0.5200 - val_loss: 0.7004 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 97/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7112 - accuracy: 0.5090 - categorical_accuracy: 0.5090 - val_loss: 0.6995 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 98/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7073 - accuracy: 0.5053 - categorical_accuracy: 0.5053 - val_loss: 0.6987 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 99/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7183 - accuracy: 0.4921 - categorical_accuracy: 0.4921 - val_loss: 0.6978 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 100/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6990 - accuracy: 0.5099 - categorical_accuracy: 0.5099 - val_loss: 0.6970 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 101/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.7034 - accuracy: 0.5162 - categorical_accuracy: 0.5162 - val_loss: 0.6961 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 102/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7067 - accuracy: 0.5056 - categorical_accuracy: 0.5056 - val_loss: 0.6953 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 103/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6949 - accuracy: 0.5203 - categorical_accuracy: 0.5203 - val_loss: 0.6945 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 104/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.7070 - accuracy: 0.5084 - categorical_accuracy: 0.5084 - val_loss: 0.6937 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 105/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6852 - accuracy: 0.5256 - categorical_accuracy: 0.5256 - val_loss: 0.6929 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 106/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6847 - accuracy: 0.5199 - categorical_accuracy: 0.5199 - val_loss: 0.6921 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 107/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.7002 - accuracy: 0.5029 - categorical_accuracy: 0.5029 - val_loss: 0.6913 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 108/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7144 - accuracy: 0.5040 - categorical_accuracy: 0.5040 - val_loss: 0.6906 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 109/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7070 - accuracy: 0.5099 - categorical_accuracy: 0.5099 - val_loss: 0.6898 - val_accuracy: 0.5060 - val_categorical_accuracy: 0.5060\n",
            "Epoch 110/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7106 - accuracy: 0.5041 - categorical_accuracy: 0.5041 - val_loss: 0.6891 - val_accuracy: 0.5248 - val_categorical_accuracy: 0.5248\n",
            "Epoch 111/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7091 - accuracy: 0.5056 - categorical_accuracy: 0.5056 - val_loss: 0.6883 - val_accuracy: 0.5248 - val_categorical_accuracy: 0.5248\n",
            "Epoch 112/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6968 - accuracy: 0.5109 - categorical_accuracy: 0.5109 - val_loss: 0.6876 - val_accuracy: 0.5248 - val_categorical_accuracy: 0.5248\n",
            "Epoch 113/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7023 - accuracy: 0.5074 - categorical_accuracy: 0.5074 - val_loss: 0.6868 - val_accuracy: 0.5248 - val_categorical_accuracy: 0.5248\n",
            "Epoch 114/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6927 - accuracy: 0.5099 - categorical_accuracy: 0.5099 - val_loss: 0.6861 - val_accuracy: 0.5248 - val_categorical_accuracy: 0.5248\n",
            "Epoch 115/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6776 - accuracy: 0.5231 - categorical_accuracy: 0.5231 - val_loss: 0.6854 - val_accuracy: 0.5248 - val_categorical_accuracy: 0.5248\n",
            "Epoch 116/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6880 - accuracy: 0.5214 - categorical_accuracy: 0.5214 - val_loss: 0.6847 - val_accuracy: 0.5248 - val_categorical_accuracy: 0.5248\n",
            "Epoch 117/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7016 - accuracy: 0.5071 - categorical_accuracy: 0.5071 - val_loss: 0.6839 - val_accuracy: 0.5248 - val_categorical_accuracy: 0.5248\n",
            "Epoch 118/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6897 - accuracy: 0.5217 - categorical_accuracy: 0.5217 - val_loss: 0.6832 - val_accuracy: 0.5256 - val_categorical_accuracy: 0.5256\n",
            "Epoch 119/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6841 - accuracy: 0.5221 - categorical_accuracy: 0.5221 - val_loss: 0.6825 - val_accuracy: 0.5256 - val_categorical_accuracy: 0.5256\n",
            "Epoch 120/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6878 - accuracy: 0.5139 - categorical_accuracy: 0.5139 - val_loss: 0.6818 - val_accuracy: 0.5256 - val_categorical_accuracy: 0.5256\n",
            "Epoch 121/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6965 - accuracy: 0.5079 - categorical_accuracy: 0.5079 - val_loss: 0.6811 - val_accuracy: 0.5256 - val_categorical_accuracy: 0.5256\n",
            "Epoch 122/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6941 - accuracy: 0.5017 - categorical_accuracy: 0.5017 - val_loss: 0.6804 - val_accuracy: 0.5256 - val_categorical_accuracy: 0.5256\n",
            "Epoch 123/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6881 - accuracy: 0.5217 - categorical_accuracy: 0.5217 - val_loss: 0.6798 - val_accuracy: 0.5256 - val_categorical_accuracy: 0.5256\n",
            "Epoch 124/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6822 - accuracy: 0.5116 - categorical_accuracy: 0.5116 - val_loss: 0.6791 - val_accuracy: 0.5256 - val_categorical_accuracy: 0.5256\n",
            "Epoch 125/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6785 - accuracy: 0.5234 - categorical_accuracy: 0.5234 - val_loss: 0.6784 - val_accuracy: 0.5256 - val_categorical_accuracy: 0.5256\n",
            "Epoch 126/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6848 - accuracy: 0.5266 - categorical_accuracy: 0.5266 - val_loss: 0.6777 - val_accuracy: 0.5256 - val_categorical_accuracy: 0.5256\n",
            "Epoch 127/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7025 - accuracy: 0.5351 - categorical_accuracy: 0.5351 - val_loss: 0.6770 - val_accuracy: 0.5256 - val_categorical_accuracy: 0.5256\n",
            "Epoch 128/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6812 - accuracy: 0.5184 - categorical_accuracy: 0.5184 - val_loss: 0.6764 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 129/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6886 - accuracy: 0.5189 - categorical_accuracy: 0.5189 - val_loss: 0.6757 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 130/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6792 - accuracy: 0.5312 - categorical_accuracy: 0.5312 - val_loss: 0.6751 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 131/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6701 - accuracy: 0.5275 - categorical_accuracy: 0.5275 - val_loss: 0.6744 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 132/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6700 - accuracy: 0.5195 - categorical_accuracy: 0.5195 - val_loss: 0.6737 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 133/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6826 - accuracy: 0.5294 - categorical_accuracy: 0.5294 - val_loss: 0.6731 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 134/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6888 - accuracy: 0.5197 - categorical_accuracy: 0.5197 - val_loss: 0.6724 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 135/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6750 - accuracy: 0.5209 - categorical_accuracy: 0.5209 - val_loss: 0.6718 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 136/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6866 - accuracy: 0.5207 - categorical_accuracy: 0.5207 - val_loss: 0.6712 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 137/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.6765 - accuracy: 0.5170 - categorical_accuracy: 0.5170 - val_loss: 0.6705 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 138/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6759 - accuracy: 0.5203 - categorical_accuracy: 0.5203 - val_loss: 0.6699 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 139/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6614 - accuracy: 0.5343 - categorical_accuracy: 0.5343 - val_loss: 0.6692 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 140/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6704 - accuracy: 0.5285 - categorical_accuracy: 0.5285 - val_loss: 0.6686 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 141/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6702 - accuracy: 0.5188 - categorical_accuracy: 0.5188 - val_loss: 0.6679 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 142/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6711 - accuracy: 0.5375 - categorical_accuracy: 0.5375 - val_loss: 0.6673 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 143/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6685 - accuracy: 0.5277 - categorical_accuracy: 0.5277 - val_loss: 0.6666 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 144/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6753 - accuracy: 0.5116 - categorical_accuracy: 0.5116 - val_loss: 0.6660 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 145/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6842 - accuracy: 0.5228 - categorical_accuracy: 0.5228 - val_loss: 0.6654 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 146/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6713 - accuracy: 0.5225 - categorical_accuracy: 0.5225 - val_loss: 0.6647 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 147/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6758 - accuracy: 0.5242 - categorical_accuracy: 0.5242 - val_loss: 0.6641 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 148/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6731 - accuracy: 0.5240 - categorical_accuracy: 0.5240 - val_loss: 0.6634 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 149/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.6688 - accuracy: 0.5293 - categorical_accuracy: 0.5293 - val_loss: 0.6628 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 150/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6772 - accuracy: 0.5084 - categorical_accuracy: 0.5084 - val_loss: 0.6621 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 151/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6696 - accuracy: 0.5243 - categorical_accuracy: 0.5243 - val_loss: 0.6615 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 152/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6573 - accuracy: 0.5408 - categorical_accuracy: 0.5408 - val_loss: 0.6608 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 153/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6650 - accuracy: 0.5260 - categorical_accuracy: 0.5260 - val_loss: 0.6602 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 154/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6651 - accuracy: 0.5312 - categorical_accuracy: 0.5312 - val_loss: 0.6595 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 155/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6586 - accuracy: 0.5424 - categorical_accuracy: 0.5424 - val_loss: 0.6589 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 156/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6611 - accuracy: 0.5338 - categorical_accuracy: 0.5338 - val_loss: 0.6582 - val_accuracy: 0.5427 - val_categorical_accuracy: 0.5427\n",
            "Epoch 157/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6709 - accuracy: 0.5275 - categorical_accuracy: 0.5275 - val_loss: 0.6575 - val_accuracy: 0.5641 - val_categorical_accuracy: 0.5641\n",
            "Epoch 158/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6598 - accuracy: 0.5384 - categorical_accuracy: 0.5384 - val_loss: 0.6568 - val_accuracy: 0.5692 - val_categorical_accuracy: 0.5692\n",
            "Epoch 159/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6623 - accuracy: 0.5435 - categorical_accuracy: 0.5435 - val_loss: 0.6561 - val_accuracy: 0.5692 - val_categorical_accuracy: 0.5692\n",
            "Epoch 160/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6563 - accuracy: 0.5388 - categorical_accuracy: 0.5388 - val_loss: 0.6555 - val_accuracy: 0.5718 - val_categorical_accuracy: 0.5718\n",
            "Epoch 161/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6619 - accuracy: 0.5349 - categorical_accuracy: 0.5349 - val_loss: 0.6548 - val_accuracy: 0.5718 - val_categorical_accuracy: 0.5718\n",
            "Epoch 162/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6705 - accuracy: 0.5259 - categorical_accuracy: 0.5259 - val_loss: 0.6541 - val_accuracy: 0.5726 - val_categorical_accuracy: 0.5726\n",
            "Epoch 163/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6594 - accuracy: 0.5408 - categorical_accuracy: 0.5408 - val_loss: 0.6534 - val_accuracy: 0.5761 - val_categorical_accuracy: 0.5761\n",
            "Epoch 164/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6660 - accuracy: 0.5262 - categorical_accuracy: 0.5262 - val_loss: 0.6526 - val_accuracy: 0.5761 - val_categorical_accuracy: 0.5761\n",
            "Epoch 165/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6531 - accuracy: 0.5406 - categorical_accuracy: 0.5406 - val_loss: 0.6519 - val_accuracy: 0.5761 - val_categorical_accuracy: 0.5761\n",
            "Epoch 166/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6638 - accuracy: 0.5195 - categorical_accuracy: 0.5195 - val_loss: 0.6512 - val_accuracy: 0.5761 - val_categorical_accuracy: 0.5761\n",
            "Epoch 167/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6667 - accuracy: 0.5229 - categorical_accuracy: 0.5229 - val_loss: 0.6504 - val_accuracy: 0.5761 - val_categorical_accuracy: 0.5761\n",
            "Epoch 168/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6548 - accuracy: 0.5390 - categorical_accuracy: 0.5390 - val_loss: 0.6497 - val_accuracy: 0.5761 - val_categorical_accuracy: 0.5761\n",
            "Epoch 169/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6546 - accuracy: 0.5311 - categorical_accuracy: 0.5311 - val_loss: 0.6489 - val_accuracy: 0.5761 - val_categorical_accuracy: 0.5761\n",
            "Epoch 170/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6587 - accuracy: 0.5382 - categorical_accuracy: 0.5382 - val_loss: 0.6481 - val_accuracy: 0.5778 - val_categorical_accuracy: 0.5778\n",
            "Epoch 171/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6686 - accuracy: 0.5328 - categorical_accuracy: 0.5328 - val_loss: 0.6474 - val_accuracy: 0.5778 - val_categorical_accuracy: 0.5778\n",
            "Epoch 172/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6607 - accuracy: 0.5331 - categorical_accuracy: 0.5331 - val_loss: 0.6465 - val_accuracy: 0.5795 - val_categorical_accuracy: 0.5795\n",
            "Epoch 173/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6459 - accuracy: 0.5473 - categorical_accuracy: 0.5473 - val_loss: 0.6457 - val_accuracy: 0.5795 - val_categorical_accuracy: 0.5795\n",
            "Epoch 174/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6498 - accuracy: 0.5478 - categorical_accuracy: 0.5478 - val_loss: 0.6449 - val_accuracy: 0.5795 - val_categorical_accuracy: 0.5795\n",
            "Epoch 175/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6599 - accuracy: 0.5367 - categorical_accuracy: 0.5367 - val_loss: 0.6440 - val_accuracy: 0.5795 - val_categorical_accuracy: 0.5795\n",
            "Epoch 176/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.6377 - accuracy: 0.5581 - categorical_accuracy: 0.5581 - val_loss: 0.6432 - val_accuracy: 0.5821 - val_categorical_accuracy: 0.5821\n",
            "Epoch 177/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6567 - accuracy: 0.5394 - categorical_accuracy: 0.5394 - val_loss: 0.6423 - val_accuracy: 0.5821 - val_categorical_accuracy: 0.5821\n",
            "Epoch 178/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6620 - accuracy: 0.5294 - categorical_accuracy: 0.5294 - val_loss: 0.6414 - val_accuracy: 0.5829 - val_categorical_accuracy: 0.5829\n",
            "Epoch 179/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6500 - accuracy: 0.5320 - categorical_accuracy: 0.5320 - val_loss: 0.6405 - val_accuracy: 0.5829 - val_categorical_accuracy: 0.5829\n",
            "Epoch 180/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.6405 - accuracy: 0.5544 - categorical_accuracy: 0.5544 - val_loss: 0.6396 - val_accuracy: 0.5829 - val_categorical_accuracy: 0.5829\n",
            "Epoch 181/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6299 - accuracy: 0.5667 - categorical_accuracy: 0.5667 - val_loss: 0.6386 - val_accuracy: 0.5829 - val_categorical_accuracy: 0.5829\n",
            "Epoch 182/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6419 - accuracy: 0.5465 - categorical_accuracy: 0.5465 - val_loss: 0.6376 - val_accuracy: 0.5829 - val_categorical_accuracy: 0.5829\n",
            "Epoch 183/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6396 - accuracy: 0.5521 - categorical_accuracy: 0.5521 - val_loss: 0.6366 - val_accuracy: 0.5829 - val_categorical_accuracy: 0.5829\n",
            "Epoch 184/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6499 - accuracy: 0.5369 - categorical_accuracy: 0.5369 - val_loss: 0.6356 - val_accuracy: 0.5829 - val_categorical_accuracy: 0.5829\n",
            "Epoch 185/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6422 - accuracy: 0.5497 - categorical_accuracy: 0.5497 - val_loss: 0.6346 - val_accuracy: 0.5829 - val_categorical_accuracy: 0.5829\n",
            "Epoch 186/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6423 - accuracy: 0.5521 - categorical_accuracy: 0.5521 - val_loss: 0.6335 - val_accuracy: 0.5838 - val_categorical_accuracy: 0.5838\n",
            "Epoch 187/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6302 - accuracy: 0.5498 - categorical_accuracy: 0.5498 - val_loss: 0.6325 - val_accuracy: 0.5838 - val_categorical_accuracy: 0.5838\n",
            "Epoch 188/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6407 - accuracy: 0.5544 - categorical_accuracy: 0.5544 - val_loss: 0.6314 - val_accuracy: 0.5838 - val_categorical_accuracy: 0.5838\n",
            "Epoch 189/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6309 - accuracy: 0.5505 - categorical_accuracy: 0.5505 - val_loss: 0.6303 - val_accuracy: 0.5838 - val_categorical_accuracy: 0.5838\n",
            "Epoch 190/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6355 - accuracy: 0.5534 - categorical_accuracy: 0.5534 - val_loss: 0.6291 - val_accuracy: 0.5838 - val_categorical_accuracy: 0.5838\n",
            "Epoch 191/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6364 - accuracy: 0.5643 - categorical_accuracy: 0.5643 - val_loss: 0.6280 - val_accuracy: 0.5838 - val_categorical_accuracy: 0.5838\n",
            "Epoch 192/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.6218 - accuracy: 0.5571 - categorical_accuracy: 0.5571 - val_loss: 0.6269 - val_accuracy: 0.5838 - val_categorical_accuracy: 0.5838\n",
            "Epoch 193/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6313 - accuracy: 0.5636 - categorical_accuracy: 0.5636 - val_loss: 0.6257 - val_accuracy: 0.5838 - val_categorical_accuracy: 0.5838\n",
            "Epoch 194/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6364 - accuracy: 0.5632 - categorical_accuracy: 0.5632 - val_loss: 0.6245 - val_accuracy: 0.5838 - val_categorical_accuracy: 0.5838\n",
            "Epoch 195/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6338 - accuracy: 0.5668 - categorical_accuracy: 0.5668 - val_loss: 0.6233 - val_accuracy: 0.6043 - val_categorical_accuracy: 0.6043\n",
            "Epoch 196/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6464 - accuracy: 0.5552 - categorical_accuracy: 0.5552 - val_loss: 0.6221 - val_accuracy: 0.6043 - val_categorical_accuracy: 0.6043\n",
            "Epoch 197/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6242 - accuracy: 0.5676 - categorical_accuracy: 0.5676 - val_loss: 0.6209 - val_accuracy: 0.6043 - val_categorical_accuracy: 0.6043\n",
            "Epoch 198/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6342 - accuracy: 0.5567 - categorical_accuracy: 0.5567 - val_loss: 0.6196 - val_accuracy: 0.6060 - val_categorical_accuracy: 0.6060\n",
            "Epoch 199/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6262 - accuracy: 0.5716 - categorical_accuracy: 0.5716 - val_loss: 0.6184 - val_accuracy: 0.6060 - val_categorical_accuracy: 0.6060\n",
            "Epoch 200/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6130 - accuracy: 0.5784 - categorical_accuracy: 0.5784 - val_loss: 0.6172 - val_accuracy: 0.6060 - val_categorical_accuracy: 0.6060\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.6172 - accuracy: 0.6060 - categorical_accuracy: 0.6060\n",
            "1142\n",
            "Generation-7 Chromosome-8:\n",
            "Middle layers: 2 | Activation: selu | Optimization: Adadelta | Loss: categorical_hinge | LR: 1e-05 | Dropout: 0.15 |\n",
            "\tScore 0.54  | Accuracy: 0.61\n",
            "Epoch 1/200\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.9775 - accuracy: 0.0460 - categorical_accuracy: 0.0460 - val_loss: 0.9557 - val_accuracy: 0.4111 - val_categorical_accuracy: 0.4111\n",
            "Epoch 2/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.9109 - accuracy: 0.4517 - categorical_accuracy: 0.4517 - val_loss: 0.7404 - val_accuracy: 0.4855 - val_categorical_accuracy: 0.4855\n",
            "Epoch 3/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.7439 - accuracy: 0.4939 - categorical_accuracy: 0.4939 - val_loss: 0.6919 - val_accuracy: 0.5120 - val_categorical_accuracy: 0.5120\n",
            "Epoch 4/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6831 - accuracy: 0.5184 - categorical_accuracy: 0.5184 - val_loss: 0.6667 - val_accuracy: 0.5274 - val_categorical_accuracy: 0.5274\n",
            "Epoch 5/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6622 - accuracy: 0.5172 - categorical_accuracy: 0.5172 - val_loss: 0.6429 - val_accuracy: 0.5479 - val_categorical_accuracy: 0.5479\n",
            "Epoch 6/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6339 - accuracy: 0.5663 - categorical_accuracy: 0.5663 - val_loss: 0.6083 - val_accuracy: 0.5684 - val_categorical_accuracy: 0.5684\n",
            "Epoch 7/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.5973 - accuracy: 0.5827 - categorical_accuracy: 0.5827 - val_loss: 0.5703 - val_accuracy: 0.5701 - val_categorical_accuracy: 0.5701\n",
            "Epoch 8/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.5629 - accuracy: 0.5699 - categorical_accuracy: 0.5699 - val_loss: 0.5368 - val_accuracy: 0.5829 - val_categorical_accuracy: 0.5829\n",
            "Epoch 9/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.5089 - accuracy: 0.5891 - categorical_accuracy: 0.5891 - val_loss: 0.5105 - val_accuracy: 0.5829 - val_categorical_accuracy: 0.5829\n",
            "Epoch 10/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.4992 - accuracy: 0.5713 - categorical_accuracy: 0.5713 - val_loss: 0.4947 - val_accuracy: 0.6085 - val_categorical_accuracy: 0.6085\n",
            "Epoch 11/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.4817 - accuracy: 0.5903 - categorical_accuracy: 0.5903 - val_loss: 0.4830 - val_accuracy: 0.6085 - val_categorical_accuracy: 0.6085\n",
            "Epoch 12/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.4686 - accuracy: 0.5979 - categorical_accuracy: 0.5979 - val_loss: 0.4694 - val_accuracy: 0.6103 - val_categorical_accuracy: 0.6103\n",
            "Epoch 13/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.4559 - accuracy: 0.5959 - categorical_accuracy: 0.5959 - val_loss: 0.4587 - val_accuracy: 0.6162 - val_categorical_accuracy: 0.6162\n",
            "Epoch 14/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.4526 - accuracy: 0.6191 - categorical_accuracy: 0.6191 - val_loss: 0.4517 - val_accuracy: 0.6162 - val_categorical_accuracy: 0.6162\n",
            "Epoch 15/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.4319 - accuracy: 0.6272 - categorical_accuracy: 0.6272 - val_loss: 0.4461 - val_accuracy: 0.6188 - val_categorical_accuracy: 0.6188\n",
            "Epoch 16/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.4261 - accuracy: 0.6327 - categorical_accuracy: 0.6327 - val_loss: 0.4408 - val_accuracy: 0.6368 - val_categorical_accuracy: 0.6368\n",
            "Epoch 17/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.4155 - accuracy: 0.6256 - categorical_accuracy: 0.6256 - val_loss: 0.4350 - val_accuracy: 0.6675 - val_categorical_accuracy: 0.6675\n",
            "Epoch 18/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.4088 - accuracy: 0.6691 - categorical_accuracy: 0.6691 - val_loss: 0.4281 - val_accuracy: 0.6675 - val_categorical_accuracy: 0.6675\n",
            "Epoch 19/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.4314 - accuracy: 0.6432 - categorical_accuracy: 0.6432 - val_loss: 0.4185 - val_accuracy: 0.6735 - val_categorical_accuracy: 0.6735\n",
            "Epoch 20/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.4086 - accuracy: 0.6587 - categorical_accuracy: 0.6587 - val_loss: 0.4059 - val_accuracy: 0.6735 - val_categorical_accuracy: 0.6735\n",
            "Epoch 21/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.3950 - accuracy: 0.6633 - categorical_accuracy: 0.6633 - val_loss: 0.3933 - val_accuracy: 0.6769 - val_categorical_accuracy: 0.6769\n",
            "Epoch 22/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.3747 - accuracy: 0.6797 - categorical_accuracy: 0.6797 - val_loss: 0.3835 - val_accuracy: 0.6983 - val_categorical_accuracy: 0.6983\n",
            "Epoch 23/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.3649 - accuracy: 0.6866 - categorical_accuracy: 0.6866 - val_loss: 0.3742 - val_accuracy: 0.6991 - val_categorical_accuracy: 0.6991\n",
            "Epoch 24/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.3726 - accuracy: 0.6781 - categorical_accuracy: 0.6781 - val_loss: 0.3652 - val_accuracy: 0.7017 - val_categorical_accuracy: 0.7017\n",
            "Epoch 25/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.3426 - accuracy: 0.6788 - categorical_accuracy: 0.6788 - val_loss: 0.3558 - val_accuracy: 0.7017 - val_categorical_accuracy: 0.7017\n",
            "Epoch 26/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.3456 - accuracy: 0.6912 - categorical_accuracy: 0.6912 - val_loss: 0.3475 - val_accuracy: 0.7017 - val_categorical_accuracy: 0.7017\n",
            "Epoch 27/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.3305 - accuracy: 0.6810 - categorical_accuracy: 0.6810 - val_loss: 0.3402 - val_accuracy: 0.7017 - val_categorical_accuracy: 0.7017\n",
            "Epoch 28/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.3298 - accuracy: 0.6867 - categorical_accuracy: 0.6867 - val_loss: 0.3333 - val_accuracy: 0.7017 - val_categorical_accuracy: 0.7017\n",
            "Epoch 29/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.3193 - accuracy: 0.6854 - categorical_accuracy: 0.6854 - val_loss: 0.3269 - val_accuracy: 0.7017 - val_categorical_accuracy: 0.7017\n",
            "Epoch 30/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.3143 - accuracy: 0.6828 - categorical_accuracy: 0.6828 - val_loss: 0.3210 - val_accuracy: 0.7017 - val_categorical_accuracy: 0.7017\n",
            "Epoch 31/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.3135 - accuracy: 0.6807 - categorical_accuracy: 0.6807 - val_loss: 0.3158 - val_accuracy: 0.7017 - val_categorical_accuracy: 0.7017\n",
            "Epoch 32/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.3033 - accuracy: 0.6837 - categorical_accuracy: 0.6837 - val_loss: 0.3107 - val_accuracy: 0.7017 - val_categorical_accuracy: 0.7017\n",
            "Epoch 33/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.2950 - accuracy: 0.6774 - categorical_accuracy: 0.6774 - val_loss: 0.3048 - val_accuracy: 0.7017 - val_categorical_accuracy: 0.7017\n",
            "Epoch 34/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.2854 - accuracy: 0.6873 - categorical_accuracy: 0.6873 - val_loss: 0.2978 - val_accuracy: 0.7017 - val_categorical_accuracy: 0.7017\n",
            "Epoch 35/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.3189 - accuracy: 0.6721 - categorical_accuracy: 0.6721 - val_loss: 0.2888 - val_accuracy: 0.7017 - val_categorical_accuracy: 0.7017\n",
            "Epoch 36/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.2608 - accuracy: 0.6892 - categorical_accuracy: 0.6892 - val_loss: 0.2785 - val_accuracy: 0.7017 - val_categorical_accuracy: 0.7017\n",
            "Epoch 37/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.2628 - accuracy: 0.6866 - categorical_accuracy: 0.6866 - val_loss: 0.2688 - val_accuracy: 0.7017 - val_categorical_accuracy: 0.7017\n",
            "Epoch 38/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.2620 - accuracy: 0.6858 - categorical_accuracy: 0.6858 - val_loss: 0.2595 - val_accuracy: 0.7017 - val_categorical_accuracy: 0.7017\n",
            "Epoch 39/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.2628 - accuracy: 0.6758 - categorical_accuracy: 0.6758 - val_loss: 0.2506 - val_accuracy: 0.7017 - val_categorical_accuracy: 0.7017\n",
            "Epoch 40/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.2382 - accuracy: 0.6956 - categorical_accuracy: 0.6956 - val_loss: 0.2412 - val_accuracy: 0.7017 - val_categorical_accuracy: 0.7017\n",
            "Epoch 41/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.2383 - accuracy: 0.6875 - categorical_accuracy: 0.6875 - val_loss: 0.2317 - val_accuracy: 0.7171 - val_categorical_accuracy: 0.7171\n",
            "Epoch 42/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.2307 - accuracy: 0.6974 - categorical_accuracy: 0.6974 - val_loss: 0.2229 - val_accuracy: 0.7171 - val_categorical_accuracy: 0.7171\n",
            "Epoch 43/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.2237 - accuracy: 0.6895 - categorical_accuracy: 0.6895 - val_loss: 0.2133 - val_accuracy: 0.7171 - val_categorical_accuracy: 0.7171\n",
            "Epoch 44/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.2230 - accuracy: 0.7010 - categorical_accuracy: 0.7010 - val_loss: 0.2051 - val_accuracy: 0.7171 - val_categorical_accuracy: 0.7171\n",
            "Epoch 45/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1879 - accuracy: 0.7077 - categorical_accuracy: 0.7077 - val_loss: 0.1969 - val_accuracy: 0.7197 - val_categorical_accuracy: 0.7197\n",
            "Epoch 46/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.2005 - accuracy: 0.7107 - categorical_accuracy: 0.7107 - val_loss: 0.1897 - val_accuracy: 0.7197 - val_categorical_accuracy: 0.7197\n",
            "Epoch 47/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.2060 - accuracy: 0.6961 - categorical_accuracy: 0.6961 - val_loss: 0.1833 - val_accuracy: 0.7197 - val_categorical_accuracy: 0.7197\n",
            "Epoch 48/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1902 - accuracy: 0.6956 - categorical_accuracy: 0.6956 - val_loss: 0.1778 - val_accuracy: 0.7197 - val_categorical_accuracy: 0.7197\n",
            "Epoch 49/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1768 - accuracy: 0.7004 - categorical_accuracy: 0.7004 - val_loss: 0.1729 - val_accuracy: 0.7214 - val_categorical_accuracy: 0.7214\n",
            "Epoch 50/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1870 - accuracy: 0.6924 - categorical_accuracy: 0.6924 - val_loss: 0.1695 - val_accuracy: 0.7188 - val_categorical_accuracy: 0.7188\n",
            "Epoch 51/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1788 - accuracy: 0.7131 - categorical_accuracy: 0.7131 - val_loss: 0.1662 - val_accuracy: 0.7188 - val_categorical_accuracy: 0.7188\n",
            "Epoch 52/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1678 - accuracy: 0.7002 - categorical_accuracy: 0.7002 - val_loss: 0.1631 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 53/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1796 - accuracy: 0.6842 - categorical_accuracy: 0.6842 - val_loss: 0.1606 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 54/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1763 - accuracy: 0.6881 - categorical_accuracy: 0.6881 - val_loss: 0.1589 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 55/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1703 - accuracy: 0.7032 - categorical_accuracy: 0.7032 - val_loss: 0.1569 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 56/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1535 - accuracy: 0.7300 - categorical_accuracy: 0.7300 - val_loss: 0.1554 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 57/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1583 - accuracy: 0.7095 - categorical_accuracy: 0.7095 - val_loss: 0.1537 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 58/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1617 - accuracy: 0.7096 - categorical_accuracy: 0.7096 - val_loss: 0.1530 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 59/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1621 - accuracy: 0.7135 - categorical_accuracy: 0.7135 - val_loss: 0.1512 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 60/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1498 - accuracy: 0.7148 - categorical_accuracy: 0.7148 - val_loss: 0.1503 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 61/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1535 - accuracy: 0.7088 - categorical_accuracy: 0.7088 - val_loss: 0.1486 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 62/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1504 - accuracy: 0.7114 - categorical_accuracy: 0.7114 - val_loss: 0.1477 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 63/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1301 - accuracy: 0.7200 - categorical_accuracy: 0.7200 - val_loss: 0.1461 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 64/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1582 - accuracy: 0.7019 - categorical_accuracy: 0.7019 - val_loss: 0.1447 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 65/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1541 - accuracy: 0.7076 - categorical_accuracy: 0.7076 - val_loss: 0.1436 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 66/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1466 - accuracy: 0.7003 - categorical_accuracy: 0.7003 - val_loss: 0.1418 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 67/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1410 - accuracy: 0.7232 - categorical_accuracy: 0.7232 - val_loss: 0.1400 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 68/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1461 - accuracy: 0.7206 - categorical_accuracy: 0.7206 - val_loss: 0.1385 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 69/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1568 - accuracy: 0.6946 - categorical_accuracy: 0.6946 - val_loss: 0.1367 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 70/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1295 - accuracy: 0.7141 - categorical_accuracy: 0.7141 - val_loss: 0.1348 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 71/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1378 - accuracy: 0.7072 - categorical_accuracy: 0.7072 - val_loss: 0.1333 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 72/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1330 - accuracy: 0.7092 - categorical_accuracy: 0.7092 - val_loss: 0.1315 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 73/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1287 - accuracy: 0.7178 - categorical_accuracy: 0.7178 - val_loss: 0.1302 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 74/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1310 - accuracy: 0.7089 - categorical_accuracy: 0.7089 - val_loss: 0.1289 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 75/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1398 - accuracy: 0.7039 - categorical_accuracy: 0.7039 - val_loss: 0.1283 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 76/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1454 - accuracy: 0.7046 - categorical_accuracy: 0.7046 - val_loss: 0.1267 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 77/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1293 - accuracy: 0.7062 - categorical_accuracy: 0.7062 - val_loss: 0.1254 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 78/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1335 - accuracy: 0.7060 - categorical_accuracy: 0.7060 - val_loss: 0.1247 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 79/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1112 - accuracy: 0.7201 - categorical_accuracy: 0.7201 - val_loss: 0.1236 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 80/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1173 - accuracy: 0.7251 - categorical_accuracy: 0.7251 - val_loss: 0.1230 - val_accuracy: 0.7274 - val_categorical_accuracy: 0.7274\n",
            "Epoch 81/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1371 - accuracy: 0.6977 - categorical_accuracy: 0.6977 - val_loss: 0.1220 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 82/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1178 - accuracy: 0.7143 - categorical_accuracy: 0.7143 - val_loss: 0.1212 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 83/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1180 - accuracy: 0.7168 - categorical_accuracy: 0.7168 - val_loss: 0.1207 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 84/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1225 - accuracy: 0.7038 - categorical_accuracy: 0.7038 - val_loss: 0.1198 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 85/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1201 - accuracy: 0.7129 - categorical_accuracy: 0.7129 - val_loss: 0.1189 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 86/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1136 - accuracy: 0.7162 - categorical_accuracy: 0.7162 - val_loss: 0.1183 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 87/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1131 - accuracy: 0.7010 - categorical_accuracy: 0.7010 - val_loss: 0.1171 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 88/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1235 - accuracy: 0.7128 - categorical_accuracy: 0.7128 - val_loss: 0.1163 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 89/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1187 - accuracy: 0.7185 - categorical_accuracy: 0.7185 - val_loss: 0.1154 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 90/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1167 - accuracy: 0.7109 - categorical_accuracy: 0.7109 - val_loss: 0.1144 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 91/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1173 - accuracy: 0.7095 - categorical_accuracy: 0.7095 - val_loss: 0.1131 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 92/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1138 - accuracy: 0.7049 - categorical_accuracy: 0.7049 - val_loss: 0.1121 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 93/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1072 - accuracy: 0.7155 - categorical_accuracy: 0.7155 - val_loss: 0.1107 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 94/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0999 - accuracy: 0.7146 - categorical_accuracy: 0.7146 - val_loss: 0.1096 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 95/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1072 - accuracy: 0.7090 - categorical_accuracy: 0.7090 - val_loss: 0.1086 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 96/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1055 - accuracy: 0.7147 - categorical_accuracy: 0.7147 - val_loss: 0.1075 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 97/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1080 - accuracy: 0.7106 - categorical_accuracy: 0.7106 - val_loss: 0.1065 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 98/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1006 - accuracy: 0.7174 - categorical_accuracy: 0.7174 - val_loss: 0.1057 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 99/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1072 - accuracy: 0.7056 - categorical_accuracy: 0.7056 - val_loss: 0.1051 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 100/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0943 - accuracy: 0.7168 - categorical_accuracy: 0.7168 - val_loss: 0.1044 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 101/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0955 - accuracy: 0.7196 - categorical_accuracy: 0.7196 - val_loss: 0.1032 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 102/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1009 - accuracy: 0.7246 - categorical_accuracy: 0.7246 - val_loss: 0.1019 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 103/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0972 - accuracy: 0.7250 - categorical_accuracy: 0.7250 - val_loss: 0.1017 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 104/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0944 - accuracy: 0.7052 - categorical_accuracy: 0.7052 - val_loss: 0.1011 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 105/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0882 - accuracy: 0.7252 - categorical_accuracy: 0.7252 - val_loss: 0.1008 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 106/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0972 - accuracy: 0.7191 - categorical_accuracy: 0.7191 - val_loss: 0.1006 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 107/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0977 - accuracy: 0.7107 - categorical_accuracy: 0.7107 - val_loss: 0.1003 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 108/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0926 - accuracy: 0.7140 - categorical_accuracy: 0.7140 - val_loss: 0.1000 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 109/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0923 - accuracy: 0.7164 - categorical_accuracy: 0.7164 - val_loss: 0.0995 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 110/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0882 - accuracy: 0.7111 - categorical_accuracy: 0.7111 - val_loss: 0.0994 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 111/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1000 - accuracy: 0.7087 - categorical_accuracy: 0.7087 - val_loss: 0.0994 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 112/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0934 - accuracy: 0.7041 - categorical_accuracy: 0.7041 - val_loss: 0.0990 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 113/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1030 - accuracy: 0.6890 - categorical_accuracy: 0.6890 - val_loss: 0.0990 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 114/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0888 - accuracy: 0.7126 - categorical_accuracy: 0.7126 - val_loss: 0.0986 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 115/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0940 - accuracy: 0.7114 - categorical_accuracy: 0.7114 - val_loss: 0.0986 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 116/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0855 - accuracy: 0.7163 - categorical_accuracy: 0.7163 - val_loss: 0.0984 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 117/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0911 - accuracy: 0.7039 - categorical_accuracy: 0.7039 - val_loss: 0.0982 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 118/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0929 - accuracy: 0.7139 - categorical_accuracy: 0.7139 - val_loss: 0.0981 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 119/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0915 - accuracy: 0.7124 - categorical_accuracy: 0.7124 - val_loss: 0.0981 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 120/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0871 - accuracy: 0.7096 - categorical_accuracy: 0.7096 - val_loss: 0.0979 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 121/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0916 - accuracy: 0.7174 - categorical_accuracy: 0.7174 - val_loss: 0.0978 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 122/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0952 - accuracy: 0.7120 - categorical_accuracy: 0.7120 - val_loss: 0.0977 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 123/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0922 - accuracy: 0.7086 - categorical_accuracy: 0.7086 - val_loss: 0.0977 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 124/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1031 - accuracy: 0.7200 - categorical_accuracy: 0.7200 - val_loss: 0.0977 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 125/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0860 - accuracy: 0.7224 - categorical_accuracy: 0.7224 - val_loss: 0.0976 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 126/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0868 - accuracy: 0.7318 - categorical_accuracy: 0.7318 - val_loss: 0.0975 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 127/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0891 - accuracy: 0.7207 - categorical_accuracy: 0.7207 - val_loss: 0.0974 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 128/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0869 - accuracy: 0.7172 - categorical_accuracy: 0.7172 - val_loss: 0.0974 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 129/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0781 - accuracy: 0.7183 - categorical_accuracy: 0.7183 - val_loss: 0.0972 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 130/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0930 - accuracy: 0.7141 - categorical_accuracy: 0.7141 - val_loss: 0.0970 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 131/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0909 - accuracy: 0.7144 - categorical_accuracy: 0.7144 - val_loss: 0.0971 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 132/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0772 - accuracy: 0.7179 - categorical_accuracy: 0.7179 - val_loss: 0.0968 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 133/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0795 - accuracy: 0.7157 - categorical_accuracy: 0.7157 - val_loss: 0.0969 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 134/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0828 - accuracy: 0.7244 - categorical_accuracy: 0.7244 - val_loss: 0.0969 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 135/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1011 - accuracy: 0.7095 - categorical_accuracy: 0.7095 - val_loss: 0.0967 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 136/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0949 - accuracy: 0.7214 - categorical_accuracy: 0.7214 - val_loss: 0.0968 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 137/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0824 - accuracy: 0.7231 - categorical_accuracy: 0.7231 - val_loss: 0.0967 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 138/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0828 - accuracy: 0.7169 - categorical_accuracy: 0.7169 - val_loss: 0.0966 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 139/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0798 - accuracy: 0.7158 - categorical_accuracy: 0.7158 - val_loss: 0.0965 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 140/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0879 - accuracy: 0.7112 - categorical_accuracy: 0.7112 - val_loss: 0.0966 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 141/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0810 - accuracy: 0.7075 - categorical_accuracy: 0.7075 - val_loss: 0.0964 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 142/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1051 - accuracy: 0.7098 - categorical_accuracy: 0.7098 - val_loss: 0.0965 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 143/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0863 - accuracy: 0.7129 - categorical_accuracy: 0.7129 - val_loss: 0.0963 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 144/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1006 - accuracy: 0.7075 - categorical_accuracy: 0.7075 - val_loss: 0.0963 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 145/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0925 - accuracy: 0.7259 - categorical_accuracy: 0.7259 - val_loss: 0.0962 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 146/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0892 - accuracy: 0.7169 - categorical_accuracy: 0.7169 - val_loss: 0.0962 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 147/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0918 - accuracy: 0.7119 - categorical_accuracy: 0.7119 - val_loss: 0.0962 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 148/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0990 - accuracy: 0.7128 - categorical_accuracy: 0.7128 - val_loss: 0.0960 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 149/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0815 - accuracy: 0.7142 - categorical_accuracy: 0.7142 - val_loss: 0.0959 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 150/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0868 - accuracy: 0.7130 - categorical_accuracy: 0.7130 - val_loss: 0.0959 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 151/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.1019 - accuracy: 0.6968 - categorical_accuracy: 0.6968 - val_loss: 0.0959 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 152/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0969 - accuracy: 0.7167 - categorical_accuracy: 0.7167 - val_loss: 0.0959 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 153/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0930 - accuracy: 0.7089 - categorical_accuracy: 0.7089 - val_loss: 0.0957 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 154/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0893 - accuracy: 0.7078 - categorical_accuracy: 0.7078 - val_loss: 0.0960 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 155/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0904 - accuracy: 0.7143 - categorical_accuracy: 0.7143 - val_loss: 0.0958 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 156/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0927 - accuracy: 0.7068 - categorical_accuracy: 0.7068 - val_loss: 0.0959 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 157/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0858 - accuracy: 0.7179 - categorical_accuracy: 0.7179 - val_loss: 0.0957 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 158/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0848 - accuracy: 0.7272 - categorical_accuracy: 0.7272 - val_loss: 0.0957 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 159/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0959 - accuracy: 0.7066 - categorical_accuracy: 0.7066 - val_loss: 0.0957 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 160/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0787 - accuracy: 0.7261 - categorical_accuracy: 0.7261 - val_loss: 0.0958 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 161/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0878 - accuracy: 0.7115 - categorical_accuracy: 0.7115 - val_loss: 0.0954 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 162/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0953 - accuracy: 0.7089 - categorical_accuracy: 0.7089 - val_loss: 0.0954 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 163/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0966 - accuracy: 0.7072 - categorical_accuracy: 0.7072 - val_loss: 0.0954 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 164/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0860 - accuracy: 0.7221 - categorical_accuracy: 0.7221 - val_loss: 0.0956 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 165/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0885 - accuracy: 0.7015 - categorical_accuracy: 0.7015 - val_loss: 0.0956 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 166/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0867 - accuracy: 0.7111 - categorical_accuracy: 0.7111 - val_loss: 0.0953 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 167/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0807 - accuracy: 0.7237 - categorical_accuracy: 0.7237 - val_loss: 0.0953 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 168/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0857 - accuracy: 0.7090 - categorical_accuracy: 0.7090 - val_loss: 0.0955 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 169/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0818 - accuracy: 0.7067 - categorical_accuracy: 0.7067 - val_loss: 0.0953 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 170/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0939 - accuracy: 0.7004 - categorical_accuracy: 0.7004 - val_loss: 0.0953 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 171/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0927 - accuracy: 0.7115 - categorical_accuracy: 0.7115 - val_loss: 0.0951 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 172/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0947 - accuracy: 0.7078 - categorical_accuracy: 0.7078 - val_loss: 0.0952 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 173/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0882 - accuracy: 0.7146 - categorical_accuracy: 0.7146 - val_loss: 0.0950 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 174/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0871 - accuracy: 0.7158 - categorical_accuracy: 0.7158 - val_loss: 0.0950 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 175/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0872 - accuracy: 0.7146 - categorical_accuracy: 0.7146 - val_loss: 0.0950 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 176/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0810 - accuracy: 0.7195 - categorical_accuracy: 0.7195 - val_loss: 0.0951 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 177/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0933 - accuracy: 0.7154 - categorical_accuracy: 0.7154 - val_loss: 0.0950 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 178/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0906 - accuracy: 0.7040 - categorical_accuracy: 0.7040 - val_loss: 0.0951 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 179/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0859 - accuracy: 0.7100 - categorical_accuracy: 0.7100 - val_loss: 0.0948 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 180/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0847 - accuracy: 0.7245 - categorical_accuracy: 0.7245 - val_loss: 0.0948 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 181/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0994 - accuracy: 0.7061 - categorical_accuracy: 0.7061 - val_loss: 0.0949 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 182/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0904 - accuracy: 0.7133 - categorical_accuracy: 0.7133 - val_loss: 0.0946 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 183/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0833 - accuracy: 0.7090 - categorical_accuracy: 0.7090 - val_loss: 0.0948 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 184/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0903 - accuracy: 0.7218 - categorical_accuracy: 0.7218 - val_loss: 0.0947 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 185/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0856 - accuracy: 0.7185 - categorical_accuracy: 0.7185 - val_loss: 0.0948 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 186/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0928 - accuracy: 0.7158 - categorical_accuracy: 0.7158 - val_loss: 0.0945 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 187/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1033 - accuracy: 0.7187 - categorical_accuracy: 0.7187 - val_loss: 0.0945 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 188/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0951 - accuracy: 0.7208 - categorical_accuracy: 0.7208 - val_loss: 0.0945 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 189/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0835 - accuracy: 0.7173 - categorical_accuracy: 0.7173 - val_loss: 0.0949 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 190/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0827 - accuracy: 0.6997 - categorical_accuracy: 0.6997 - val_loss: 0.0945 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 191/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0922 - accuracy: 0.7090 - categorical_accuracy: 0.7090 - val_loss: 0.0945 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 192/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0963 - accuracy: 0.7213 - categorical_accuracy: 0.7213 - val_loss: 0.0945 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 193/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0925 - accuracy: 0.7082 - categorical_accuracy: 0.7082 - val_loss: 0.0945 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 194/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0821 - accuracy: 0.7202 - categorical_accuracy: 0.7202 - val_loss: 0.0943 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 195/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0986 - accuracy: 0.7134 - categorical_accuracy: 0.7134 - val_loss: 0.0943 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 196/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1021 - accuracy: 0.7175 - categorical_accuracy: 0.7175 - val_loss: 0.0943 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 197/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.1110 - accuracy: 0.7042 - categorical_accuracy: 0.7042 - val_loss: 0.0944 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 198/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0899 - accuracy: 0.7136 - categorical_accuracy: 0.7136 - val_loss: 0.0944 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 199/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0972 - accuracy: 0.7066 - categorical_accuracy: 0.7066 - val_loss: 0.0943 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "Epoch 200/200\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.0971 - accuracy: 0.6951 - categorical_accuracy: 0.6951 - val_loss: 0.0941 - val_accuracy: 0.7299 - val_categorical_accuracy: 0.7299\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0941 - accuracy: 0.7299 - categorical_accuracy: 0.7299\n",
            "1102\n",
            "Generation-7 Chromosome-9:\n",
            "Middle layers: 1 | Activation: selu | Optimization: Adadelta | Loss: categorical_hinge | LR: 0.001 | Dropout: 0.15 |\n",
            "\tScore 0.65  | Accuracy: 0.73\n",
            "Epoch 1/200\n",
            "351/351 [==============================] - 6s 14ms/step - loss: 20.3523 - accuracy: 0.0785 - categorical_accuracy: 0.0785 - val_loss: 18.3687 - val_accuracy: 0.4256 - val_categorical_accuracy: 0.4256\n",
            "Epoch 2/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 18.5305 - accuracy: 0.3986 - categorical_accuracy: 0.3986 - val_loss: 17.6170 - val_accuracy: 0.5000 - val_categorical_accuracy: 0.5000\n",
            "Epoch 3/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 17.7999 - accuracy: 0.4682 - categorical_accuracy: 0.4682 - val_loss: 17.2949 - val_accuracy: 0.5744 - val_categorical_accuracy: 0.5744\n",
            "Epoch 4/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 17.5517 - accuracy: 0.5047 - categorical_accuracy: 0.5047 - val_loss: 17.0344 - val_accuracy: 0.5829 - val_categorical_accuracy: 0.5829\n",
            "Epoch 5/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 17.3975 - accuracy: 0.5240 - categorical_accuracy: 0.5240 - val_loss: 16.8195 - val_accuracy: 0.5658 - val_categorical_accuracy: 0.5658\n",
            "Epoch 6/200\n",
            "351/351 [==============================] - 5s 13ms/step - loss: 17.1952 - accuracy: 0.5439 - categorical_accuracy: 0.5439 - val_loss: 16.6699 - val_accuracy: 0.5915 - val_categorical_accuracy: 0.5915\n",
            "Epoch 7/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 16.9572 - accuracy: 0.5664 - categorical_accuracy: 0.5664 - val_loss: 16.5579 - val_accuracy: 0.5983 - val_categorical_accuracy: 0.5983\n",
            "Epoch 8/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 16.4839 - accuracy: 0.5755 - categorical_accuracy: 0.5755 - val_loss: 16.4762 - val_accuracy: 0.6145 - val_categorical_accuracy: 0.6145\n",
            "Epoch 9/200\n",
            "351/351 [==============================] - 5s 13ms/step - loss: 16.3473 - accuracy: 0.5960 - categorical_accuracy: 0.5960 - val_loss: 16.4360 - val_accuracy: 0.6051 - val_categorical_accuracy: 0.6051\n",
            "Epoch 10/200\n",
            "351/351 [==============================] - 5s 13ms/step - loss: 16.7071 - accuracy: 0.5855 - categorical_accuracy: 0.5855 - val_loss: 16.4385 - val_accuracy: 0.6359 - val_categorical_accuracy: 0.6359\n",
            "Epoch 11/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 16.6152 - accuracy: 0.6029 - categorical_accuracy: 0.6029 - val_loss: 16.4849 - val_accuracy: 0.6462 - val_categorical_accuracy: 0.6462\n",
            "Epoch 12/200\n",
            "351/351 [==============================] - 5s 13ms/step - loss: 16.4252 - accuracy: 0.5997 - categorical_accuracy: 0.5997 - val_loss: 16.5626 - val_accuracy: 0.6342 - val_categorical_accuracy: 0.6342\n",
            "Epoch 13/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 16.5092 - accuracy: 0.6188 - categorical_accuracy: 0.6188 - val_loss: 16.6838 - val_accuracy: 0.6325 - val_categorical_accuracy: 0.6325\n",
            "Epoch 14/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 16.4624 - accuracy: 0.6213 - categorical_accuracy: 0.6213 - val_loss: 16.8565 - val_accuracy: 0.6274 - val_categorical_accuracy: 0.6274\n",
            "Epoch 15/200\n",
            "351/351 [==============================] - 5s 13ms/step - loss: 16.8324 - accuracy: 0.6156 - categorical_accuracy: 0.6156 - val_loss: 17.0430 - val_accuracy: 0.6282 - val_categorical_accuracy: 0.6282\n",
            "Epoch 16/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 16.9140 - accuracy: 0.6187 - categorical_accuracy: 0.6187 - val_loss: 17.2531 - val_accuracy: 0.6026 - val_categorical_accuracy: 0.6026\n",
            "Epoch 17/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 16.8983 - accuracy: 0.6300 - categorical_accuracy: 0.6300 - val_loss: 17.5065 - val_accuracy: 0.6017 - val_categorical_accuracy: 0.6017\n",
            "Epoch 18/200\n",
            "351/351 [==============================] - 5s 13ms/step - loss: 17.5015 - accuracy: 0.6143 - categorical_accuracy: 0.6143 - val_loss: 17.8153 - val_accuracy: 0.6043 - val_categorical_accuracy: 0.6043\n",
            "Epoch 19/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 17.6458 - accuracy: 0.6225 - categorical_accuracy: 0.6225 - val_loss: 18.1345 - val_accuracy: 0.6043 - val_categorical_accuracy: 0.6043\n",
            "Epoch 20/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 17.8794 - accuracy: 0.5964 - categorical_accuracy: 0.5964 - val_loss: 18.4707 - val_accuracy: 0.6043 - val_categorical_accuracy: 0.6043\n",
            "Epoch 21/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 18.5833 - accuracy: 0.6012 - categorical_accuracy: 0.6012 - val_loss: 18.8482 - val_accuracy: 0.6043 - val_categorical_accuracy: 0.6043\n",
            "Epoch 22/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 18.8566 - accuracy: 0.5978 - categorical_accuracy: 0.5978 - val_loss: 19.2316 - val_accuracy: 0.6017 - val_categorical_accuracy: 0.6017\n",
            "Epoch 23/200\n",
            "351/351 [==============================] - 5s 13ms/step - loss: 18.9565 - accuracy: 0.6065 - categorical_accuracy: 0.6065 - val_loss: 19.6340 - val_accuracy: 0.6017 - val_categorical_accuracy: 0.6017\n",
            "Epoch 24/200\n",
            "351/351 [==============================] - 5s 13ms/step - loss: 19.3711 - accuracy: 0.6093 - categorical_accuracy: 0.6093 - val_loss: 20.0712 - val_accuracy: 0.6017 - val_categorical_accuracy: 0.6017\n",
            "Epoch 25/200\n",
            "351/351 [==============================] - 5s 13ms/step - loss: 20.3501 - accuracy: 0.6022 - categorical_accuracy: 0.6022 - val_loss: 20.5527 - val_accuracy: 0.6017 - val_categorical_accuracy: 0.6017\n",
            "Epoch 26/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 20.3435 - accuracy: 0.5904 - categorical_accuracy: 0.5904 - val_loss: 21.0652 - val_accuracy: 0.6103 - val_categorical_accuracy: 0.6103\n",
            "Epoch 27/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 20.6894 - accuracy: 0.6193 - categorical_accuracy: 0.6193 - val_loss: 21.5726 - val_accuracy: 0.6085 - val_categorical_accuracy: 0.6085\n",
            "Epoch 28/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 21.7025 - accuracy: 0.5963 - categorical_accuracy: 0.5963 - val_loss: 22.1037 - val_accuracy: 0.6103 - val_categorical_accuracy: 0.6103\n",
            "Epoch 29/200\n",
            "351/351 [==============================] - 5s 13ms/step - loss: 22.3382 - accuracy: 0.5944 - categorical_accuracy: 0.5944 - val_loss: 22.6593 - val_accuracy: 0.6248 - val_categorical_accuracy: 0.6248\n",
            "Epoch 30/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 22.5066 - accuracy: 0.6090 - categorical_accuracy: 0.6090 - val_loss: 23.2491 - val_accuracy: 0.6248 - val_categorical_accuracy: 0.6248\n",
            "Epoch 31/200\n",
            "351/351 [==============================] - 5s 13ms/step - loss: 23.1346 - accuracy: 0.6021 - categorical_accuracy: 0.6021 - val_loss: 23.8658 - val_accuracy: 0.6111 - val_categorical_accuracy: 0.6111\n",
            "Epoch 32/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 24.2379 - accuracy: 0.5918 - categorical_accuracy: 0.5918 - val_loss: 24.4951 - val_accuracy: 0.6103 - val_categorical_accuracy: 0.6103\n",
            "Epoch 33/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 23.7105 - accuracy: 0.6005 - categorical_accuracy: 0.6005 - val_loss: 25.1156 - val_accuracy: 0.6103 - val_categorical_accuracy: 0.6103\n",
            "Epoch 34/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 24.9418 - accuracy: 0.5854 - categorical_accuracy: 0.5854 - val_loss: 25.7865 - val_accuracy: 0.6051 - val_categorical_accuracy: 0.6051\n",
            "Epoch 35/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 25.4386 - accuracy: 0.6006 - categorical_accuracy: 0.6006 - val_loss: 26.5053 - val_accuracy: 0.6060 - val_categorical_accuracy: 0.6060\n",
            "Epoch 36/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 25.7300 - accuracy: 0.5975 - categorical_accuracy: 0.5975 - val_loss: 27.2200 - val_accuracy: 0.6145 - val_categorical_accuracy: 0.6145\n",
            "Epoch 37/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 27.1461 - accuracy: 0.5778 - categorical_accuracy: 0.5778 - val_loss: 27.9942 - val_accuracy: 0.6291 - val_categorical_accuracy: 0.6291\n",
            "Epoch 38/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 27.0287 - accuracy: 0.5850 - categorical_accuracy: 0.5850 - val_loss: 28.7027 - val_accuracy: 0.6085 - val_categorical_accuracy: 0.6085\n",
            "Epoch 39/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 28.1957 - accuracy: 0.5760 - categorical_accuracy: 0.5760 - val_loss: 29.5037 - val_accuracy: 0.6291 - val_categorical_accuracy: 0.6291\n",
            "Epoch 40/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 29.2676 - accuracy: 0.5738 - categorical_accuracy: 0.5738 - val_loss: 30.3071 - val_accuracy: 0.6299 - val_categorical_accuracy: 0.6299\n",
            "Epoch 41/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 30.0628 - accuracy: 0.5868 - categorical_accuracy: 0.5868 - val_loss: 31.1377 - val_accuracy: 0.6658 - val_categorical_accuracy: 0.6658\n",
            "Epoch 42/200\n",
            "351/351 [==============================] - 5s 13ms/step - loss: 31.1601 - accuracy: 0.5770 - categorical_accuracy: 0.5770 - val_loss: 31.9868 - val_accuracy: 0.6675 - val_categorical_accuracy: 0.6675\n",
            "Epoch 43/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 31.5081 - accuracy: 0.5864 - categorical_accuracy: 0.5864 - val_loss: 32.8293 - val_accuracy: 0.6521 - val_categorical_accuracy: 0.6521\n",
            "Epoch 44/200\n",
            "351/351 [==============================] - 5s 13ms/step - loss: 32.6128 - accuracy: 0.5826 - categorical_accuracy: 0.5826 - val_loss: 33.7620 - val_accuracy: 0.6547 - val_categorical_accuracy: 0.6547\n",
            "Epoch 45/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 33.6627 - accuracy: 0.5906 - categorical_accuracy: 0.5906 - val_loss: 34.6844 - val_accuracy: 0.6684 - val_categorical_accuracy: 0.6684\n",
            "Epoch 46/200\n",
            "351/351 [==============================] - 5s 13ms/step - loss: 35.3317 - accuracy: 0.6034 - categorical_accuracy: 0.6034 - val_loss: 35.5600 - val_accuracy: 0.6504 - val_categorical_accuracy: 0.6504\n",
            "Epoch 47/200\n",
            "351/351 [==============================] - 5s 13ms/step - loss: 35.8931 - accuracy: 0.5748 - categorical_accuracy: 0.5748 - val_loss: 36.5224 - val_accuracy: 0.6504 - val_categorical_accuracy: 0.6504\n",
            "Epoch 48/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 35.5627 - accuracy: 0.5708 - categorical_accuracy: 0.5708 - val_loss: 37.5348 - val_accuracy: 0.6342 - val_categorical_accuracy: 0.6342\n",
            "Epoch 49/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 38.0006 - accuracy: 0.5844 - categorical_accuracy: 0.5844 - val_loss: 38.5381 - val_accuracy: 0.6342 - val_categorical_accuracy: 0.6342\n",
            "Epoch 50/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 38.6482 - accuracy: 0.5853 - categorical_accuracy: 0.5853 - val_loss: 39.6382 - val_accuracy: 0.6521 - val_categorical_accuracy: 0.6521\n",
            "Epoch 51/200\n",
            "351/351 [==============================] - 5s 13ms/step - loss: 38.9308 - accuracy: 0.5819 - categorical_accuracy: 0.5819 - val_loss: 40.6484 - val_accuracy: 0.6179 - val_categorical_accuracy: 0.6179\n",
            "Epoch 52/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 40.7676 - accuracy: 0.5793 - categorical_accuracy: 0.5793 - val_loss: 41.7973 - val_accuracy: 0.6650 - val_categorical_accuracy: 0.6650\n",
            "Epoch 53/200\n",
            "351/351 [==============================] - 5s 13ms/step - loss: 43.4055 - accuracy: 0.5781 - categorical_accuracy: 0.5781 - val_loss: 42.9215 - val_accuracy: 0.6359 - val_categorical_accuracy: 0.6359\n",
            "Epoch 54/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 42.3167 - accuracy: 0.5815 - categorical_accuracy: 0.5815 - val_loss: 43.9976 - val_accuracy: 0.6291 - val_categorical_accuracy: 0.6291\n",
            "Epoch 55/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 43.8732 - accuracy: 0.5592 - categorical_accuracy: 0.5592 - val_loss: 45.2962 - val_accuracy: 0.6701 - val_categorical_accuracy: 0.6701\n",
            "Epoch 56/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 43.9835 - accuracy: 0.5867 - categorical_accuracy: 0.5867 - val_loss: 46.3874 - val_accuracy: 0.6385 - val_categorical_accuracy: 0.6385\n",
            "Epoch 57/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 45.9675 - accuracy: 0.5781 - categorical_accuracy: 0.5781 - val_loss: 47.6621 - val_accuracy: 0.6726 - val_categorical_accuracy: 0.6726\n",
            "Epoch 58/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 46.5821 - accuracy: 0.5775 - categorical_accuracy: 0.5775 - val_loss: 48.9194 - val_accuracy: 0.6513 - val_categorical_accuracy: 0.6513\n",
            "Epoch 59/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 49.3605 - accuracy: 0.5821 - categorical_accuracy: 0.5821 - val_loss: 50.2615 - val_accuracy: 0.6735 - val_categorical_accuracy: 0.6735\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 50.2615 - accuracy: 0.6735 - categorical_accuracy: 0.6735\n",
            "1102\n",
            "Generation-7 Chromosome-10:\n",
            "Middle layers: 2 | Activation: selu | Optimization: Adadelta | Loss: categorical_crossentropy | LR: 0.0001 | Dropout: 0.25 |\n",
            "\tScore 0.60  | Accuracy: 0.67\n",
            "[0.6601251418948173, 0.6601251418948173, 0.6814194995999336, 0.6814194995999336, 0.6814194995999336, 0.6814194995999336, 0.7118400106072426] Best accuracies of each generation\n",
            "[array([2.0e+00, 1.0e+00, 4.0e+00, 0.0e+00, 1.0e-03, 1.5e-01]), array([2.0e+00, 5.0e+00, 1.0e+00, 0.0e+00, 1.0e-04, 2.5e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01]), array([2.0e+00, 5.0e+00, 1.0e+00, 0.0e+00, 1.0e-04, 2.5e-01]), array([2.0e+00, 5.0e+00, 1.0e+00, 0.0e+00, 1.0e-04, 2.5e-01]), array([2.0e+00, 5.0e+00, 1.0e+00, 0.0e+00, 1.0e-04, 2.5e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01])] Best of each generation\n",
            "Generation-8 Chromosome-1 scored 0.71  (Chromosome already known)\n",
            "Generation-8 Chromosome-2 scored 0.68  (Chromosome already known)\n",
            "Generation-8 Chromosome-3 scored 0.68  (Chromosome already known)\n",
            "Generation-8 Chromosome-4 scored 0.68  (Chromosome already known)\n",
            "Generation-8 Chromosome-5 scored 0.67  (Chromosome already known)\n",
            "Epoch 1/200\n",
            "351/351 [==============================] - 3s 6ms/step - loss: 1.0497 - accuracy: 0.0072 - categorical_accuracy: 0.0072 - val_loss: 0.9930 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 1.0424 - accuracy: 0.0091 - categorical_accuracy: 0.0091 - val_loss: 0.9888 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 3/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 1.0405 - accuracy: 0.0104 - categorical_accuracy: 0.0104 - val_loss: 0.9849 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 4/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 1.0359 - accuracy: 0.0121 - categorical_accuracy: 0.0121 - val_loss: 0.9801 - val_accuracy: 0.0376 - val_categorical_accuracy: 0.0376\n",
            "Epoch 5/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 1.0331 - accuracy: 0.0141 - categorical_accuracy: 0.0141 - val_loss: 0.9742 - val_accuracy: 0.0436 - val_categorical_accuracy: 0.0436\n",
            "Epoch 6/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 1.0255 - accuracy: 0.0336 - categorical_accuracy: 0.0336 - val_loss: 0.9659 - val_accuracy: 0.1709 - val_categorical_accuracy: 0.1709\n",
            "Epoch 7/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 1.0162 - accuracy: 0.0531 - categorical_accuracy: 0.0531 - val_loss: 0.9515 - val_accuracy: 0.3368 - val_categorical_accuracy: 0.3368\n",
            "Epoch 8/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9997 - accuracy: 0.1118 - categorical_accuracy: 0.1118 - val_loss: 0.9130 - val_accuracy: 0.4299 - val_categorical_accuracy: 0.4299\n",
            "Epoch 9/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.9511 - accuracy: 0.2557 - categorical_accuracy: 0.2557 - val_loss: 0.8175 - val_accuracy: 0.4402 - val_categorical_accuracy: 0.4402\n",
            "Epoch 10/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.8706 - accuracy: 0.3699 - categorical_accuracy: 0.3699 - val_loss: 0.7490 - val_accuracy: 0.4444 - val_categorical_accuracy: 0.4444\n",
            "Epoch 11/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.7821 - accuracy: 0.4370 - categorical_accuracy: 0.4370 - val_loss: 0.7300 - val_accuracy: 0.4547 - val_categorical_accuracy: 0.4547\n",
            "Epoch 12/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.7479 - accuracy: 0.4470 - categorical_accuracy: 0.4470 - val_loss: 0.7219 - val_accuracy: 0.4564 - val_categorical_accuracy: 0.4564\n",
            "Epoch 13/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.7419 - accuracy: 0.4544 - categorical_accuracy: 0.4544 - val_loss: 0.7153 - val_accuracy: 0.4607 - val_categorical_accuracy: 0.4607\n",
            "Epoch 14/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.7286 - accuracy: 0.4543 - categorical_accuracy: 0.4543 - val_loss: 0.7077 - val_accuracy: 0.4607 - val_categorical_accuracy: 0.4607\n",
            "Epoch 15/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.7223 - accuracy: 0.4483 - categorical_accuracy: 0.4483 - val_loss: 0.7010 - val_accuracy: 0.4658 - val_categorical_accuracy: 0.4658\n",
            "Epoch 16/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.7302 - accuracy: 0.4447 - categorical_accuracy: 0.4447 - val_loss: 0.6945 - val_accuracy: 0.4684 - val_categorical_accuracy: 0.4684\n",
            "Epoch 17/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.7262 - accuracy: 0.4459 - categorical_accuracy: 0.4459 - val_loss: 0.6882 - val_accuracy: 0.4701 - val_categorical_accuracy: 0.4701\n",
            "Epoch 18/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.7055 - accuracy: 0.4642 - categorical_accuracy: 0.4642 - val_loss: 0.6827 - val_accuracy: 0.4889 - val_categorical_accuracy: 0.4889\n",
            "Epoch 19/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.7039 - accuracy: 0.4526 - categorical_accuracy: 0.4526 - val_loss: 0.6774 - val_accuracy: 0.4889 - val_categorical_accuracy: 0.4889\n",
            "Epoch 20/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.7120 - accuracy: 0.4416 - categorical_accuracy: 0.4416 - val_loss: 0.6721 - val_accuracy: 0.4932 - val_categorical_accuracy: 0.4932\n",
            "Epoch 21/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6991 - accuracy: 0.4597 - categorical_accuracy: 0.4597 - val_loss: 0.6676 - val_accuracy: 0.5094 - val_categorical_accuracy: 0.5094\n",
            "Epoch 22/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.6822 - accuracy: 0.4773 - categorical_accuracy: 0.4773 - val_loss: 0.6627 - val_accuracy: 0.5274 - val_categorical_accuracy: 0.5274\n",
            "Epoch 23/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6924 - accuracy: 0.4554 - categorical_accuracy: 0.4554 - val_loss: 0.6578 - val_accuracy: 0.5274 - val_categorical_accuracy: 0.5274\n",
            "Epoch 24/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6807 - accuracy: 0.4679 - categorical_accuracy: 0.4679 - val_loss: 0.6530 - val_accuracy: 0.5299 - val_categorical_accuracy: 0.5299\n",
            "Epoch 25/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.6525 - accuracy: 0.4906 - categorical_accuracy: 0.4906 - val_loss: 0.6481 - val_accuracy: 0.5299 - val_categorical_accuracy: 0.5299\n",
            "Epoch 26/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6754 - accuracy: 0.4682 - categorical_accuracy: 0.4682 - val_loss: 0.6424 - val_accuracy: 0.5299 - val_categorical_accuracy: 0.5299\n",
            "Epoch 27/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.6640 - accuracy: 0.4715 - categorical_accuracy: 0.4715 - val_loss: 0.6372 - val_accuracy: 0.5342 - val_categorical_accuracy: 0.5342\n",
            "Epoch 28/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6592 - accuracy: 0.4756 - categorical_accuracy: 0.4756 - val_loss: 0.6326 - val_accuracy: 0.5496 - val_categorical_accuracy: 0.5496\n",
            "Epoch 29/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.6461 - accuracy: 0.4939 - categorical_accuracy: 0.4939 - val_loss: 0.6263 - val_accuracy: 0.5547 - val_categorical_accuracy: 0.5547\n",
            "Epoch 30/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.6440 - accuracy: 0.4963 - categorical_accuracy: 0.4963 - val_loss: 0.6216 - val_accuracy: 0.5556 - val_categorical_accuracy: 0.5556\n",
            "Epoch 31/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6383 - accuracy: 0.4898 - categorical_accuracy: 0.4898 - val_loss: 0.6160 - val_accuracy: 0.5590 - val_categorical_accuracy: 0.5590\n",
            "Epoch 32/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.6350 - accuracy: 0.4914 - categorical_accuracy: 0.4914 - val_loss: 0.6097 - val_accuracy: 0.5632 - val_categorical_accuracy: 0.5632\n",
            "Epoch 33/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6185 - accuracy: 0.4998 - categorical_accuracy: 0.4998 - val_loss: 0.6034 - val_accuracy: 0.5752 - val_categorical_accuracy: 0.5752\n",
            "Epoch 34/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.6243 - accuracy: 0.5069 - categorical_accuracy: 0.5069 - val_loss: 0.5973 - val_accuracy: 0.5752 - val_categorical_accuracy: 0.5752\n",
            "Epoch 35/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6085 - accuracy: 0.5080 - categorical_accuracy: 0.5080 - val_loss: 0.5897 - val_accuracy: 0.5752 - val_categorical_accuracy: 0.5752\n",
            "Epoch 36/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.5899 - accuracy: 0.5239 - categorical_accuracy: 0.5239 - val_loss: 0.5823 - val_accuracy: 0.5769 - val_categorical_accuracy: 0.5769\n",
            "Epoch 37/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5955 - accuracy: 0.5134 - categorical_accuracy: 0.5134 - val_loss: 0.5744 - val_accuracy: 0.5829 - val_categorical_accuracy: 0.5829\n",
            "Epoch 38/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.6028 - accuracy: 0.5124 - categorical_accuracy: 0.5124 - val_loss: 0.5659 - val_accuracy: 0.5829 - val_categorical_accuracy: 0.5829\n",
            "Epoch 39/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5745 - accuracy: 0.5307 - categorical_accuracy: 0.5307 - val_loss: 0.5572 - val_accuracy: 0.5846 - val_categorical_accuracy: 0.5846\n",
            "Epoch 40/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5684 - accuracy: 0.5269 - categorical_accuracy: 0.5269 - val_loss: 0.5499 - val_accuracy: 0.5846 - val_categorical_accuracy: 0.5846\n",
            "Epoch 41/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.5538 - accuracy: 0.5510 - categorical_accuracy: 0.5510 - val_loss: 0.5436 - val_accuracy: 0.5829 - val_categorical_accuracy: 0.5829\n",
            "Epoch 42/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.5537 - accuracy: 0.5410 - categorical_accuracy: 0.5410 - val_loss: 0.5381 - val_accuracy: 0.5829 - val_categorical_accuracy: 0.5829\n",
            "Epoch 43/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.5476 - accuracy: 0.5330 - categorical_accuracy: 0.5330 - val_loss: 0.5332 - val_accuracy: 0.5829 - val_categorical_accuracy: 0.5829\n",
            "Epoch 44/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5453 - accuracy: 0.5401 - categorical_accuracy: 0.5401 - val_loss: 0.5292 - val_accuracy: 0.5829 - val_categorical_accuracy: 0.5829\n",
            "Epoch 45/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.5406 - accuracy: 0.5502 - categorical_accuracy: 0.5502 - val_loss: 0.5251 - val_accuracy: 0.6043 - val_categorical_accuracy: 0.6043\n",
            "Epoch 46/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5389 - accuracy: 0.5461 - categorical_accuracy: 0.5461 - val_loss: 0.5215 - val_accuracy: 0.6265 - val_categorical_accuracy: 0.6265\n",
            "Epoch 47/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.5395 - accuracy: 0.5470 - categorical_accuracy: 0.5470 - val_loss: 0.5170 - val_accuracy: 0.6291 - val_categorical_accuracy: 0.6291\n",
            "Epoch 48/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5462 - accuracy: 0.5473 - categorical_accuracy: 0.5473 - val_loss: 0.5124 - val_accuracy: 0.6291 - val_categorical_accuracy: 0.6291\n",
            "Epoch 49/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.5280 - accuracy: 0.5549 - categorical_accuracy: 0.5549 - val_loss: 0.5067 - val_accuracy: 0.6291 - val_categorical_accuracy: 0.6291\n",
            "Epoch 50/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5293 - accuracy: 0.5551 - categorical_accuracy: 0.5551 - val_loss: 0.5010 - val_accuracy: 0.6368 - val_categorical_accuracy: 0.6368\n",
            "Epoch 51/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5087 - accuracy: 0.5556 - categorical_accuracy: 0.5556 - val_loss: 0.4954 - val_accuracy: 0.6350 - val_categorical_accuracy: 0.6350\n",
            "Epoch 52/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.5198 - accuracy: 0.5545 - categorical_accuracy: 0.5545 - val_loss: 0.4906 - val_accuracy: 0.6368 - val_categorical_accuracy: 0.6368\n",
            "Epoch 53/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4943 - accuracy: 0.5745 - categorical_accuracy: 0.5745 - val_loss: 0.4858 - val_accuracy: 0.6376 - val_categorical_accuracy: 0.6376\n",
            "Epoch 54/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.4949 - accuracy: 0.5699 - categorical_accuracy: 0.5699 - val_loss: 0.4812 - val_accuracy: 0.6376 - val_categorical_accuracy: 0.6376\n",
            "Epoch 55/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4963 - accuracy: 0.5750 - categorical_accuracy: 0.5750 - val_loss: 0.4774 - val_accuracy: 0.6376 - val_categorical_accuracy: 0.6376\n",
            "Epoch 56/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.4906 - accuracy: 0.5767 - categorical_accuracy: 0.5767 - val_loss: 0.4739 - val_accuracy: 0.6376 - val_categorical_accuracy: 0.6376\n",
            "Epoch 57/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4810 - accuracy: 0.5907 - categorical_accuracy: 0.5907 - val_loss: 0.4706 - val_accuracy: 0.6376 - val_categorical_accuracy: 0.6376\n",
            "Epoch 58/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4896 - accuracy: 0.5822 - categorical_accuracy: 0.5822 - val_loss: 0.4672 - val_accuracy: 0.6376 - val_categorical_accuracy: 0.6376\n",
            "Epoch 59/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4897 - accuracy: 0.5795 - categorical_accuracy: 0.5795 - val_loss: 0.4635 - val_accuracy: 0.6376 - val_categorical_accuracy: 0.6376\n",
            "Epoch 60/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4605 - accuracy: 0.5983 - categorical_accuracy: 0.5983 - val_loss: 0.4598 - val_accuracy: 0.6376 - val_categorical_accuracy: 0.6376\n",
            "Epoch 61/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.4740 - accuracy: 0.5901 - categorical_accuracy: 0.5901 - val_loss: 0.4562 - val_accuracy: 0.6376 - val_categorical_accuracy: 0.6376\n",
            "Epoch 62/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4671 - accuracy: 0.6015 - categorical_accuracy: 0.6015 - val_loss: 0.4528 - val_accuracy: 0.6427 - val_categorical_accuracy: 0.6427\n",
            "Epoch 63/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.4606 - accuracy: 0.5992 - categorical_accuracy: 0.5992 - val_loss: 0.4489 - val_accuracy: 0.6427 - val_categorical_accuracy: 0.6427\n",
            "Epoch 64/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4490 - accuracy: 0.6075 - categorical_accuracy: 0.6075 - val_loss: 0.4456 - val_accuracy: 0.6427 - val_categorical_accuracy: 0.6427\n",
            "Epoch 65/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.4615 - accuracy: 0.6007 - categorical_accuracy: 0.6007 - val_loss: 0.4418 - val_accuracy: 0.6444 - val_categorical_accuracy: 0.6444\n",
            "Epoch 66/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4624 - accuracy: 0.6054 - categorical_accuracy: 0.6054 - val_loss: 0.4387 - val_accuracy: 0.6650 - val_categorical_accuracy: 0.6650\n",
            "Epoch 67/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4399 - accuracy: 0.5975 - categorical_accuracy: 0.5975 - val_loss: 0.4361 - val_accuracy: 0.6650 - val_categorical_accuracy: 0.6650\n",
            "Epoch 68/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.4283 - accuracy: 0.6241 - categorical_accuracy: 0.6241 - val_loss: 0.4339 - val_accuracy: 0.6923 - val_categorical_accuracy: 0.6923\n",
            "Epoch 69/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4244 - accuracy: 0.6307 - categorical_accuracy: 0.6307 - val_loss: 0.4315 - val_accuracy: 0.6923 - val_categorical_accuracy: 0.6923\n",
            "Epoch 70/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.4384 - accuracy: 0.6191 - categorical_accuracy: 0.6191 - val_loss: 0.4290 - val_accuracy: 0.6923 - val_categorical_accuracy: 0.6923\n",
            "Epoch 71/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4469 - accuracy: 0.6081 - categorical_accuracy: 0.6081 - val_loss: 0.4262 - val_accuracy: 0.6923 - val_categorical_accuracy: 0.6923\n",
            "Epoch 72/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.4339 - accuracy: 0.6138 - categorical_accuracy: 0.6138 - val_loss: 0.4237 - val_accuracy: 0.6949 - val_categorical_accuracy: 0.6949\n",
            "Epoch 73/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4192 - accuracy: 0.6333 - categorical_accuracy: 0.6333 - val_loss: 0.4206 - val_accuracy: 0.6949 - val_categorical_accuracy: 0.6949\n",
            "Epoch 74/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4336 - accuracy: 0.6241 - categorical_accuracy: 0.6241 - val_loss: 0.4175 - val_accuracy: 0.6949 - val_categorical_accuracy: 0.6949\n",
            "Epoch 75/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.4202 - accuracy: 0.6322 - categorical_accuracy: 0.6322 - val_loss: 0.4146 - val_accuracy: 0.6949 - val_categorical_accuracy: 0.6949\n",
            "Epoch 76/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4261 - accuracy: 0.6226 - categorical_accuracy: 0.6226 - val_loss: 0.4113 - val_accuracy: 0.6949 - val_categorical_accuracy: 0.6949\n",
            "Epoch 77/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.4242 - accuracy: 0.6256 - categorical_accuracy: 0.6256 - val_loss: 0.4077 - val_accuracy: 0.6949 - val_categorical_accuracy: 0.6949\n",
            "Epoch 78/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4028 - accuracy: 0.6426 - categorical_accuracy: 0.6426 - val_loss: 0.4051 - val_accuracy: 0.6949 - val_categorical_accuracy: 0.6949\n",
            "Epoch 79/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3984 - accuracy: 0.6405 - categorical_accuracy: 0.6405 - val_loss: 0.4024 - val_accuracy: 0.6949 - val_categorical_accuracy: 0.6949\n",
            "Epoch 80/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4056 - accuracy: 0.6377 - categorical_accuracy: 0.6377 - val_loss: 0.3992 - val_accuracy: 0.6949 - val_categorical_accuracy: 0.6949\n",
            "Epoch 81/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4128 - accuracy: 0.6609 - categorical_accuracy: 0.6609 - val_loss: 0.3961 - val_accuracy: 0.6949 - val_categorical_accuracy: 0.6949\n",
            "Epoch 82/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.4039 - accuracy: 0.6487 - categorical_accuracy: 0.6487 - val_loss: 0.3932 - val_accuracy: 0.6949 - val_categorical_accuracy: 0.6949\n",
            "Epoch 83/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3955 - accuracy: 0.6602 - categorical_accuracy: 0.6602 - val_loss: 0.3901 - val_accuracy: 0.6949 - val_categorical_accuracy: 0.6949\n",
            "Epoch 84/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.3908 - accuracy: 0.6578 - categorical_accuracy: 0.6578 - val_loss: 0.3872 - val_accuracy: 0.6949 - val_categorical_accuracy: 0.6949\n",
            "Epoch 85/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3899 - accuracy: 0.6629 - categorical_accuracy: 0.6629 - val_loss: 0.3839 - val_accuracy: 0.6949 - val_categorical_accuracy: 0.6949\n",
            "Epoch 86/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.3912 - accuracy: 0.6635 - categorical_accuracy: 0.6635 - val_loss: 0.3803 - val_accuracy: 0.6949 - val_categorical_accuracy: 0.6949\n",
            "Epoch 87/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3700 - accuracy: 0.6757 - categorical_accuracy: 0.6757 - val_loss: 0.3770 - val_accuracy: 0.6949 - val_categorical_accuracy: 0.6949\n",
            "Epoch 88/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3693 - accuracy: 0.6800 - categorical_accuracy: 0.6800 - val_loss: 0.3738 - val_accuracy: 0.6949 - val_categorical_accuracy: 0.6949\n",
            "Epoch 89/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3924 - accuracy: 0.6648 - categorical_accuracy: 0.6648 - val_loss: 0.3700 - val_accuracy: 0.6957 - val_categorical_accuracy: 0.6957\n",
            "Epoch 90/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3723 - accuracy: 0.6808 - categorical_accuracy: 0.6808 - val_loss: 0.3658 - val_accuracy: 0.6957 - val_categorical_accuracy: 0.6957\n",
            "Epoch 91/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.3574 - accuracy: 0.6816 - categorical_accuracy: 0.6816 - val_loss: 0.3612 - val_accuracy: 0.6957 - val_categorical_accuracy: 0.6957\n",
            "Epoch 92/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3456 - accuracy: 0.6934 - categorical_accuracy: 0.6934 - val_loss: 0.3566 - val_accuracy: 0.6957 - val_categorical_accuracy: 0.6957\n",
            "Epoch 93/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.3584 - accuracy: 0.6926 - categorical_accuracy: 0.6926 - val_loss: 0.3515 - val_accuracy: 0.6957 - val_categorical_accuracy: 0.6957\n",
            "Epoch 94/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3413 - accuracy: 0.6914 - categorical_accuracy: 0.6914 - val_loss: 0.3465 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 95/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.3524 - accuracy: 0.6990 - categorical_accuracy: 0.6990 - val_loss: 0.3413 - val_accuracy: 0.6915 - val_categorical_accuracy: 0.6915\n",
            "Epoch 96/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3750 - accuracy: 0.6863 - categorical_accuracy: 0.6863 - val_loss: 0.3357 - val_accuracy: 0.6915 - val_categorical_accuracy: 0.6915\n",
            "Epoch 97/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.3522 - accuracy: 0.6855 - categorical_accuracy: 0.6855 - val_loss: 0.3301 - val_accuracy: 0.6915 - val_categorical_accuracy: 0.6915\n",
            "Epoch 98/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3455 - accuracy: 0.6932 - categorical_accuracy: 0.6932 - val_loss: 0.3247 - val_accuracy: 0.6915 - val_categorical_accuracy: 0.6915\n",
            "Epoch 99/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3267 - accuracy: 0.6973 - categorical_accuracy: 0.6973 - val_loss: 0.3190 - val_accuracy: 0.7068 - val_categorical_accuracy: 0.7068\n",
            "Epoch 100/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.3118 - accuracy: 0.7156 - categorical_accuracy: 0.7156 - val_loss: 0.3135 - val_accuracy: 0.7068 - val_categorical_accuracy: 0.7068\n",
            "Epoch 101/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3114 - accuracy: 0.7058 - categorical_accuracy: 0.7058 - val_loss: 0.3082 - val_accuracy: 0.7068 - val_categorical_accuracy: 0.7068\n",
            "Epoch 102/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.3113 - accuracy: 0.7007 - categorical_accuracy: 0.7007 - val_loss: 0.3030 - val_accuracy: 0.7068 - val_categorical_accuracy: 0.7068\n",
            "Epoch 103/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3135 - accuracy: 0.6976 - categorical_accuracy: 0.6976 - val_loss: 0.2980 - val_accuracy: 0.7068 - val_categorical_accuracy: 0.7068\n",
            "Epoch 104/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.3055 - accuracy: 0.6966 - categorical_accuracy: 0.6966 - val_loss: 0.2930 - val_accuracy: 0.7068 - val_categorical_accuracy: 0.7068\n",
            "Epoch 105/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.2984 - accuracy: 0.7081 - categorical_accuracy: 0.7081 - val_loss: 0.2878 - val_accuracy: 0.7068 - val_categorical_accuracy: 0.7068\n",
            "Epoch 106/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.2954 - accuracy: 0.6982 - categorical_accuracy: 0.6982 - val_loss: 0.2828 - val_accuracy: 0.7085 - val_categorical_accuracy: 0.7085\n",
            "Epoch 107/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.2914 - accuracy: 0.7121 - categorical_accuracy: 0.7121 - val_loss: 0.2778 - val_accuracy: 0.7085 - val_categorical_accuracy: 0.7085\n",
            "Epoch 108/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2803 - accuracy: 0.7059 - categorical_accuracy: 0.7059 - val_loss: 0.2729 - val_accuracy: 0.7085 - val_categorical_accuracy: 0.7085\n",
            "Epoch 109/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.2929 - accuracy: 0.7211 - categorical_accuracy: 0.7211 - val_loss: 0.2677 - val_accuracy: 0.7085 - val_categorical_accuracy: 0.7085\n",
            "Epoch 110/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2690 - accuracy: 0.7183 - categorical_accuracy: 0.7183 - val_loss: 0.2626 - val_accuracy: 0.7085 - val_categorical_accuracy: 0.7085\n",
            "Epoch 111/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.2737 - accuracy: 0.6973 - categorical_accuracy: 0.6973 - val_loss: 0.2575 - val_accuracy: 0.7085 - val_categorical_accuracy: 0.7085\n",
            "Epoch 112/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2736 - accuracy: 0.7263 - categorical_accuracy: 0.7263 - val_loss: 0.2524 - val_accuracy: 0.7085 - val_categorical_accuracy: 0.7085\n",
            "Epoch 113/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.2675 - accuracy: 0.7039 - categorical_accuracy: 0.7039 - val_loss: 0.2472 - val_accuracy: 0.7085 - val_categorical_accuracy: 0.7085\n",
            "Epoch 114/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2616 - accuracy: 0.7175 - categorical_accuracy: 0.7175 - val_loss: 0.2418 - val_accuracy: 0.7085 - val_categorical_accuracy: 0.7085\n",
            "Epoch 115/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.2622 - accuracy: 0.7104 - categorical_accuracy: 0.7104 - val_loss: 0.2363 - val_accuracy: 0.7085 - val_categorical_accuracy: 0.7085\n",
            "Epoch 116/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2493 - accuracy: 0.6980 - categorical_accuracy: 0.6980 - val_loss: 0.2309 - val_accuracy: 0.7085 - val_categorical_accuracy: 0.7085\n",
            "Epoch 117/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.2454 - accuracy: 0.7116 - categorical_accuracy: 0.7116 - val_loss: 0.2256 - val_accuracy: 0.7085 - val_categorical_accuracy: 0.7085\n",
            "Epoch 118/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.2298 - accuracy: 0.7195 - categorical_accuracy: 0.7195 - val_loss: 0.2202 - val_accuracy: 0.7085 - val_categorical_accuracy: 0.7085\n",
            "Epoch 119/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.2246 - accuracy: 0.7142 - categorical_accuracy: 0.7142 - val_loss: 0.2149 - val_accuracy: 0.7085 - val_categorical_accuracy: 0.7085\n",
            "Epoch 120/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.2404 - accuracy: 0.7061 - categorical_accuracy: 0.7061 - val_loss: 0.2097 - val_accuracy: 0.7085 - val_categorical_accuracy: 0.7085\n",
            "Epoch 121/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2134 - accuracy: 0.7093 - categorical_accuracy: 0.7093 - val_loss: 0.2049 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 122/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2134 - accuracy: 0.7173 - categorical_accuracy: 0.7173 - val_loss: 0.2003 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 123/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2163 - accuracy: 0.7042 - categorical_accuracy: 0.7042 - val_loss: 0.1957 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 124/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.2010 - accuracy: 0.7055 - categorical_accuracy: 0.7055 - val_loss: 0.1915 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 125/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2136 - accuracy: 0.7086 - categorical_accuracy: 0.7086 - val_loss: 0.1874 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 126/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1984 - accuracy: 0.7161 - categorical_accuracy: 0.7161 - val_loss: 0.1837 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 127/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1880 - accuracy: 0.7198 - categorical_accuracy: 0.7198 - val_loss: 0.1801 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 128/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1972 - accuracy: 0.7082 - categorical_accuracy: 0.7082 - val_loss: 0.1767 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 129/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1885 - accuracy: 0.7035 - categorical_accuracy: 0.7035 - val_loss: 0.1735 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 130/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1897 - accuracy: 0.7128 - categorical_accuracy: 0.7128 - val_loss: 0.1706 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 131/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1797 - accuracy: 0.7312 - categorical_accuracy: 0.7312 - val_loss: 0.1678 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 132/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1865 - accuracy: 0.7051 - categorical_accuracy: 0.7051 - val_loss: 0.1653 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 133/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1794 - accuracy: 0.7169 - categorical_accuracy: 0.7169 - val_loss: 0.1628 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 134/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1700 - accuracy: 0.7303 - categorical_accuracy: 0.7303 - val_loss: 0.1606 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 135/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1741 - accuracy: 0.7226 - categorical_accuracy: 0.7226 - val_loss: 0.1584 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 136/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1705 - accuracy: 0.7347 - categorical_accuracy: 0.7347 - val_loss: 0.1564 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 137/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1716 - accuracy: 0.7013 - categorical_accuracy: 0.7013 - val_loss: 0.1545 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 138/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1736 - accuracy: 0.7223 - categorical_accuracy: 0.7223 - val_loss: 0.1526 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 139/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1720 - accuracy: 0.7167 - categorical_accuracy: 0.7167 - val_loss: 0.1508 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 140/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1669 - accuracy: 0.7173 - categorical_accuracy: 0.7173 - val_loss: 0.1491 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 141/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1600 - accuracy: 0.7151 - categorical_accuracy: 0.7151 - val_loss: 0.1474 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 142/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1547 - accuracy: 0.7270 - categorical_accuracy: 0.7270 - val_loss: 0.1458 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 143/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1601 - accuracy: 0.7306 - categorical_accuracy: 0.7306 - val_loss: 0.1442 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 144/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1573 - accuracy: 0.7252 - categorical_accuracy: 0.7252 - val_loss: 0.1426 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 145/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1525 - accuracy: 0.7192 - categorical_accuracy: 0.7192 - val_loss: 0.1411 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 146/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1540 - accuracy: 0.7277 - categorical_accuracy: 0.7277 - val_loss: 0.1395 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 147/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1475 - accuracy: 0.7221 - categorical_accuracy: 0.7221 - val_loss: 0.1380 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 148/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1505 - accuracy: 0.7213 - categorical_accuracy: 0.7213 - val_loss: 0.1365 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 149/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1533 - accuracy: 0.7279 - categorical_accuracy: 0.7279 - val_loss: 0.1349 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 150/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1386 - accuracy: 0.7247 - categorical_accuracy: 0.7247 - val_loss: 0.1335 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 151/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1398 - accuracy: 0.7153 - categorical_accuracy: 0.7153 - val_loss: 0.1321 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 152/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1414 - accuracy: 0.7051 - categorical_accuracy: 0.7051 - val_loss: 0.1306 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 153/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1416 - accuracy: 0.7192 - categorical_accuracy: 0.7192 - val_loss: 0.1291 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 154/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1334 - accuracy: 0.7277 - categorical_accuracy: 0.7277 - val_loss: 0.1277 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 155/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1340 - accuracy: 0.7182 - categorical_accuracy: 0.7182 - val_loss: 0.1263 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 156/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1254 - accuracy: 0.7072 - categorical_accuracy: 0.7072 - val_loss: 0.1250 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 157/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1257 - accuracy: 0.7199 - categorical_accuracy: 0.7199 - val_loss: 0.1238 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 158/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1440 - accuracy: 0.7147 - categorical_accuracy: 0.7147 - val_loss: 0.1226 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 159/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1286 - accuracy: 0.7241 - categorical_accuracy: 0.7241 - val_loss: 0.1214 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 160/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1145 - accuracy: 0.7395 - categorical_accuracy: 0.7395 - val_loss: 0.1203 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 161/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1227 - accuracy: 0.7217 - categorical_accuracy: 0.7217 - val_loss: 0.1192 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 162/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1333 - accuracy: 0.7159 - categorical_accuracy: 0.7159 - val_loss: 0.1182 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 163/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1164 - accuracy: 0.7200 - categorical_accuracy: 0.7200 - val_loss: 0.1171 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 164/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1220 - accuracy: 0.7234 - categorical_accuracy: 0.7234 - val_loss: 0.1161 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 165/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1189 - accuracy: 0.7215 - categorical_accuracy: 0.7215 - val_loss: 0.1152 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 166/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1206 - accuracy: 0.7128 - categorical_accuracy: 0.7128 - val_loss: 0.1143 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 167/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1153 - accuracy: 0.7149 - categorical_accuracy: 0.7149 - val_loss: 0.1135 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 168/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1139 - accuracy: 0.7179 - categorical_accuracy: 0.7179 - val_loss: 0.1127 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 169/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1158 - accuracy: 0.7177 - categorical_accuracy: 0.7177 - val_loss: 0.1119 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 170/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1230 - accuracy: 0.7143 - categorical_accuracy: 0.7143 - val_loss: 0.1112 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 171/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1290 - accuracy: 0.7046 - categorical_accuracy: 0.7046 - val_loss: 0.1106 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 172/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1087 - accuracy: 0.7149 - categorical_accuracy: 0.7149 - val_loss: 0.1099 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 173/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1120 - accuracy: 0.7170 - categorical_accuracy: 0.7170 - val_loss: 0.1093 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 174/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1177 - accuracy: 0.7213 - categorical_accuracy: 0.7213 - val_loss: 0.1088 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 175/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1163 - accuracy: 0.7198 - categorical_accuracy: 0.7198 - val_loss: 0.1082 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 176/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1117 - accuracy: 0.7030 - categorical_accuracy: 0.7030 - val_loss: 0.1077 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 177/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1145 - accuracy: 0.7254 - categorical_accuracy: 0.7254 - val_loss: 0.1071 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 178/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1098 - accuracy: 0.7259 - categorical_accuracy: 0.7259 - val_loss: 0.1067 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 179/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1142 - accuracy: 0.7070 - categorical_accuracy: 0.7070 - val_loss: 0.1062 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 180/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1146 - accuracy: 0.7190 - categorical_accuracy: 0.7190 - val_loss: 0.1058 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 181/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1121 - accuracy: 0.7178 - categorical_accuracy: 0.7178 - val_loss: 0.1053 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 182/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1073 - accuracy: 0.7166 - categorical_accuracy: 0.7166 - val_loss: 0.1049 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 183/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0993 - accuracy: 0.7197 - categorical_accuracy: 0.7197 - val_loss: 0.1045 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 184/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0978 - accuracy: 0.7133 - categorical_accuracy: 0.7133 - val_loss: 0.1041 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 185/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1026 - accuracy: 0.7168 - categorical_accuracy: 0.7168 - val_loss: 0.1037 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 186/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0999 - accuracy: 0.7260 - categorical_accuracy: 0.7260 - val_loss: 0.1034 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 187/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1046 - accuracy: 0.7133 - categorical_accuracy: 0.7133 - val_loss: 0.1030 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 188/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1105 - accuracy: 0.7221 - categorical_accuracy: 0.7221 - val_loss: 0.1026 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 189/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0967 - accuracy: 0.7115 - categorical_accuracy: 0.7115 - val_loss: 0.1023 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 190/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0894 - accuracy: 0.7262 - categorical_accuracy: 0.7262 - val_loss: 0.1020 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 191/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1080 - accuracy: 0.7075 - categorical_accuracy: 0.7075 - val_loss: 0.1016 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 192/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1010 - accuracy: 0.7172 - categorical_accuracy: 0.7172 - val_loss: 0.1014 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 193/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0995 - accuracy: 0.7133 - categorical_accuracy: 0.7133 - val_loss: 0.1011 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 194/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1070 - accuracy: 0.7056 - categorical_accuracy: 0.7056 - val_loss: 0.1008 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 195/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0988 - accuracy: 0.7137 - categorical_accuracy: 0.7137 - val_loss: 0.1005 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 196/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0888 - accuracy: 0.7218 - categorical_accuracy: 0.7218 - val_loss: 0.1001 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 197/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0984 - accuracy: 0.7124 - categorical_accuracy: 0.7124 - val_loss: 0.0998 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 198/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1010 - accuracy: 0.7195 - categorical_accuracy: 0.7195 - val_loss: 0.0996 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 199/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0993 - accuracy: 0.7278 - categorical_accuracy: 0.7278 - val_loss: 0.0994 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "Epoch 200/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1046 - accuracy: 0.7173 - categorical_accuracy: 0.7173 - val_loss: 0.0991 - val_accuracy: 0.7162 - val_categorical_accuracy: 0.7162\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0991 - accuracy: 0.7162 - categorical_accuracy: 0.7162\n",
            "1102\n",
            "Generation-8 Chromosome-6:\n",
            "Middle layers: 2 | Activation: selu | Optimization: SGD | Loss: categorical_hinge | LR: 0.0001 | Dropout: 0.5 |\n",
            "\tScore 0.64  | Accuracy: 0.72\n",
            "Epoch 1/200\n",
            "351/351 [==============================] - 3s 6ms/step - loss: 0.4343 - accuracy: 0.6317 - categorical_accuracy: 0.6317 - val_loss: 0.1216 - val_accuracy: 0.7137 - val_categorical_accuracy: 0.7137\n",
            "Epoch 2/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0962 - accuracy: 0.7368 - categorical_accuracy: 0.7368 - val_loss: 0.0649 - val_accuracy: 0.7615 - val_categorical_accuracy: 0.7615\n",
            "Epoch 3/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0637 - accuracy: 0.7665 - categorical_accuracy: 0.7665 - val_loss: 0.0577 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 4/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0403 - accuracy: 0.7794 - categorical_accuracy: 0.7794 - val_loss: 0.0566 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 5/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0609 - accuracy: 0.7817 - categorical_accuracy: 0.7817 - val_loss: 0.0565 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 6/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0457 - accuracy: 0.7751 - categorical_accuracy: 0.7751 - val_loss: 0.0565 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 7/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0538 - accuracy: 0.7683 - categorical_accuracy: 0.7683 - val_loss: 0.0565 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 8/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0454 - accuracy: 0.7684 - categorical_accuracy: 0.7684 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 9/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0497 - accuracy: 0.7781 - categorical_accuracy: 0.7781 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 10/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0462 - accuracy: 0.7671 - categorical_accuracy: 0.7671 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 11/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0449 - accuracy: 0.7783 - categorical_accuracy: 0.7783 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 12/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0438 - accuracy: 0.7666 - categorical_accuracy: 0.7666 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 13/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0545 - accuracy: 0.7651 - categorical_accuracy: 0.7651 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 14/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0399 - accuracy: 0.7777 - categorical_accuracy: 0.7777 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 15/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0483 - accuracy: 0.7760 - categorical_accuracy: 0.7760 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 16/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0434 - accuracy: 0.7718 - categorical_accuracy: 0.7718 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 17/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0497 - accuracy: 0.7645 - categorical_accuracy: 0.7645 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 18/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0544 - accuracy: 0.7709 - categorical_accuracy: 0.7709 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 19/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0460 - accuracy: 0.7852 - categorical_accuracy: 0.7852 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 20/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0419 - accuracy: 0.7802 - categorical_accuracy: 0.7802 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 21/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0404 - accuracy: 0.7740 - categorical_accuracy: 0.7740 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 22/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0437 - accuracy: 0.7702 - categorical_accuracy: 0.7702 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 23/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0479 - accuracy: 0.7755 - categorical_accuracy: 0.7755 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 24/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0544 - accuracy: 0.7628 - categorical_accuracy: 0.7628 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 25/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0474 - accuracy: 0.7747 - categorical_accuracy: 0.7747 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 26/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0449 - accuracy: 0.7665 - categorical_accuracy: 0.7665 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 27/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0514 - accuracy: 0.7567 - categorical_accuracy: 0.7567 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 28/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0538 - accuracy: 0.7611 - categorical_accuracy: 0.7611 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 29/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0483 - accuracy: 0.7645 - categorical_accuracy: 0.7645 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 30/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0557 - accuracy: 0.7713 - categorical_accuracy: 0.7713 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 31/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0554 - accuracy: 0.7685 - categorical_accuracy: 0.7685 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 32/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0495 - accuracy: 0.7760 - categorical_accuracy: 0.7760 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 33/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0518 - accuracy: 0.7639 - categorical_accuracy: 0.7639 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 34/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0462 - accuracy: 0.7619 - categorical_accuracy: 0.7619 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 35/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0510 - accuracy: 0.7700 - categorical_accuracy: 0.7700 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 36/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0415 - accuracy: 0.7719 - categorical_accuracy: 0.7719 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 37/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0467 - accuracy: 0.7628 - categorical_accuracy: 0.7628 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 38/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0485 - accuracy: 0.7761 - categorical_accuracy: 0.7761 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 39/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0495 - accuracy: 0.7690 - categorical_accuracy: 0.7690 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 40/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0438 - accuracy: 0.7713 - categorical_accuracy: 0.7713 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 41/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0538 - accuracy: 0.7722 - categorical_accuracy: 0.7722 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 42/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0514 - accuracy: 0.7771 - categorical_accuracy: 0.7771 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 43/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0623 - accuracy: 0.7585 - categorical_accuracy: 0.7585 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 44/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0486 - accuracy: 0.7643 - categorical_accuracy: 0.7643 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 45/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0470 - accuracy: 0.7609 - categorical_accuracy: 0.7609 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 46/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0557 - accuracy: 0.7770 - categorical_accuracy: 0.7770 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 47/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0357 - accuracy: 0.7798 - categorical_accuracy: 0.7798 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 48/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0482 - accuracy: 0.7622 - categorical_accuracy: 0.7622 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 49/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0530 - accuracy: 0.7673 - categorical_accuracy: 0.7673 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 50/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0571 - accuracy: 0.7691 - categorical_accuracy: 0.7691 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 51/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0644 - accuracy: 0.7565 - categorical_accuracy: 0.7565 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 52/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0485 - accuracy: 0.7660 - categorical_accuracy: 0.7660 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 53/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0468 - accuracy: 0.7718 - categorical_accuracy: 0.7718 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 54/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0549 - accuracy: 0.7762 - categorical_accuracy: 0.7762 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 55/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0443 - accuracy: 0.7621 - categorical_accuracy: 0.7621 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 56/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0448 - accuracy: 0.7746 - categorical_accuracy: 0.7746 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 57/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0526 - accuracy: 0.7691 - categorical_accuracy: 0.7691 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 58/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0505 - accuracy: 0.7622 - categorical_accuracy: 0.7622 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 59/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0500 - accuracy: 0.7718 - categorical_accuracy: 0.7718 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 60/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0467 - accuracy: 0.7830 - categorical_accuracy: 0.7830 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 61/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0549 - accuracy: 0.7731 - categorical_accuracy: 0.7731 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 62/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0593 - accuracy: 0.7581 - categorical_accuracy: 0.7581 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 63/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0461 - accuracy: 0.7793 - categorical_accuracy: 0.7793 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 64/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0494 - accuracy: 0.7644 - categorical_accuracy: 0.7644 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 65/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0458 - accuracy: 0.7625 - categorical_accuracy: 0.7625 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 66/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0533 - accuracy: 0.7761 - categorical_accuracy: 0.7761 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 67/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0524 - accuracy: 0.7687 - categorical_accuracy: 0.7687 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 68/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0653 - accuracy: 0.7701 - categorical_accuracy: 0.7701 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 69/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0400 - accuracy: 0.7788 - categorical_accuracy: 0.7788 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 70/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0551 - accuracy: 0.7738 - categorical_accuracy: 0.7738 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 71/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0467 - accuracy: 0.7787 - categorical_accuracy: 0.7787 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 72/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0453 - accuracy: 0.7793 - categorical_accuracy: 0.7793 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 73/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0454 - accuracy: 0.7636 - categorical_accuracy: 0.7636 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 74/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0505 - accuracy: 0.7740 - categorical_accuracy: 0.7740 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 75/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0545 - accuracy: 0.7763 - categorical_accuracy: 0.7763 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 76/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0546 - accuracy: 0.7853 - categorical_accuracy: 0.7853 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 77/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0480 - accuracy: 0.7687 - categorical_accuracy: 0.7687 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 78/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0600 - accuracy: 0.7640 - categorical_accuracy: 0.7640 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 79/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0518 - accuracy: 0.7733 - categorical_accuracy: 0.7733 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 80/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0367 - accuracy: 0.7855 - categorical_accuracy: 0.7855 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 81/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0563 - accuracy: 0.7737 - categorical_accuracy: 0.7737 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 82/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0476 - accuracy: 0.7704 - categorical_accuracy: 0.7704 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 83/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0583 - accuracy: 0.7750 - categorical_accuracy: 0.7750 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 84/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0501 - accuracy: 0.7703 - categorical_accuracy: 0.7703 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 85/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0516 - accuracy: 0.7800 - categorical_accuracy: 0.7800 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 86/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0426 - accuracy: 0.7673 - categorical_accuracy: 0.7673 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 87/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0472 - accuracy: 0.7750 - categorical_accuracy: 0.7750 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 88/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0525 - accuracy: 0.7610 - categorical_accuracy: 0.7610 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 89/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0438 - accuracy: 0.7697 - categorical_accuracy: 0.7697 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 90/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0547 - accuracy: 0.7581 - categorical_accuracy: 0.7581 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 91/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0503 - accuracy: 0.7711 - categorical_accuracy: 0.7711 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 92/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0537 - accuracy: 0.7694 - categorical_accuracy: 0.7694 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 93/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.0546 - accuracy: 0.7735 - categorical_accuracy: 0.7735 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 94/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0480 - accuracy: 0.7669 - categorical_accuracy: 0.7669 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 95/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0487 - accuracy: 0.7676 - categorical_accuracy: 0.7676 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 96/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0533 - accuracy: 0.7719 - categorical_accuracy: 0.7719 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 97/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0384 - accuracy: 0.7689 - categorical_accuracy: 0.7689 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 98/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0506 - accuracy: 0.7611 - categorical_accuracy: 0.7611 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 99/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0466 - accuracy: 0.7723 - categorical_accuracy: 0.7723 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 100/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0546 - accuracy: 0.7646 - categorical_accuracy: 0.7646 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 101/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0523 - accuracy: 0.7664 - categorical_accuracy: 0.7664 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 102/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0509 - accuracy: 0.7749 - categorical_accuracy: 0.7749 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 103/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0457 - accuracy: 0.7769 - categorical_accuracy: 0.7769 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 104/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0442 - accuracy: 0.7767 - categorical_accuracy: 0.7767 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 105/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0458 - accuracy: 0.7723 - categorical_accuracy: 0.7723 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "Epoch 106/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0562 - accuracy: 0.7641 - categorical_accuracy: 0.7641 - val_loss: 0.0564 - val_accuracy: 0.7667 - val_categorical_accuracy: 0.7667\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.7667 - categorical_accuracy: 0.7667\n",
            "1102\n",
            "Generation-8 Chromosome-7:\n",
            "Middle layers: 2 | Activation: softsign | Optimization: Adam | Loss: categorical_hinge | LR: 0.0001 | Dropout: 0.3 |\n",
            "\tScore 0.68  | Accuracy: 0.77\n",
            "Epoch 1/200\n",
            "351/351 [==============================] - 3s 6ms/step - loss: 0.4484 - accuracy: 0.6691 - categorical_accuracy: 0.6691 - val_loss: 0.3665 - val_accuracy: 0.7231 - val_categorical_accuracy: 0.7231\n",
            "Epoch 2/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3510 - accuracy: 0.7181 - categorical_accuracy: 0.7181 - val_loss: 0.3627 - val_accuracy: 0.7256 - val_categorical_accuracy: 0.7256\n",
            "Epoch 3/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3545 - accuracy: 0.7097 - categorical_accuracy: 0.7097 - val_loss: 0.3624 - val_accuracy: 0.7256 - val_categorical_accuracy: 0.7256\n",
            "Epoch 4/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3349 - accuracy: 0.7174 - categorical_accuracy: 0.7174 - val_loss: 0.3228 - val_accuracy: 0.7453 - val_categorical_accuracy: 0.7453\n",
            "Epoch 5/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3003 - accuracy: 0.7520 - categorical_accuracy: 0.7520 - val_loss: 0.3180 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 6/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3091 - accuracy: 0.7328 - categorical_accuracy: 0.7328 - val_loss: 0.3180 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 7/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3178 - accuracy: 0.7321 - categorical_accuracy: 0.7321 - val_loss: 0.3180 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 8/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3025 - accuracy: 0.7454 - categorical_accuracy: 0.7454 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 9/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3161 - accuracy: 0.7318 - categorical_accuracy: 0.7318 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 10/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2968 - accuracy: 0.7450 - categorical_accuracy: 0.7450 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 11/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2945 - accuracy: 0.7566 - categorical_accuracy: 0.7566 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 12/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2830 - accuracy: 0.7550 - categorical_accuracy: 0.7550 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 13/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3208 - accuracy: 0.7379 - categorical_accuracy: 0.7379 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 14/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3245 - accuracy: 0.7393 - categorical_accuracy: 0.7393 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 15/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3077 - accuracy: 0.7395 - categorical_accuracy: 0.7395 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 16/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3076 - accuracy: 0.7304 - categorical_accuracy: 0.7304 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 17/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.2938 - accuracy: 0.7440 - categorical_accuracy: 0.7440 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 18/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3017 - accuracy: 0.7374 - categorical_accuracy: 0.7374 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 19/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2957 - accuracy: 0.7545 - categorical_accuracy: 0.7545 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 20/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2941 - accuracy: 0.7528 - categorical_accuracy: 0.7528 - val_loss: 0.3180 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 21/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3015 - accuracy: 0.7412 - categorical_accuracy: 0.7412 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 22/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.3203 - accuracy: 0.7391 - categorical_accuracy: 0.7391 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 23/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3147 - accuracy: 0.7250 - categorical_accuracy: 0.7250 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 24/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2801 - accuracy: 0.7481 - categorical_accuracy: 0.7481 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 25/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2822 - accuracy: 0.7511 - categorical_accuracy: 0.7511 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 26/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2779 - accuracy: 0.7522 - categorical_accuracy: 0.7522 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 27/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3040 - accuracy: 0.7500 - categorical_accuracy: 0.7500 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 28/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2937 - accuracy: 0.7534 - categorical_accuracy: 0.7534 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 29/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3073 - accuracy: 0.7430 - categorical_accuracy: 0.7430 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 30/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3031 - accuracy: 0.7455 - categorical_accuracy: 0.7455 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 31/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3146 - accuracy: 0.7334 - categorical_accuracy: 0.7334 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 32/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3057 - accuracy: 0.7501 - categorical_accuracy: 0.7501 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 33/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2964 - accuracy: 0.7423 - categorical_accuracy: 0.7423 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 34/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.3089 - accuracy: 0.7457 - categorical_accuracy: 0.7457 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 35/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2911 - accuracy: 0.7536 - categorical_accuracy: 0.7536 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 36/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3371 - accuracy: 0.7350 - categorical_accuracy: 0.7350 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 37/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3139 - accuracy: 0.7356 - categorical_accuracy: 0.7356 - val_loss: 0.3178 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 38/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2941 - accuracy: 0.7396 - categorical_accuracy: 0.7396 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 39/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3069 - accuracy: 0.7473 - categorical_accuracy: 0.7473 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 40/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2977 - accuracy: 0.7463 - categorical_accuracy: 0.7463 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 41/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.2928 - accuracy: 0.7385 - categorical_accuracy: 0.7385 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 42/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2974 - accuracy: 0.7477 - categorical_accuracy: 0.7477 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 43/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.3017 - accuracy: 0.7426 - categorical_accuracy: 0.7426 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 44/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2887 - accuracy: 0.7663 - categorical_accuracy: 0.7663 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 45/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3275 - accuracy: 0.7236 - categorical_accuracy: 0.7236 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 46/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3159 - accuracy: 0.7430 - categorical_accuracy: 0.7430 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 47/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3116 - accuracy: 0.7307 - categorical_accuracy: 0.7307 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 48/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2992 - accuracy: 0.7350 - categorical_accuracy: 0.7350 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 49/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3017 - accuracy: 0.7439 - categorical_accuracy: 0.7439 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 50/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3163 - accuracy: 0.7321 - categorical_accuracy: 0.7321 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 51/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3111 - accuracy: 0.7394 - categorical_accuracy: 0.7394 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 52/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2998 - accuracy: 0.7437 - categorical_accuracy: 0.7437 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 53/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2893 - accuracy: 0.7434 - categorical_accuracy: 0.7434 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 54/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3099 - accuracy: 0.7335 - categorical_accuracy: 0.7335 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 55/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.3004 - accuracy: 0.7415 - categorical_accuracy: 0.7415 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 56/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3129 - accuracy: 0.7362 - categorical_accuracy: 0.7362 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 57/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.3057 - accuracy: 0.7475 - categorical_accuracy: 0.7475 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 58/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3017 - accuracy: 0.7405 - categorical_accuracy: 0.7405 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 59/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3127 - accuracy: 0.7413 - categorical_accuracy: 0.7413 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 60/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3126 - accuracy: 0.7391 - categorical_accuracy: 0.7391 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 61/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3018 - accuracy: 0.7429 - categorical_accuracy: 0.7429 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 62/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3061 - accuracy: 0.7389 - categorical_accuracy: 0.7389 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 63/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2949 - accuracy: 0.7501 - categorical_accuracy: 0.7501 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 64/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3078 - accuracy: 0.7271 - categorical_accuracy: 0.7271 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 65/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3390 - accuracy: 0.7243 - categorical_accuracy: 0.7243 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 66/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2856 - accuracy: 0.7601 - categorical_accuracy: 0.7601 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 67/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2889 - accuracy: 0.7449 - categorical_accuracy: 0.7449 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 68/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3116 - accuracy: 0.7402 - categorical_accuracy: 0.7402 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 69/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3112 - accuracy: 0.7487 - categorical_accuracy: 0.7487 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 70/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3110 - accuracy: 0.7247 - categorical_accuracy: 0.7247 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 71/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3041 - accuracy: 0.7397 - categorical_accuracy: 0.7397 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 72/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3345 - accuracy: 0.7296 - categorical_accuracy: 0.7296 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 73/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2950 - accuracy: 0.7518 - categorical_accuracy: 0.7518 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 74/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2842 - accuracy: 0.7484 - categorical_accuracy: 0.7484 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 75/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2940 - accuracy: 0.7527 - categorical_accuracy: 0.7527 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 76/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3131 - accuracy: 0.7447 - categorical_accuracy: 0.7447 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 77/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2852 - accuracy: 0.7521 - categorical_accuracy: 0.7521 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 78/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3009 - accuracy: 0.7413 - categorical_accuracy: 0.7413 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 79/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3272 - accuracy: 0.7348 - categorical_accuracy: 0.7348 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 80/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3134 - accuracy: 0.7408 - categorical_accuracy: 0.7408 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 81/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3067 - accuracy: 0.7427 - categorical_accuracy: 0.7427 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 82/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3116 - accuracy: 0.7437 - categorical_accuracy: 0.7437 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 83/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2832 - accuracy: 0.7568 - categorical_accuracy: 0.7568 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 84/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3175 - accuracy: 0.7326 - categorical_accuracy: 0.7326 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 85/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2940 - accuracy: 0.7463 - categorical_accuracy: 0.7463 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 86/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3136 - accuracy: 0.7356 - categorical_accuracy: 0.7356 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "Epoch 87/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3065 - accuracy: 0.7336 - categorical_accuracy: 0.7336 - val_loss: 0.3179 - val_accuracy: 0.7479 - val_categorical_accuracy: 0.7479\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.3179 - accuracy: 0.7479 - categorical_accuracy: 0.7479\n",
            "1102\n",
            "Generation-8 Chromosome-8:\n",
            "Middle layers: 2 | Activation: selu | Optimization: Adamax | Loss: categorical_hinge | LR: 0.001 | Dropout: 0.3 |\n",
            "\tScore 0.67  | Accuracy: 0.75\n",
            "Epoch 1/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 1.0010 - accuracy: 0.0013 - categorical_accuracy: 0.0013 - val_loss: 0.9914 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9987 - accuracy: 0.0037 - categorical_accuracy: 0.0037 - val_loss: 0.9884 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 3/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9957 - accuracy: 0.0082 - categorical_accuracy: 0.0082 - val_loss: 0.9856 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 4/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9932 - accuracy: 0.0089 - categorical_accuracy: 0.0089 - val_loss: 0.9829 - val_accuracy: 0.0034 - val_categorical_accuracy: 0.0034\n",
            "Epoch 5/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9915 - accuracy: 0.0155 - categorical_accuracy: 0.0155 - val_loss: 0.9800 - val_accuracy: 0.0231 - val_categorical_accuracy: 0.0231\n",
            "Epoch 6/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9872 - accuracy: 0.0320 - categorical_accuracy: 0.0320 - val_loss: 0.9767 - val_accuracy: 0.0735 - val_categorical_accuracy: 0.0735\n",
            "Epoch 7/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9849 - accuracy: 0.0464 - categorical_accuracy: 0.0464 - val_loss: 0.9726 - val_accuracy: 0.1453 - val_categorical_accuracy: 0.1453\n",
            "Epoch 8/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9809 - accuracy: 0.0820 - categorical_accuracy: 0.0820 - val_loss: 0.9670 - val_accuracy: 0.1795 - val_categorical_accuracy: 0.1795\n",
            "Epoch 9/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9736 - accuracy: 0.1320 - categorical_accuracy: 0.1320 - val_loss: 0.9582 - val_accuracy: 0.2316 - val_categorical_accuracy: 0.2316\n",
            "Epoch 10/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9631 - accuracy: 0.1914 - categorical_accuracy: 0.1914 - val_loss: 0.9439 - val_accuracy: 0.2624 - val_categorical_accuracy: 0.2624\n",
            "Epoch 11/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9473 - accuracy: 0.2505 - categorical_accuracy: 0.2505 - val_loss: 0.9237 - val_accuracy: 0.3308 - val_categorical_accuracy: 0.3308\n",
            "Epoch 12/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9280 - accuracy: 0.3054 - categorical_accuracy: 0.3054 - val_loss: 0.9002 - val_accuracy: 0.3624 - val_categorical_accuracy: 0.3624\n",
            "Epoch 13/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9137 - accuracy: 0.3323 - categorical_accuracy: 0.3323 - val_loss: 0.8769 - val_accuracy: 0.4581 - val_categorical_accuracy: 0.4581\n",
            "Epoch 14/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.8821 - accuracy: 0.4088 - categorical_accuracy: 0.4088 - val_loss: 0.8504 - val_accuracy: 0.4709 - val_categorical_accuracy: 0.4709\n",
            "Epoch 15/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.8521 - accuracy: 0.4402 - categorical_accuracy: 0.4402 - val_loss: 0.8175 - val_accuracy: 0.4744 - val_categorical_accuracy: 0.4744\n",
            "Epoch 16/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.8337 - accuracy: 0.4483 - categorical_accuracy: 0.4483 - val_loss: 0.7847 - val_accuracy: 0.4821 - val_categorical_accuracy: 0.4821\n",
            "Epoch 17/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.7914 - accuracy: 0.4794 - categorical_accuracy: 0.4794 - val_loss: 0.7587 - val_accuracy: 0.4974 - val_categorical_accuracy: 0.4974\n",
            "Epoch 18/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.7634 - accuracy: 0.4754 - categorical_accuracy: 0.4754 - val_loss: 0.7403 - val_accuracy: 0.5214 - val_categorical_accuracy: 0.5214\n",
            "Epoch 19/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.7344 - accuracy: 0.5001 - categorical_accuracy: 0.5001 - val_loss: 0.7278 - val_accuracy: 0.5256 - val_categorical_accuracy: 0.5256\n",
            "Epoch 20/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.7355 - accuracy: 0.4917 - categorical_accuracy: 0.4917 - val_loss: 0.7184 - val_accuracy: 0.5256 - val_categorical_accuracy: 0.5256\n",
            "Epoch 21/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.7411 - accuracy: 0.4751 - categorical_accuracy: 0.4751 - val_loss: 0.7107 - val_accuracy: 0.5256 - val_categorical_accuracy: 0.5256\n",
            "Epoch 22/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.7277 - accuracy: 0.4891 - categorical_accuracy: 0.4891 - val_loss: 0.7038 - val_accuracy: 0.5274 - val_categorical_accuracy: 0.5274\n",
            "Epoch 23/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.7073 - accuracy: 0.5168 - categorical_accuracy: 0.5168 - val_loss: 0.6974 - val_accuracy: 0.5274 - val_categorical_accuracy: 0.5274\n",
            "Epoch 24/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6996 - accuracy: 0.5110 - categorical_accuracy: 0.5110 - val_loss: 0.6911 - val_accuracy: 0.5299 - val_categorical_accuracy: 0.5299\n",
            "Epoch 25/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6918 - accuracy: 0.5195 - categorical_accuracy: 0.5195 - val_loss: 0.6847 - val_accuracy: 0.5316 - val_categorical_accuracy: 0.5316\n",
            "Epoch 26/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6937 - accuracy: 0.5139 - categorical_accuracy: 0.5139 - val_loss: 0.6783 - val_accuracy: 0.5376 - val_categorical_accuracy: 0.5376\n",
            "Epoch 27/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6935 - accuracy: 0.5198 - categorical_accuracy: 0.5198 - val_loss: 0.6717 - val_accuracy: 0.5581 - val_categorical_accuracy: 0.5581\n",
            "Epoch 28/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6972 - accuracy: 0.5067 - categorical_accuracy: 0.5067 - val_loss: 0.6652 - val_accuracy: 0.5581 - val_categorical_accuracy: 0.5581\n",
            "Epoch 29/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6633 - accuracy: 0.5197 - categorical_accuracy: 0.5197 - val_loss: 0.6586 - val_accuracy: 0.5581 - val_categorical_accuracy: 0.5581\n",
            "Epoch 30/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6604 - accuracy: 0.5201 - categorical_accuracy: 0.5201 - val_loss: 0.6521 - val_accuracy: 0.5581 - val_categorical_accuracy: 0.5581\n",
            "Epoch 31/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6572 - accuracy: 0.5304 - categorical_accuracy: 0.5304 - val_loss: 0.6460 - val_accuracy: 0.5581 - val_categorical_accuracy: 0.5581\n",
            "Epoch 32/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6606 - accuracy: 0.5184 - categorical_accuracy: 0.5184 - val_loss: 0.6402 - val_accuracy: 0.5581 - val_categorical_accuracy: 0.5581\n",
            "Epoch 33/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6572 - accuracy: 0.5304 - categorical_accuracy: 0.5304 - val_loss: 0.6347 - val_accuracy: 0.5581 - val_categorical_accuracy: 0.5581\n",
            "Epoch 34/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6296 - accuracy: 0.5373 - categorical_accuracy: 0.5373 - val_loss: 0.6297 - val_accuracy: 0.5581 - val_categorical_accuracy: 0.5581\n",
            "Epoch 35/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6414 - accuracy: 0.5456 - categorical_accuracy: 0.5456 - val_loss: 0.6249 - val_accuracy: 0.5581 - val_categorical_accuracy: 0.5581\n",
            "Epoch 36/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6221 - accuracy: 0.5553 - categorical_accuracy: 0.5553 - val_loss: 0.6205 - val_accuracy: 0.5624 - val_categorical_accuracy: 0.5624\n",
            "Epoch 37/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6596 - accuracy: 0.5283 - categorical_accuracy: 0.5283 - val_loss: 0.6164 - val_accuracy: 0.5795 - val_categorical_accuracy: 0.5795\n",
            "Epoch 38/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6438 - accuracy: 0.5445 - categorical_accuracy: 0.5445 - val_loss: 0.6124 - val_accuracy: 0.5838 - val_categorical_accuracy: 0.5838\n",
            "Epoch 39/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6206 - accuracy: 0.5579 - categorical_accuracy: 0.5579 - val_loss: 0.6084 - val_accuracy: 0.5889 - val_categorical_accuracy: 0.5889\n",
            "Epoch 40/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6151 - accuracy: 0.5658 - categorical_accuracy: 0.5658 - val_loss: 0.6045 - val_accuracy: 0.5889 - val_categorical_accuracy: 0.5889\n",
            "Epoch 41/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6144 - accuracy: 0.5696 - categorical_accuracy: 0.5696 - val_loss: 0.6006 - val_accuracy: 0.5949 - val_categorical_accuracy: 0.5949\n",
            "Epoch 42/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6021 - accuracy: 0.5754 - categorical_accuracy: 0.5754 - val_loss: 0.5967 - val_accuracy: 0.6171 - val_categorical_accuracy: 0.6171\n",
            "Epoch 43/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6009 - accuracy: 0.5710 - categorical_accuracy: 0.5710 - val_loss: 0.5926 - val_accuracy: 0.6171 - val_categorical_accuracy: 0.6171\n",
            "Epoch 44/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6250 - accuracy: 0.5511 - categorical_accuracy: 0.5511 - val_loss: 0.5884 - val_accuracy: 0.6205 - val_categorical_accuracy: 0.6205\n",
            "Epoch 45/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5878 - accuracy: 0.5817 - categorical_accuracy: 0.5817 - val_loss: 0.5841 - val_accuracy: 0.6205 - val_categorical_accuracy: 0.6205\n",
            "Epoch 46/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6093 - accuracy: 0.5704 - categorical_accuracy: 0.5704 - val_loss: 0.5796 - val_accuracy: 0.6205 - val_categorical_accuracy: 0.6205\n",
            "Epoch 47/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5971 - accuracy: 0.5655 - categorical_accuracy: 0.5655 - val_loss: 0.5753 - val_accuracy: 0.6205 - val_categorical_accuracy: 0.6205\n",
            "Epoch 48/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5910 - accuracy: 0.5754 - categorical_accuracy: 0.5754 - val_loss: 0.5711 - val_accuracy: 0.6205 - val_categorical_accuracy: 0.6205\n",
            "Epoch 49/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5751 - accuracy: 0.5844 - categorical_accuracy: 0.5844 - val_loss: 0.5670 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 50/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5873 - accuracy: 0.5807 - categorical_accuracy: 0.5807 - val_loss: 0.5632 - val_accuracy: 0.6231 - val_categorical_accuracy: 0.6231\n",
            "Epoch 51/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5561 - accuracy: 0.5903 - categorical_accuracy: 0.5903 - val_loss: 0.5595 - val_accuracy: 0.6385 - val_categorical_accuracy: 0.6385\n",
            "Epoch 52/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5731 - accuracy: 0.6061 - categorical_accuracy: 0.6061 - val_loss: 0.5560 - val_accuracy: 0.6385 - val_categorical_accuracy: 0.6385\n",
            "Epoch 53/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5704 - accuracy: 0.5963 - categorical_accuracy: 0.5963 - val_loss: 0.5526 - val_accuracy: 0.6393 - val_categorical_accuracy: 0.6393\n",
            "Epoch 54/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.5685 - accuracy: 0.6117 - categorical_accuracy: 0.6117 - val_loss: 0.5494 - val_accuracy: 0.6393 - val_categorical_accuracy: 0.6393\n",
            "Epoch 55/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5674 - accuracy: 0.6088 - categorical_accuracy: 0.6088 - val_loss: 0.5462 - val_accuracy: 0.6393 - val_categorical_accuracy: 0.6393\n",
            "Epoch 56/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.5564 - accuracy: 0.6009 - categorical_accuracy: 0.6009 - val_loss: 0.5430 - val_accuracy: 0.6410 - val_categorical_accuracy: 0.6410\n",
            "Epoch 57/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5558 - accuracy: 0.6106 - categorical_accuracy: 0.6106 - val_loss: 0.5399 - val_accuracy: 0.6410 - val_categorical_accuracy: 0.6410\n",
            "Epoch 58/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5447 - accuracy: 0.6110 - categorical_accuracy: 0.6110 - val_loss: 0.5368 - val_accuracy: 0.6410 - val_categorical_accuracy: 0.6410\n",
            "Epoch 59/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5518 - accuracy: 0.6065 - categorical_accuracy: 0.6065 - val_loss: 0.5338 - val_accuracy: 0.6419 - val_categorical_accuracy: 0.6419\n",
            "Epoch 60/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5389 - accuracy: 0.6248 - categorical_accuracy: 0.6248 - val_loss: 0.5307 - val_accuracy: 0.6419 - val_categorical_accuracy: 0.6419\n",
            "Epoch 61/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.5429 - accuracy: 0.6206 - categorical_accuracy: 0.6206 - val_loss: 0.5276 - val_accuracy: 0.6444 - val_categorical_accuracy: 0.6444\n",
            "Epoch 62/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5262 - accuracy: 0.6311 - categorical_accuracy: 0.6311 - val_loss: 0.5245 - val_accuracy: 0.6444 - val_categorical_accuracy: 0.6444\n",
            "Epoch 63/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.5211 - accuracy: 0.6310 - categorical_accuracy: 0.6310 - val_loss: 0.5212 - val_accuracy: 0.6444 - val_categorical_accuracy: 0.6444\n",
            "Epoch 64/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5147 - accuracy: 0.6365 - categorical_accuracy: 0.6365 - val_loss: 0.5179 - val_accuracy: 0.6427 - val_categorical_accuracy: 0.6427\n",
            "Epoch 65/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5139 - accuracy: 0.6281 - categorical_accuracy: 0.6281 - val_loss: 0.5144 - val_accuracy: 0.6385 - val_categorical_accuracy: 0.6385\n",
            "Epoch 66/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5137 - accuracy: 0.6268 - categorical_accuracy: 0.6268 - val_loss: 0.5111 - val_accuracy: 0.6376 - val_categorical_accuracy: 0.6376\n",
            "Epoch 67/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5082 - accuracy: 0.6340 - categorical_accuracy: 0.6340 - val_loss: 0.5079 - val_accuracy: 0.6333 - val_categorical_accuracy: 0.6333\n",
            "Epoch 68/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.5208 - accuracy: 0.6173 - categorical_accuracy: 0.6173 - val_loss: 0.5047 - val_accuracy: 0.6333 - val_categorical_accuracy: 0.6333\n",
            "Epoch 69/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.4972 - accuracy: 0.6440 - categorical_accuracy: 0.6440 - val_loss: 0.5016 - val_accuracy: 0.6333 - val_categorical_accuracy: 0.6333\n",
            "Epoch 70/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5000 - accuracy: 0.6360 - categorical_accuracy: 0.6360 - val_loss: 0.4987 - val_accuracy: 0.6333 - val_categorical_accuracy: 0.6333\n",
            "Epoch 71/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.5004 - accuracy: 0.6228 - categorical_accuracy: 0.6228 - val_loss: 0.4959 - val_accuracy: 0.6333 - val_categorical_accuracy: 0.6333\n",
            "Epoch 72/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5050 - accuracy: 0.6267 - categorical_accuracy: 0.6267 - val_loss: 0.4933 - val_accuracy: 0.6333 - val_categorical_accuracy: 0.6333\n",
            "Epoch 73/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.4913 - accuracy: 0.6336 - categorical_accuracy: 0.6336 - val_loss: 0.4908 - val_accuracy: 0.6333 - val_categorical_accuracy: 0.6333\n",
            "Epoch 74/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4966 - accuracy: 0.6170 - categorical_accuracy: 0.6170 - val_loss: 0.4884 - val_accuracy: 0.6342 - val_categorical_accuracy: 0.6342\n",
            "Epoch 75/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4815 - accuracy: 0.6405 - categorical_accuracy: 0.6405 - val_loss: 0.4860 - val_accuracy: 0.6342 - val_categorical_accuracy: 0.6342\n",
            "Epoch 76/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4790 - accuracy: 0.6354 - categorical_accuracy: 0.6354 - val_loss: 0.4838 - val_accuracy: 0.6342 - val_categorical_accuracy: 0.6342\n",
            "Epoch 77/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4814 - accuracy: 0.6353 - categorical_accuracy: 0.6353 - val_loss: 0.4817 - val_accuracy: 0.6342 - val_categorical_accuracy: 0.6342\n",
            "Epoch 78/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4804 - accuracy: 0.6321 - categorical_accuracy: 0.6321 - val_loss: 0.4794 - val_accuracy: 0.6547 - val_categorical_accuracy: 0.6547\n",
            "Epoch 79/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4682 - accuracy: 0.6347 - categorical_accuracy: 0.6347 - val_loss: 0.4773 - val_accuracy: 0.6573 - val_categorical_accuracy: 0.6573\n",
            "Epoch 80/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.4729 - accuracy: 0.6430 - categorical_accuracy: 0.6430 - val_loss: 0.4752 - val_accuracy: 0.6624 - val_categorical_accuracy: 0.6624\n",
            "Epoch 81/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4567 - accuracy: 0.6649 - categorical_accuracy: 0.6649 - val_loss: 0.4731 - val_accuracy: 0.6624 - val_categorical_accuracy: 0.6624\n",
            "Epoch 82/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4626 - accuracy: 0.6498 - categorical_accuracy: 0.6498 - val_loss: 0.4709 - val_accuracy: 0.6607 - val_categorical_accuracy: 0.6607\n",
            "Epoch 83/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4536 - accuracy: 0.6492 - categorical_accuracy: 0.6492 - val_loss: 0.4686 - val_accuracy: 0.6607 - val_categorical_accuracy: 0.6607\n",
            "Epoch 84/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4596 - accuracy: 0.6512 - categorical_accuracy: 0.6512 - val_loss: 0.4662 - val_accuracy: 0.6615 - val_categorical_accuracy: 0.6615\n",
            "Epoch 85/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4598 - accuracy: 0.6454 - categorical_accuracy: 0.6454 - val_loss: 0.4636 - val_accuracy: 0.6615 - val_categorical_accuracy: 0.6615\n",
            "Epoch 86/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4556 - accuracy: 0.6521 - categorical_accuracy: 0.6521 - val_loss: 0.4609 - val_accuracy: 0.6615 - val_categorical_accuracy: 0.6615\n",
            "Epoch 87/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4590 - accuracy: 0.6468 - categorical_accuracy: 0.6468 - val_loss: 0.4583 - val_accuracy: 0.6615 - val_categorical_accuracy: 0.6615\n",
            "Epoch 88/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4513 - accuracy: 0.6524 - categorical_accuracy: 0.6524 - val_loss: 0.4556 - val_accuracy: 0.6615 - val_categorical_accuracy: 0.6615\n",
            "Epoch 89/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.4264 - accuracy: 0.6645 - categorical_accuracy: 0.6645 - val_loss: 0.4530 - val_accuracy: 0.6821 - val_categorical_accuracy: 0.6821\n",
            "Epoch 90/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4451 - accuracy: 0.6579 - categorical_accuracy: 0.6579 - val_loss: 0.4503 - val_accuracy: 0.6829 - val_categorical_accuracy: 0.6829\n",
            "Epoch 91/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4321 - accuracy: 0.6622 - categorical_accuracy: 0.6622 - val_loss: 0.4478 - val_accuracy: 0.6829 - val_categorical_accuracy: 0.6829\n",
            "Epoch 92/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4316 - accuracy: 0.6710 - categorical_accuracy: 0.6710 - val_loss: 0.4452 - val_accuracy: 0.6829 - val_categorical_accuracy: 0.6829\n",
            "Epoch 93/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4356 - accuracy: 0.6620 - categorical_accuracy: 0.6620 - val_loss: 0.4428 - val_accuracy: 0.6838 - val_categorical_accuracy: 0.6838\n",
            "Epoch 94/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4197 - accuracy: 0.6826 - categorical_accuracy: 0.6826 - val_loss: 0.4403 - val_accuracy: 0.7009 - val_categorical_accuracy: 0.7009\n",
            "Epoch 95/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4323 - accuracy: 0.6760 - categorical_accuracy: 0.6760 - val_loss: 0.4377 - val_accuracy: 0.7043 - val_categorical_accuracy: 0.7043\n",
            "Epoch 96/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.4324 - accuracy: 0.6718 - categorical_accuracy: 0.6718 - val_loss: 0.4352 - val_accuracy: 0.7043 - val_categorical_accuracy: 0.7043\n",
            "Epoch 97/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4230 - accuracy: 0.6795 - categorical_accuracy: 0.6795 - val_loss: 0.4325 - val_accuracy: 0.7068 - val_categorical_accuracy: 0.7068\n",
            "Epoch 98/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.3954 - accuracy: 0.7145 - categorical_accuracy: 0.7145 - val_loss: 0.4299 - val_accuracy: 0.7077 - val_categorical_accuracy: 0.7077\n",
            "Epoch 99/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4081 - accuracy: 0.6878 - categorical_accuracy: 0.6878 - val_loss: 0.4271 - val_accuracy: 0.7077 - val_categorical_accuracy: 0.7077\n",
            "Epoch 100/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4104 - accuracy: 0.6904 - categorical_accuracy: 0.6904 - val_loss: 0.4243 - val_accuracy: 0.7085 - val_categorical_accuracy: 0.7085\n",
            "Epoch 101/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4032 - accuracy: 0.6867 - categorical_accuracy: 0.6867 - val_loss: 0.4213 - val_accuracy: 0.7111 - val_categorical_accuracy: 0.7111\n",
            "Epoch 102/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4025 - accuracy: 0.6975 - categorical_accuracy: 0.6975 - val_loss: 0.4184 - val_accuracy: 0.7111 - val_categorical_accuracy: 0.7111\n",
            "Epoch 103/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4029 - accuracy: 0.6858 - categorical_accuracy: 0.6858 - val_loss: 0.4157 - val_accuracy: 0.7111 - val_categorical_accuracy: 0.7111\n",
            "Epoch 104/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3971 - accuracy: 0.6917 - categorical_accuracy: 0.6917 - val_loss: 0.4130 - val_accuracy: 0.7111 - val_categorical_accuracy: 0.7111\n",
            "Epoch 105/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4016 - accuracy: 0.7018 - categorical_accuracy: 0.7018 - val_loss: 0.4104 - val_accuracy: 0.7111 - val_categorical_accuracy: 0.7111\n",
            "Epoch 106/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3963 - accuracy: 0.6940 - categorical_accuracy: 0.6940 - val_loss: 0.4079 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 107/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.4034 - accuracy: 0.6917 - categorical_accuracy: 0.6917 - val_loss: 0.4056 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 108/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3902 - accuracy: 0.7073 - categorical_accuracy: 0.7073 - val_loss: 0.4035 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 109/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4010 - accuracy: 0.6924 - categorical_accuracy: 0.6924 - val_loss: 0.4015 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 110/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3776 - accuracy: 0.7074 - categorical_accuracy: 0.7074 - val_loss: 0.3995 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 111/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3890 - accuracy: 0.6986 - categorical_accuracy: 0.6986 - val_loss: 0.3977 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 112/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3881 - accuracy: 0.6992 - categorical_accuracy: 0.6992 - val_loss: 0.3959 - val_accuracy: 0.7137 - val_categorical_accuracy: 0.7137\n",
            "Epoch 113/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3639 - accuracy: 0.7108 - categorical_accuracy: 0.7108 - val_loss: 0.3942 - val_accuracy: 0.7137 - val_categorical_accuracy: 0.7137\n",
            "Epoch 114/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.3766 - accuracy: 0.6955 - categorical_accuracy: 0.6955 - val_loss: 0.3925 - val_accuracy: 0.7137 - val_categorical_accuracy: 0.7137\n",
            "Epoch 115/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3743 - accuracy: 0.7026 - categorical_accuracy: 0.7026 - val_loss: 0.3908 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 116/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3654 - accuracy: 0.7179 - categorical_accuracy: 0.7179 - val_loss: 0.3892 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 117/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3653 - accuracy: 0.7039 - categorical_accuracy: 0.7039 - val_loss: 0.3875 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 118/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.3684 - accuracy: 0.7175 - categorical_accuracy: 0.7175 - val_loss: 0.3859 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 119/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3856 - accuracy: 0.6832 - categorical_accuracy: 0.6832 - val_loss: 0.3844 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 120/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3804 - accuracy: 0.7077 - categorical_accuracy: 0.7077 - val_loss: 0.3828 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 121/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3705 - accuracy: 0.6966 - categorical_accuracy: 0.6966 - val_loss: 0.3812 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 122/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3562 - accuracy: 0.7173 - categorical_accuracy: 0.7173 - val_loss: 0.3797 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 123/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.3634 - accuracy: 0.7079 - categorical_accuracy: 0.7079 - val_loss: 0.3781 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 124/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3558 - accuracy: 0.7125 - categorical_accuracy: 0.7125 - val_loss: 0.3766 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 125/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3622 - accuracy: 0.7144 - categorical_accuracy: 0.7144 - val_loss: 0.3751 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 126/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3606 - accuracy: 0.7214 - categorical_accuracy: 0.7214 - val_loss: 0.3736 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 127/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3670 - accuracy: 0.7103 - categorical_accuracy: 0.7103 - val_loss: 0.3721 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 128/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3413 - accuracy: 0.7065 - categorical_accuracy: 0.7065 - val_loss: 0.3705 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 129/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.3475 - accuracy: 0.7023 - categorical_accuracy: 0.7023 - val_loss: 0.3690 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 130/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3375 - accuracy: 0.7279 - categorical_accuracy: 0.7279 - val_loss: 0.3674 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 131/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3516 - accuracy: 0.7218 - categorical_accuracy: 0.7218 - val_loss: 0.3659 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 132/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3428 - accuracy: 0.7113 - categorical_accuracy: 0.7113 - val_loss: 0.3643 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 133/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3374 - accuracy: 0.7185 - categorical_accuracy: 0.7185 - val_loss: 0.3627 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 134/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.3453 - accuracy: 0.7128 - categorical_accuracy: 0.7128 - val_loss: 0.3610 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 135/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3267 - accuracy: 0.7275 - categorical_accuracy: 0.7275 - val_loss: 0.3594 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 136/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3378 - accuracy: 0.7062 - categorical_accuracy: 0.7062 - val_loss: 0.3577 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 137/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3309 - accuracy: 0.7264 - categorical_accuracy: 0.7264 - val_loss: 0.3559 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 138/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.3364 - accuracy: 0.7130 - categorical_accuracy: 0.7130 - val_loss: 0.3541 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 139/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3430 - accuracy: 0.7146 - categorical_accuracy: 0.7146 - val_loss: 0.3522 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 140/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3361 - accuracy: 0.7048 - categorical_accuracy: 0.7048 - val_loss: 0.3503 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 141/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.3371 - accuracy: 0.7136 - categorical_accuracy: 0.7136 - val_loss: 0.3483 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 142/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3376 - accuracy: 0.7111 - categorical_accuracy: 0.7111 - val_loss: 0.3463 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 143/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3315 - accuracy: 0.7166 - categorical_accuracy: 0.7166 - val_loss: 0.3442 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 144/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3334 - accuracy: 0.7064 - categorical_accuracy: 0.7064 - val_loss: 0.3420 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 145/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3149 - accuracy: 0.7165 - categorical_accuracy: 0.7165 - val_loss: 0.3397 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 146/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3210 - accuracy: 0.7251 - categorical_accuracy: 0.7251 - val_loss: 0.3373 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 147/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3217 - accuracy: 0.7115 - categorical_accuracy: 0.7115 - val_loss: 0.3348 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 148/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3137 - accuracy: 0.7209 - categorical_accuracy: 0.7209 - val_loss: 0.3322 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 149/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3066 - accuracy: 0.7358 - categorical_accuracy: 0.7358 - val_loss: 0.3294 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 150/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.3035 - accuracy: 0.7256 - categorical_accuracy: 0.7256 - val_loss: 0.3265 - val_accuracy: 0.7120 - val_categorical_accuracy: 0.7120\n",
            "Epoch 151/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3013 - accuracy: 0.7159 - categorical_accuracy: 0.7159 - val_loss: 0.3236 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 152/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2886 - accuracy: 0.7175 - categorical_accuracy: 0.7175 - val_loss: 0.3207 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 153/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.3059 - accuracy: 0.7029 - categorical_accuracy: 0.7029 - val_loss: 0.3180 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 154/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2971 - accuracy: 0.7265 - categorical_accuracy: 0.7265 - val_loss: 0.3152 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 155/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3091 - accuracy: 0.7142 - categorical_accuracy: 0.7142 - val_loss: 0.3126 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 156/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2912 - accuracy: 0.7202 - categorical_accuracy: 0.7202 - val_loss: 0.3102 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 157/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.2917 - accuracy: 0.7120 - categorical_accuracy: 0.7120 - val_loss: 0.3078 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 158/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2896 - accuracy: 0.7181 - categorical_accuracy: 0.7181 - val_loss: 0.3056 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 159/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.2924 - accuracy: 0.7089 - categorical_accuracy: 0.7089 - val_loss: 0.3035 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 160/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2878 - accuracy: 0.7174 - categorical_accuracy: 0.7174 - val_loss: 0.3016 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 161/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2873 - accuracy: 0.7172 - categorical_accuracy: 0.7172 - val_loss: 0.2998 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 162/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.2832 - accuracy: 0.7142 - categorical_accuracy: 0.7142 - val_loss: 0.2980 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 163/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2809 - accuracy: 0.7191 - categorical_accuracy: 0.7191 - val_loss: 0.2962 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 164/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.2871 - accuracy: 0.7116 - categorical_accuracy: 0.7116 - val_loss: 0.2945 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 165/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2691 - accuracy: 0.7273 - categorical_accuracy: 0.7273 - val_loss: 0.2929 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 166/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2736 - accuracy: 0.7163 - categorical_accuracy: 0.7163 - val_loss: 0.2912 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 167/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2662 - accuracy: 0.7157 - categorical_accuracy: 0.7157 - val_loss: 0.2895 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 168/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2676 - accuracy: 0.7153 - categorical_accuracy: 0.7153 - val_loss: 0.2879 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 169/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.2659 - accuracy: 0.7197 - categorical_accuracy: 0.7197 - val_loss: 0.2862 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 170/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2697 - accuracy: 0.7247 - categorical_accuracy: 0.7247 - val_loss: 0.2846 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 171/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2732 - accuracy: 0.7131 - categorical_accuracy: 0.7131 - val_loss: 0.2829 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 172/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2798 - accuracy: 0.7148 - categorical_accuracy: 0.7148 - val_loss: 0.2813 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 173/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2692 - accuracy: 0.7205 - categorical_accuracy: 0.7205 - val_loss: 0.2797 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 174/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2679 - accuracy: 0.7102 - categorical_accuracy: 0.7102 - val_loss: 0.2780 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 175/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2750 - accuracy: 0.7188 - categorical_accuracy: 0.7188 - val_loss: 0.2764 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 176/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2610 - accuracy: 0.7114 - categorical_accuracy: 0.7114 - val_loss: 0.2747 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 177/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2456 - accuracy: 0.7201 - categorical_accuracy: 0.7201 - val_loss: 0.2730 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 178/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.2595 - accuracy: 0.7188 - categorical_accuracy: 0.7188 - val_loss: 0.2713 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 179/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2640 - accuracy: 0.7118 - categorical_accuracy: 0.7118 - val_loss: 0.2696 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 180/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.2433 - accuracy: 0.7159 - categorical_accuracy: 0.7159 - val_loss: 0.2678 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 181/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2421 - accuracy: 0.7189 - categorical_accuracy: 0.7189 - val_loss: 0.2661 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 182/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2564 - accuracy: 0.7177 - categorical_accuracy: 0.7177 - val_loss: 0.2643 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 183/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2465 - accuracy: 0.7149 - categorical_accuracy: 0.7149 - val_loss: 0.2626 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 184/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2445 - accuracy: 0.7174 - categorical_accuracy: 0.7174 - val_loss: 0.2608 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 185/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.2420 - accuracy: 0.7152 - categorical_accuracy: 0.7152 - val_loss: 0.2591 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 186/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2425 - accuracy: 0.7116 - categorical_accuracy: 0.7116 - val_loss: 0.2573 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 187/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2348 - accuracy: 0.7252 - categorical_accuracy: 0.7252 - val_loss: 0.2556 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 188/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.2400 - accuracy: 0.7101 - categorical_accuracy: 0.7101 - val_loss: 0.2538 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 189/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2404 - accuracy: 0.7111 - categorical_accuracy: 0.7111 - val_loss: 0.2520 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 190/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.2366 - accuracy: 0.7154 - categorical_accuracy: 0.7154 - val_loss: 0.2503 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 191/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2339 - accuracy: 0.7214 - categorical_accuracy: 0.7214 - val_loss: 0.2485 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 192/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2170 - accuracy: 0.7259 - categorical_accuracy: 0.7259 - val_loss: 0.2468 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 193/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2346 - accuracy: 0.7100 - categorical_accuracy: 0.7100 - val_loss: 0.2451 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 194/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2249 - accuracy: 0.7225 - categorical_accuracy: 0.7225 - val_loss: 0.2433 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 195/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.2303 - accuracy: 0.7100 - categorical_accuracy: 0.7100 - val_loss: 0.2416 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 196/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2227 - accuracy: 0.7232 - categorical_accuracy: 0.7232 - val_loss: 0.2399 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 197/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2203 - accuracy: 0.7228 - categorical_accuracy: 0.7228 - val_loss: 0.2383 - val_accuracy: 0.7128 - val_categorical_accuracy: 0.7128\n",
            "Epoch 198/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2245 - accuracy: 0.7226 - categorical_accuracy: 0.7226 - val_loss: 0.2366 - val_accuracy: 0.7145 - val_categorical_accuracy: 0.7145\n",
            "Epoch 199/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2214 - accuracy: 0.7172 - categorical_accuracy: 0.7172 - val_loss: 0.2350 - val_accuracy: 0.7171 - val_categorical_accuracy: 0.7171\n",
            "Epoch 200/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2104 - accuracy: 0.7159 - categorical_accuracy: 0.7159 - val_loss: 0.2334 - val_accuracy: 0.7171 - val_categorical_accuracy: 0.7171\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.2334 - accuracy: 0.7171 - categorical_accuracy: 0.7171\n",
            "1142\n",
            "Generation-8 Chromosome-9:\n",
            "Middle layers: 2 | Activation: selu | Optimization: Adadelta | Loss: categorical_hinge | LR: 0.0001 | Dropout: 0.15 |\n",
            "\tScore 0.64  | Accuracy: 0.72\n",
            "Epoch 1/200\n",
            "351/351 [==============================] - 6s 14ms/step - loss: 0.9709 - accuracy: 0.0972 - categorical_accuracy: 0.0972 - val_loss: 0.9639 - val_accuracy: 0.4479 - val_categorical_accuracy: 0.4479\n",
            "Epoch 2/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.9608 - accuracy: 0.4152 - categorical_accuracy: 0.4152 - val_loss: 0.9189 - val_accuracy: 0.4726 - val_categorical_accuracy: 0.4726\n",
            "Epoch 3/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.8641 - accuracy: 0.4795 - categorical_accuracy: 0.4795 - val_loss: 0.7352 - val_accuracy: 0.5325 - val_categorical_accuracy: 0.5325\n",
            "Epoch 4/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7206 - accuracy: 0.5408 - categorical_accuracy: 0.5408 - val_loss: 0.7049 - val_accuracy: 0.5368 - val_categorical_accuracy: 0.5368\n",
            "Epoch 5/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.7095 - accuracy: 0.5498 - categorical_accuracy: 0.5498 - val_loss: 0.6874 - val_accuracy: 0.5453 - val_categorical_accuracy: 0.5453\n",
            "Epoch 6/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6797 - accuracy: 0.5482 - categorical_accuracy: 0.5482 - val_loss: 0.6739 - val_accuracy: 0.5479 - val_categorical_accuracy: 0.5479\n",
            "Epoch 7/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6811 - accuracy: 0.5507 - categorical_accuracy: 0.5507 - val_loss: 0.6624 - val_accuracy: 0.5513 - val_categorical_accuracy: 0.5513\n",
            "Epoch 8/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6640 - accuracy: 0.5653 - categorical_accuracy: 0.5653 - val_loss: 0.6519 - val_accuracy: 0.5855 - val_categorical_accuracy: 0.5855\n",
            "Epoch 9/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6453 - accuracy: 0.5868 - categorical_accuracy: 0.5868 - val_loss: 0.6418 - val_accuracy: 0.6068 - val_categorical_accuracy: 0.6068\n",
            "Epoch 10/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6321 - accuracy: 0.6227 - categorical_accuracy: 0.6227 - val_loss: 0.6306 - val_accuracy: 0.6658 - val_categorical_accuracy: 0.6658\n",
            "Epoch 11/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.6290 - accuracy: 0.6461 - categorical_accuracy: 0.6461 - val_loss: 0.6165 - val_accuracy: 0.6675 - val_categorical_accuracy: 0.6675\n",
            "Epoch 12/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.6293 - accuracy: 0.6525 - categorical_accuracy: 0.6525 - val_loss: 0.5948 - val_accuracy: 0.6470 - val_categorical_accuracy: 0.6470\n",
            "Epoch 13/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.5809 - accuracy: 0.6736 - categorical_accuracy: 0.6736 - val_loss: 0.5685 - val_accuracy: 0.6487 - val_categorical_accuracy: 0.6487\n",
            "Epoch 14/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.5704 - accuracy: 0.6728 - categorical_accuracy: 0.6728 - val_loss: 0.5391 - val_accuracy: 0.6949 - val_categorical_accuracy: 0.6949\n",
            "Epoch 15/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.5111 - accuracy: 0.6989 - categorical_accuracy: 0.6989 - val_loss: 0.5098 - val_accuracy: 0.6957 - val_categorical_accuracy: 0.6957\n",
            "Epoch 16/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.4876 - accuracy: 0.7014 - categorical_accuracy: 0.7014 - val_loss: 0.4869 - val_accuracy: 0.7111 - val_categorical_accuracy: 0.7111\n",
            "Epoch 17/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.4707 - accuracy: 0.7113 - categorical_accuracy: 0.7113 - val_loss: 0.4687 - val_accuracy: 0.7154 - val_categorical_accuracy: 0.7154\n",
            "Epoch 18/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.4697 - accuracy: 0.7079 - categorical_accuracy: 0.7079 - val_loss: 0.4558 - val_accuracy: 0.7325 - val_categorical_accuracy: 0.7325\n",
            "Epoch 19/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.4395 - accuracy: 0.7345 - categorical_accuracy: 0.7345 - val_loss: 0.4471 - val_accuracy: 0.7376 - val_categorical_accuracy: 0.7376\n",
            "Epoch 20/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.4444 - accuracy: 0.7337 - categorical_accuracy: 0.7337 - val_loss: 0.4388 - val_accuracy: 0.7419 - val_categorical_accuracy: 0.7419\n",
            "Epoch 21/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.4109 - accuracy: 0.7542 - categorical_accuracy: 0.7542 - val_loss: 0.4304 - val_accuracy: 0.7419 - val_categorical_accuracy: 0.7419\n",
            "Epoch 22/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.4110 - accuracy: 0.7583 - categorical_accuracy: 0.7583 - val_loss: 0.4238 - val_accuracy: 0.7444 - val_categorical_accuracy: 0.7444\n",
            "Epoch 23/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.3991 - accuracy: 0.7494 - categorical_accuracy: 0.7494 - val_loss: 0.4192 - val_accuracy: 0.7675 - val_categorical_accuracy: 0.7675\n",
            "Epoch 24/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.4094 - accuracy: 0.7588 - categorical_accuracy: 0.7588 - val_loss: 0.4156 - val_accuracy: 0.7675 - val_categorical_accuracy: 0.7675\n",
            "Epoch 25/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.4259 - accuracy: 0.7448 - categorical_accuracy: 0.7448 - val_loss: 0.4127 - val_accuracy: 0.7675 - val_categorical_accuracy: 0.7675\n",
            "Epoch 26/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.4039 - accuracy: 0.7427 - categorical_accuracy: 0.7427 - val_loss: 0.4096 - val_accuracy: 0.7675 - val_categorical_accuracy: 0.7675\n",
            "Epoch 27/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.3982 - accuracy: 0.7586 - categorical_accuracy: 0.7586 - val_loss: 0.4067 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 28/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.3918 - accuracy: 0.7600 - categorical_accuracy: 0.7600 - val_loss: 0.4035 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 29/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.3885 - accuracy: 0.7695 - categorical_accuracy: 0.7695 - val_loss: 0.3998 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 30/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.3911 - accuracy: 0.7679 - categorical_accuracy: 0.7679 - val_loss: 0.3952 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 31/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.3803 - accuracy: 0.7815 - categorical_accuracy: 0.7815 - val_loss: 0.3907 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 32/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.3764 - accuracy: 0.7682 - categorical_accuracy: 0.7682 - val_loss: 0.3861 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 33/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.3897 - accuracy: 0.7550 - categorical_accuracy: 0.7550 - val_loss: 0.3824 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 34/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.3663 - accuracy: 0.7677 - categorical_accuracy: 0.7677 - val_loss: 0.3789 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 35/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.3577 - accuracy: 0.7668 - categorical_accuracy: 0.7668 - val_loss: 0.3753 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 36/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.3701 - accuracy: 0.7621 - categorical_accuracy: 0.7621 - val_loss: 0.3714 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 37/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.3500 - accuracy: 0.7740 - categorical_accuracy: 0.7740 - val_loss: 0.3667 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 38/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.3538 - accuracy: 0.7656 - categorical_accuracy: 0.7656 - val_loss: 0.3609 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 39/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.3523 - accuracy: 0.7696 - categorical_accuracy: 0.7696 - val_loss: 0.3534 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 40/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.3432 - accuracy: 0.7643 - categorical_accuracy: 0.7643 - val_loss: 0.3433 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 41/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.3241 - accuracy: 0.7641 - categorical_accuracy: 0.7641 - val_loss: 0.3295 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 42/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.3093 - accuracy: 0.7780 - categorical_accuracy: 0.7780 - val_loss: 0.3140 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 43/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.3198 - accuracy: 0.7555 - categorical_accuracy: 0.7555 - val_loss: 0.2995 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 44/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.2964 - accuracy: 0.7524 - categorical_accuracy: 0.7524 - val_loss: 0.2863 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 45/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.2812 - accuracy: 0.7657 - categorical_accuracy: 0.7657 - val_loss: 0.2740 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 46/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.2554 - accuracy: 0.7740 - categorical_accuracy: 0.7740 - val_loss: 0.2622 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 47/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.2515 - accuracy: 0.7726 - categorical_accuracy: 0.7726 - val_loss: 0.2508 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 48/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.2321 - accuracy: 0.7531 - categorical_accuracy: 0.7531 - val_loss: 0.2395 - val_accuracy: 0.7701 - val_categorical_accuracy: 0.7701\n",
            "Epoch 49/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.2289 - accuracy: 0.7768 - categorical_accuracy: 0.7768 - val_loss: 0.2284 - val_accuracy: 0.7855 - val_categorical_accuracy: 0.7855\n",
            "Epoch 50/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.2124 - accuracy: 0.7856 - categorical_accuracy: 0.7856 - val_loss: 0.2176 - val_accuracy: 0.7855 - val_categorical_accuracy: 0.7855\n",
            "Epoch 51/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.2130 - accuracy: 0.7625 - categorical_accuracy: 0.7625 - val_loss: 0.2075 - val_accuracy: 0.7855 - val_categorical_accuracy: 0.7855\n",
            "Epoch 52/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.2000 - accuracy: 0.7734 - categorical_accuracy: 0.7734 - val_loss: 0.1987 - val_accuracy: 0.7855 - val_categorical_accuracy: 0.7855\n",
            "Epoch 53/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1867 - accuracy: 0.7866 - categorical_accuracy: 0.7866 - val_loss: 0.1911 - val_accuracy: 0.7838 - val_categorical_accuracy: 0.7838\n",
            "Epoch 54/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1996 - accuracy: 0.7840 - categorical_accuracy: 0.7840 - val_loss: 0.1844 - val_accuracy: 0.7838 - val_categorical_accuracy: 0.7838\n",
            "Epoch 55/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1811 - accuracy: 0.7865 - categorical_accuracy: 0.7865 - val_loss: 0.1784 - val_accuracy: 0.7838 - val_categorical_accuracy: 0.7838\n",
            "Epoch 56/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.1592 - accuracy: 0.7864 - categorical_accuracy: 0.7864 - val_loss: 0.1732 - val_accuracy: 0.7838 - val_categorical_accuracy: 0.7838\n",
            "Epoch 57/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1733 - accuracy: 0.7869 - categorical_accuracy: 0.7869 - val_loss: 0.1685 - val_accuracy: 0.7872 - val_categorical_accuracy: 0.7872\n",
            "Epoch 58/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1580 - accuracy: 0.7930 - categorical_accuracy: 0.7930 - val_loss: 0.1644 - val_accuracy: 0.7872 - val_categorical_accuracy: 0.7872\n",
            "Epoch 59/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1563 - accuracy: 0.7857 - categorical_accuracy: 0.7857 - val_loss: 0.1605 - val_accuracy: 0.7897 - val_categorical_accuracy: 0.7897\n",
            "Epoch 60/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.1492 - accuracy: 0.7901 - categorical_accuracy: 0.7901 - val_loss: 0.1568 - val_accuracy: 0.7915 - val_categorical_accuracy: 0.7915\n",
            "Epoch 61/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1509 - accuracy: 0.7890 - categorical_accuracy: 0.7890 - val_loss: 0.1532 - val_accuracy: 0.7915 - val_categorical_accuracy: 0.7915\n",
            "Epoch 62/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1459 - accuracy: 0.7849 - categorical_accuracy: 0.7849 - val_loss: 0.1495 - val_accuracy: 0.7915 - val_categorical_accuracy: 0.7915\n",
            "Epoch 63/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1487 - accuracy: 0.7816 - categorical_accuracy: 0.7816 - val_loss: 0.1459 - val_accuracy: 0.7915 - val_categorical_accuracy: 0.7915\n",
            "Epoch 64/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1391 - accuracy: 0.7928 - categorical_accuracy: 0.7928 - val_loss: 0.1423 - val_accuracy: 0.7915 - val_categorical_accuracy: 0.7915\n",
            "Epoch 65/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1357 - accuracy: 0.7993 - categorical_accuracy: 0.7993 - val_loss: 0.1389 - val_accuracy: 0.7915 - val_categorical_accuracy: 0.7915\n",
            "Epoch 66/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1404 - accuracy: 0.7841 - categorical_accuracy: 0.7841 - val_loss: 0.1359 - val_accuracy: 0.7915 - val_categorical_accuracy: 0.7915\n",
            "Epoch 67/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1279 - accuracy: 0.7962 - categorical_accuracy: 0.7962 - val_loss: 0.1334 - val_accuracy: 0.7915 - val_categorical_accuracy: 0.7915\n",
            "Epoch 68/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.1276 - accuracy: 0.7852 - categorical_accuracy: 0.7852 - val_loss: 0.1311 - val_accuracy: 0.7915 - val_categorical_accuracy: 0.7915\n",
            "Epoch 69/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1180 - accuracy: 0.7876 - categorical_accuracy: 0.7876 - val_loss: 0.1291 - val_accuracy: 0.7915 - val_categorical_accuracy: 0.7915\n",
            "Epoch 70/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1270 - accuracy: 0.7872 - categorical_accuracy: 0.7872 - val_loss: 0.1273 - val_accuracy: 0.7915 - val_categorical_accuracy: 0.7915\n",
            "Epoch 71/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1226 - accuracy: 0.7903 - categorical_accuracy: 0.7903 - val_loss: 0.1256 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 72/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.1124 - accuracy: 0.7925 - categorical_accuracy: 0.7925 - val_loss: 0.1240 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 73/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1340 - accuracy: 0.7738 - categorical_accuracy: 0.7738 - val_loss: 0.1225 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 74/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1188 - accuracy: 0.7924 - categorical_accuracy: 0.7924 - val_loss: 0.1209 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 75/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1151 - accuracy: 0.7943 - categorical_accuracy: 0.7943 - val_loss: 0.1192 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 76/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1165 - accuracy: 0.7955 - categorical_accuracy: 0.7955 - val_loss: 0.1174 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 77/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1205 - accuracy: 0.7931 - categorical_accuracy: 0.7931 - val_loss: 0.1156 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 78/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1187 - accuracy: 0.7864 - categorical_accuracy: 0.7864 - val_loss: 0.1137 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 79/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1116 - accuracy: 0.7999 - categorical_accuracy: 0.7999 - val_loss: 0.1119 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 80/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.1080 - accuracy: 0.7812 - categorical_accuracy: 0.7812 - val_loss: 0.1101 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 81/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0995 - accuracy: 0.7998 - categorical_accuracy: 0.7998 - val_loss: 0.1084 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 82/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1063 - accuracy: 0.7880 - categorical_accuracy: 0.7880 - val_loss: 0.1069 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 83/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0928 - accuracy: 0.7991 - categorical_accuracy: 0.7991 - val_loss: 0.1056 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 84/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.0947 - accuracy: 0.7910 - categorical_accuracy: 0.7910 - val_loss: 0.1045 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 85/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0895 - accuracy: 0.7895 - categorical_accuracy: 0.7895 - val_loss: 0.1035 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 86/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1008 - accuracy: 0.7783 - categorical_accuracy: 0.7783 - val_loss: 0.1027 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 87/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.1007 - accuracy: 0.7949 - categorical_accuracy: 0.7949 - val_loss: 0.1019 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 88/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.1014 - accuracy: 0.7968 - categorical_accuracy: 0.7968 - val_loss: 0.1013 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 89/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0931 - accuracy: 0.7864 - categorical_accuracy: 0.7864 - val_loss: 0.1007 - val_accuracy: 0.7932 - val_categorical_accuracy: 0.7932\n",
            "Epoch 90/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0890 - accuracy: 0.7918 - categorical_accuracy: 0.7918 - val_loss: 0.1002 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 91/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0939 - accuracy: 0.7902 - categorical_accuracy: 0.7902 - val_loss: 0.0997 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 92/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0932 - accuracy: 0.7868 - categorical_accuracy: 0.7868 - val_loss: 0.0993 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 93/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0942 - accuracy: 0.7860 - categorical_accuracy: 0.7860 - val_loss: 0.0989 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 94/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0832 - accuracy: 0.7961 - categorical_accuracy: 0.7961 - val_loss: 0.0986 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 95/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0918 - accuracy: 0.8006 - categorical_accuracy: 0.8006 - val_loss: 0.0982 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 96/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.0874 - accuracy: 0.7972 - categorical_accuracy: 0.7972 - val_loss: 0.0980 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 97/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0834 - accuracy: 0.7924 - categorical_accuracy: 0.7924 - val_loss: 0.0976 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 98/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0810 - accuracy: 0.7998 - categorical_accuracy: 0.7998 - val_loss: 0.0974 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 99/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0873 - accuracy: 0.7920 - categorical_accuracy: 0.7920 - val_loss: 0.0971 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 100/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.0803 - accuracy: 0.8015 - categorical_accuracy: 0.8015 - val_loss: 0.0968 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 101/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0824 - accuracy: 0.8031 - categorical_accuracy: 0.8031 - val_loss: 0.0966 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 102/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0934 - accuracy: 0.8108 - categorical_accuracy: 0.8108 - val_loss: 0.0964 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 103/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0759 - accuracy: 0.7962 - categorical_accuracy: 0.7962 - val_loss: 0.0961 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 104/200\n",
            "351/351 [==============================] - 5s 13ms/step - loss: 0.0829 - accuracy: 0.7999 - categorical_accuracy: 0.7999 - val_loss: 0.0959 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 105/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0855 - accuracy: 0.8114 - categorical_accuracy: 0.8114 - val_loss: 0.0957 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 106/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0770 - accuracy: 0.8061 - categorical_accuracy: 0.8061 - val_loss: 0.0954 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 107/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0917 - accuracy: 0.7911 - categorical_accuracy: 0.7911 - val_loss: 0.0952 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 108/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0981 - accuracy: 0.7933 - categorical_accuracy: 0.7933 - val_loss: 0.0950 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 109/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0876 - accuracy: 0.7996 - categorical_accuracy: 0.7996 - val_loss: 0.0948 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 110/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0849 - accuracy: 0.7948 - categorical_accuracy: 0.7948 - val_loss: 0.0946 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 111/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0862 - accuracy: 0.8022 - categorical_accuracy: 0.8022 - val_loss: 0.0944 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 112/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0807 - accuracy: 0.7962 - categorical_accuracy: 0.7962 - val_loss: 0.0942 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 113/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0833 - accuracy: 0.7988 - categorical_accuracy: 0.7988 - val_loss: 0.0940 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 114/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0850 - accuracy: 0.7991 - categorical_accuracy: 0.7991 - val_loss: 0.0938 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 115/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0859 - accuracy: 0.7971 - categorical_accuracy: 0.7971 - val_loss: 0.0936 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 116/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0810 - accuracy: 0.7957 - categorical_accuracy: 0.7957 - val_loss: 0.0934 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 117/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0759 - accuracy: 0.8005 - categorical_accuracy: 0.8005 - val_loss: 0.0932 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 118/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0839 - accuracy: 0.7999 - categorical_accuracy: 0.7999 - val_loss: 0.0930 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 119/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0942 - accuracy: 0.7960 - categorical_accuracy: 0.7960 - val_loss: 0.0928 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 120/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0869 - accuracy: 0.8065 - categorical_accuracy: 0.8065 - val_loss: 0.0926 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 121/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0933 - accuracy: 0.8088 - categorical_accuracy: 0.8088 - val_loss: 0.0924 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 122/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.0737 - accuracy: 0.8062 - categorical_accuracy: 0.8062 - val_loss: 0.0923 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 123/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0879 - accuracy: 0.7995 - categorical_accuracy: 0.7995 - val_loss: 0.0921 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 124/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0903 - accuracy: 0.7939 - categorical_accuracy: 0.7939 - val_loss: 0.0919 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 125/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0881 - accuracy: 0.8004 - categorical_accuracy: 0.8004 - val_loss: 0.0918 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 126/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0872 - accuracy: 0.7919 - categorical_accuracy: 0.7919 - val_loss: 0.0916 - val_accuracy: 0.7966 - val_categorical_accuracy: 0.7966\n",
            "Epoch 127/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0762 - accuracy: 0.8074 - categorical_accuracy: 0.8074 - val_loss: 0.0914 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 128/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.0794 - accuracy: 0.7980 - categorical_accuracy: 0.7980 - val_loss: 0.0912 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 129/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0877 - accuracy: 0.7973 - categorical_accuracy: 0.7973 - val_loss: 0.0911 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 130/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0835 - accuracy: 0.7956 - categorical_accuracy: 0.7956 - val_loss: 0.0909 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 131/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0909 - accuracy: 0.7983 - categorical_accuracy: 0.7983 - val_loss: 0.0907 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 132/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.0805 - accuracy: 0.7914 - categorical_accuracy: 0.7914 - val_loss: 0.0906 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 133/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0801 - accuracy: 0.7949 - categorical_accuracy: 0.7949 - val_loss: 0.0904 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 134/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0698 - accuracy: 0.8010 - categorical_accuracy: 0.8010 - val_loss: 0.0902 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 135/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0875 - accuracy: 0.8040 - categorical_accuracy: 0.8040 - val_loss: 0.0900 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 136/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0787 - accuracy: 0.8111 - categorical_accuracy: 0.8111 - val_loss: 0.0899 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 137/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0747 - accuracy: 0.8009 - categorical_accuracy: 0.8009 - val_loss: 0.0897 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 138/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.0794 - accuracy: 0.7924 - categorical_accuracy: 0.7924 - val_loss: 0.0895 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 139/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0834 - accuracy: 0.7997 - categorical_accuracy: 0.7997 - val_loss: 0.0893 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 140/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0789 - accuracy: 0.7942 - categorical_accuracy: 0.7942 - val_loss: 0.0891 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 141/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0873 - accuracy: 0.7943 - categorical_accuracy: 0.7943 - val_loss: 0.0890 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 142/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0744 - accuracy: 0.8023 - categorical_accuracy: 0.8023 - val_loss: 0.0888 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 143/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0907 - accuracy: 0.7993 - categorical_accuracy: 0.7993 - val_loss: 0.0886 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 144/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0743 - accuracy: 0.8021 - categorical_accuracy: 0.8021 - val_loss: 0.0884 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 145/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0833 - accuracy: 0.7880 - categorical_accuracy: 0.7880 - val_loss: 0.0882 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 146/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0785 - accuracy: 0.7875 - categorical_accuracy: 0.7875 - val_loss: 0.0880 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 147/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0725 - accuracy: 0.7975 - categorical_accuracy: 0.7975 - val_loss: 0.0878 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 148/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0787 - accuracy: 0.7949 - categorical_accuracy: 0.7949 - val_loss: 0.0876 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 149/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0771 - accuracy: 0.8005 - categorical_accuracy: 0.8005 - val_loss: 0.0873 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 150/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0888 - accuracy: 0.7917 - categorical_accuracy: 0.7917 - val_loss: 0.0871 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 151/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0868 - accuracy: 0.7870 - categorical_accuracy: 0.7870 - val_loss: 0.0869 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 152/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0798 - accuracy: 0.7949 - categorical_accuracy: 0.7949 - val_loss: 0.0867 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 153/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0789 - accuracy: 0.7949 - categorical_accuracy: 0.7949 - val_loss: 0.0864 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 154/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0719 - accuracy: 0.8047 - categorical_accuracy: 0.8047 - val_loss: 0.0862 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 155/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0785 - accuracy: 0.7968 - categorical_accuracy: 0.7968 - val_loss: 0.0860 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 156/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0767 - accuracy: 0.7906 - categorical_accuracy: 0.7906 - val_loss: 0.0857 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 157/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0726 - accuracy: 0.7955 - categorical_accuracy: 0.7955 - val_loss: 0.0854 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 158/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0848 - accuracy: 0.7919 - categorical_accuracy: 0.7919 - val_loss: 0.0851 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 159/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0753 - accuracy: 0.7989 - categorical_accuracy: 0.7989 - val_loss: 0.0849 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 160/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.0738 - accuracy: 0.7940 - categorical_accuracy: 0.7940 - val_loss: 0.0846 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 161/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0762 - accuracy: 0.7848 - categorical_accuracy: 0.7848 - val_loss: 0.0842 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 162/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0676 - accuracy: 0.8006 - categorical_accuracy: 0.8006 - val_loss: 0.0839 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 163/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0730 - accuracy: 0.7905 - categorical_accuracy: 0.7905 - val_loss: 0.0836 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 164/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.0802 - accuracy: 0.7745 - categorical_accuracy: 0.7745 - val_loss: 0.0832 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 165/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.0768 - accuracy: 0.7935 - categorical_accuracy: 0.7935 - val_loss: 0.0829 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 166/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0703 - accuracy: 0.8008 - categorical_accuracy: 0.8008 - val_loss: 0.0825 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 167/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0743 - accuracy: 0.7952 - categorical_accuracy: 0.7952 - val_loss: 0.0821 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 168/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0754 - accuracy: 0.7923 - categorical_accuracy: 0.7923 - val_loss: 0.0816 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 169/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0712 - accuracy: 0.7966 - categorical_accuracy: 0.7966 - val_loss: 0.0812 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 170/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0658 - accuracy: 0.7963 - categorical_accuracy: 0.7963 - val_loss: 0.0808 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 171/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0684 - accuracy: 0.7897 - categorical_accuracy: 0.7897 - val_loss: 0.0803 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 172/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.0723 - accuracy: 0.7851 - categorical_accuracy: 0.7851 - val_loss: 0.0798 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 173/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0688 - accuracy: 0.7862 - categorical_accuracy: 0.7862 - val_loss: 0.0793 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 174/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0743 - accuracy: 0.7853 - categorical_accuracy: 0.7853 - val_loss: 0.0788 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 175/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0700 - accuracy: 0.7850 - categorical_accuracy: 0.7850 - val_loss: 0.0782 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 176/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0674 - accuracy: 0.7954 - categorical_accuracy: 0.7954 - val_loss: 0.0777 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 177/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0754 - accuracy: 0.7981 - categorical_accuracy: 0.7981 - val_loss: 0.0771 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 178/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0670 - accuracy: 0.8002 - categorical_accuracy: 0.8002 - val_loss: 0.0765 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 179/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0597 - accuracy: 0.7974 - categorical_accuracy: 0.7974 - val_loss: 0.0760 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 180/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0646 - accuracy: 0.8013 - categorical_accuracy: 0.8013 - val_loss: 0.0754 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 181/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0617 - accuracy: 0.7886 - categorical_accuracy: 0.7886 - val_loss: 0.0748 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 182/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0631 - accuracy: 0.7830 - categorical_accuracy: 0.7830 - val_loss: 0.0742 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 183/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0641 - accuracy: 0.7825 - categorical_accuracy: 0.7825 - val_loss: 0.0737 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 184/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0620 - accuracy: 0.7884 - categorical_accuracy: 0.7884 - val_loss: 0.0731 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 185/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0560 - accuracy: 0.7926 - categorical_accuracy: 0.7926 - val_loss: 0.0726 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 186/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0637 - accuracy: 0.7976 - categorical_accuracy: 0.7976 - val_loss: 0.0721 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 187/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0679 - accuracy: 0.7845 - categorical_accuracy: 0.7845 - val_loss: 0.0716 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 188/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0687 - accuracy: 0.7949 - categorical_accuracy: 0.7949 - val_loss: 0.0712 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 189/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0605 - accuracy: 0.7852 - categorical_accuracy: 0.7852 - val_loss: 0.0708 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 190/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.0566 - accuracy: 0.7906 - categorical_accuracy: 0.7906 - val_loss: 0.0704 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 191/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0558 - accuracy: 0.7921 - categorical_accuracy: 0.7921 - val_loss: 0.0700 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 192/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0634 - accuracy: 0.7907 - categorical_accuracy: 0.7907 - val_loss: 0.0697 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 193/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0606 - accuracy: 0.7947 - categorical_accuracy: 0.7947 - val_loss: 0.0694 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 194/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0521 - accuracy: 0.7967 - categorical_accuracy: 0.7967 - val_loss: 0.0691 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 195/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0518 - accuracy: 0.7946 - categorical_accuracy: 0.7946 - val_loss: 0.0688 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 196/200\n",
            "351/351 [==============================] - 4s 13ms/step - loss: 0.0611 - accuracy: 0.7868 - categorical_accuracy: 0.7868 - val_loss: 0.0685 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 197/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0514 - accuracy: 0.7971 - categorical_accuracy: 0.7971 - val_loss: 0.0683 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 198/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0598 - accuracy: 0.7896 - categorical_accuracy: 0.7896 - val_loss: 0.0681 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 199/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0538 - accuracy: 0.7966 - categorical_accuracy: 0.7966 - val_loss: 0.0679 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "Epoch 200/200\n",
            "351/351 [==============================] - 4s 12ms/step - loss: 0.0589 - accuracy: 0.7914 - categorical_accuracy: 0.7914 - val_loss: 0.0677 - val_accuracy: 0.7949 - val_categorical_accuracy: 0.7949\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 0.0677 - accuracy: 0.7949 - categorical_accuracy: 0.7949\n",
            "1102\n",
            "Generation-8 Chromosome-10:\n",
            "Middle layers: 2 | Activation: tanh | Optimization: Adadelta | Loss: categorical_hinge | LR: 0.001 | Dropout: 0.15 |\n",
            "\tScore 0.71  | Accuracy: 0.79\n",
            "[0.6601251418948173, 0.6601251418948173, 0.6814194995999336, 0.6814194995999336, 0.6814194995999336, 0.6814194995999336, 0.7118400106072426, 0.7118400106072426] Best accuracies of each generation\n",
            "[array([2.e+00, 1.e+00, 4.e+00, 0.e+00, 1.e-03, 3.e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01]), array([2.e+00, 5.e+00, 1.e+00, 0.e+00, 1.e-04, 3.e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01]), array([2.e+00, 5.e+00, 1.e+00, 0.e+00, 1.e-04, 3.e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01])] Best of each generation\n",
            "Generation-9 Chromosome-1 scored 0.71  (Chromosome already known)\n",
            "Generation-9 Chromosome-2 scored 0.71  (Chromosome already known)\n",
            "Generation-9 Chromosome-3 scored 0.68  (Chromosome already known)\n",
            "Generation-9 Chromosome-4 scored 0.68  (Chromosome already known)\n",
            "Generation-9 Chromosome-5 scored 0.68  (Chromosome already known)\n",
            "Epoch 1/200\n",
            "351/351 [==============================] - 3s 6ms/step - loss: 0.9858 - accuracy: 0.0382 - categorical_accuracy: 0.0382 - val_loss: 0.9569 - val_accuracy: 0.4692 - val_categorical_accuracy: 0.4692\n",
            "Epoch 2/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.8854 - accuracy: 0.4549 - categorical_accuracy: 0.4549 - val_loss: 0.7045 - val_accuracy: 0.5709 - val_categorical_accuracy: 0.5709\n",
            "Epoch 3/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.6991 - accuracy: 0.5594 - categorical_accuracy: 0.5594 - val_loss: 0.6658 - val_accuracy: 0.6077 - val_categorical_accuracy: 0.6077\n",
            "Epoch 4/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.6550 - accuracy: 0.5979 - categorical_accuracy: 0.5979 - val_loss: 0.6322 - val_accuracy: 0.6111 - val_categorical_accuracy: 0.6111\n",
            "Epoch 5/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.6273 - accuracy: 0.6160 - categorical_accuracy: 0.6160 - val_loss: 0.6038 - val_accuracy: 0.6128 - val_categorical_accuracy: 0.6128\n",
            "Epoch 6/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5975 - accuracy: 0.6179 - categorical_accuracy: 0.6179 - val_loss: 0.5713 - val_accuracy: 0.6128 - val_categorical_accuracy: 0.6128\n",
            "Epoch 7/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.5415 - accuracy: 0.6262 - categorical_accuracy: 0.6262 - val_loss: 0.5543 - val_accuracy: 0.6137 - val_categorical_accuracy: 0.6137\n",
            "Epoch 8/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.5367 - accuracy: 0.6202 - categorical_accuracy: 0.6202 - val_loss: 0.5386 - val_accuracy: 0.6137 - val_categorical_accuracy: 0.6137\n",
            "Epoch 9/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.5134 - accuracy: 0.6117 - categorical_accuracy: 0.6117 - val_loss: 0.5216 - val_accuracy: 0.6128 - val_categorical_accuracy: 0.6128\n",
            "Epoch 10/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.5035 - accuracy: 0.6198 - categorical_accuracy: 0.6198 - val_loss: 0.5016 - val_accuracy: 0.6128 - val_categorical_accuracy: 0.6128\n",
            "Epoch 11/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4840 - accuracy: 0.6116 - categorical_accuracy: 0.6116 - val_loss: 0.4655 - val_accuracy: 0.6128 - val_categorical_accuracy: 0.6128\n",
            "Epoch 12/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.4433 - accuracy: 0.6119 - categorical_accuracy: 0.6119 - val_loss: 0.4434 - val_accuracy: 0.6103 - val_categorical_accuracy: 0.6103\n",
            "Epoch 13/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.4116 - accuracy: 0.6159 - categorical_accuracy: 0.6159 - val_loss: 0.4262 - val_accuracy: 0.6103 - val_categorical_accuracy: 0.6103\n",
            "Epoch 14/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.3917 - accuracy: 0.6227 - categorical_accuracy: 0.6227 - val_loss: 0.3973 - val_accuracy: 0.6103 - val_categorical_accuracy: 0.6103\n",
            "Epoch 15/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3593 - accuracy: 0.6398 - categorical_accuracy: 0.6398 - val_loss: 0.3666 - val_accuracy: 0.6085 - val_categorical_accuracy: 0.6085\n",
            "Epoch 16/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.3400 - accuracy: 0.6170 - categorical_accuracy: 0.6170 - val_loss: 0.3499 - val_accuracy: 0.6282 - val_categorical_accuracy: 0.6282\n",
            "Epoch 17/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.3248 - accuracy: 0.6495 - categorical_accuracy: 0.6495 - val_loss: 0.3381 - val_accuracy: 0.6308 - val_categorical_accuracy: 0.6308\n",
            "Epoch 18/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.3201 - accuracy: 0.6334 - categorical_accuracy: 0.6334 - val_loss: 0.3264 - val_accuracy: 0.6308 - val_categorical_accuracy: 0.6308\n",
            "Epoch 19/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.3039 - accuracy: 0.6456 - categorical_accuracy: 0.6456 - val_loss: 0.3116 - val_accuracy: 0.6308 - val_categorical_accuracy: 0.6308\n",
            "Epoch 20/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.2813 - accuracy: 0.6372 - categorical_accuracy: 0.6372 - val_loss: 0.2937 - val_accuracy: 0.6325 - val_categorical_accuracy: 0.6325\n",
            "Epoch 21/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.2639 - accuracy: 0.6526 - categorical_accuracy: 0.6526 - val_loss: 0.2742 - val_accuracy: 0.6325 - val_categorical_accuracy: 0.6325\n",
            "Epoch 22/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.2569 - accuracy: 0.6308 - categorical_accuracy: 0.6308 - val_loss: 0.2527 - val_accuracy: 0.6385 - val_categorical_accuracy: 0.6385\n",
            "Epoch 23/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.2212 - accuracy: 0.6515 - categorical_accuracy: 0.6515 - val_loss: 0.2336 - val_accuracy: 0.6410 - val_categorical_accuracy: 0.6410\n",
            "Epoch 24/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.2261 - accuracy: 0.6451 - categorical_accuracy: 0.6451 - val_loss: 0.2203 - val_accuracy: 0.6632 - val_categorical_accuracy: 0.6632\n",
            "Epoch 25/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.6663 - categorical_accuracy: 0.6663 - val_loss: 0.2113 - val_accuracy: 0.6632 - val_categorical_accuracy: 0.6632\n",
            "Epoch 26/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1807 - accuracy: 0.6602 - categorical_accuracy: 0.6602 - val_loss: 0.2049 - val_accuracy: 0.6632 - val_categorical_accuracy: 0.6632\n",
            "Epoch 27/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1770 - accuracy: 0.6678 - categorical_accuracy: 0.6678 - val_loss: 0.1997 - val_accuracy: 0.6632 - val_categorical_accuracy: 0.6632\n",
            "Epoch 28/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1841 - accuracy: 0.6683 - categorical_accuracy: 0.6683 - val_loss: 0.1947 - val_accuracy: 0.6632 - val_categorical_accuracy: 0.6632\n",
            "Epoch 29/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1725 - accuracy: 0.6613 - categorical_accuracy: 0.6613 - val_loss: 0.1887 - val_accuracy: 0.6632 - val_categorical_accuracy: 0.6632\n",
            "Epoch 30/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1858 - accuracy: 0.6647 - categorical_accuracy: 0.6647 - val_loss: 0.1794 - val_accuracy: 0.6632 - val_categorical_accuracy: 0.6632\n",
            "Epoch 31/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1560 - accuracy: 0.6533 - categorical_accuracy: 0.6533 - val_loss: 0.1685 - val_accuracy: 0.6632 - val_categorical_accuracy: 0.6632\n",
            "Epoch 32/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1629 - accuracy: 0.6449 - categorical_accuracy: 0.6449 - val_loss: 0.1611 - val_accuracy: 0.6632 - val_categorical_accuracy: 0.6632\n",
            "Epoch 33/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1496 - accuracy: 0.6743 - categorical_accuracy: 0.6743 - val_loss: 0.1563 - val_accuracy: 0.6786 - val_categorical_accuracy: 0.6786\n",
            "Epoch 34/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1502 - accuracy: 0.6627 - categorical_accuracy: 0.6627 - val_loss: 0.1521 - val_accuracy: 0.6786 - val_categorical_accuracy: 0.6786\n",
            "Epoch 35/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1393 - accuracy: 0.6829 - categorical_accuracy: 0.6829 - val_loss: 0.1477 - val_accuracy: 0.6821 - val_categorical_accuracy: 0.6821\n",
            "Epoch 36/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1384 - accuracy: 0.6746 - categorical_accuracy: 0.6746 - val_loss: 0.1430 - val_accuracy: 0.6821 - val_categorical_accuracy: 0.6821\n",
            "Epoch 37/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1402 - accuracy: 0.6727 - categorical_accuracy: 0.6727 - val_loss: 0.1383 - val_accuracy: 0.6863 - val_categorical_accuracy: 0.6863\n",
            "Epoch 38/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1310 - accuracy: 0.6804 - categorical_accuracy: 0.6804 - val_loss: 0.1343 - val_accuracy: 0.6863 - val_categorical_accuracy: 0.6863\n",
            "Epoch 39/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1293 - accuracy: 0.6902 - categorical_accuracy: 0.6902 - val_loss: 0.1312 - val_accuracy: 0.6863 - val_categorical_accuracy: 0.6863\n",
            "Epoch 40/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1260 - accuracy: 0.6831 - categorical_accuracy: 0.6831 - val_loss: 0.1288 - val_accuracy: 0.6863 - val_categorical_accuracy: 0.6863\n",
            "Epoch 41/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1277 - accuracy: 0.6901 - categorical_accuracy: 0.6901 - val_loss: 0.1270 - val_accuracy: 0.6863 - val_categorical_accuracy: 0.6863\n",
            "Epoch 42/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1153 - accuracy: 0.7027 - categorical_accuracy: 0.7027 - val_loss: 0.1254 - val_accuracy: 0.6863 - val_categorical_accuracy: 0.6863\n",
            "Epoch 43/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1274 - accuracy: 0.6779 - categorical_accuracy: 0.6779 - val_loss: 0.1239 - val_accuracy: 0.6863 - val_categorical_accuracy: 0.6863\n",
            "Epoch 44/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1108 - accuracy: 0.6879 - categorical_accuracy: 0.6879 - val_loss: 0.1225 - val_accuracy: 0.6880 - val_categorical_accuracy: 0.6880\n",
            "Epoch 45/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1138 - accuracy: 0.6927 - categorical_accuracy: 0.6927 - val_loss: 0.1211 - val_accuracy: 0.6880 - val_categorical_accuracy: 0.6880\n",
            "Epoch 46/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1159 - accuracy: 0.6820 - categorical_accuracy: 0.6820 - val_loss: 0.1197 - val_accuracy: 0.6880 - val_categorical_accuracy: 0.6880\n",
            "Epoch 47/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1133 - accuracy: 0.7081 - categorical_accuracy: 0.7081 - val_loss: 0.1182 - val_accuracy: 0.6897 - val_categorical_accuracy: 0.6897\n",
            "Epoch 48/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1069 - accuracy: 0.6786 - categorical_accuracy: 0.6786 - val_loss: 0.1165 - val_accuracy: 0.6880 - val_categorical_accuracy: 0.6880\n",
            "Epoch 49/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1008 - accuracy: 0.6778 - categorical_accuracy: 0.6778 - val_loss: 0.1144 - val_accuracy: 0.6889 - val_categorical_accuracy: 0.6889\n",
            "Epoch 50/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.1021 - accuracy: 0.6956 - categorical_accuracy: 0.6956 - val_loss: 0.1119 - val_accuracy: 0.6889 - val_categorical_accuracy: 0.6889\n",
            "Epoch 51/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1108 - accuracy: 0.7069 - categorical_accuracy: 0.7069 - val_loss: 0.1092 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 52/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0975 - accuracy: 0.6951 - categorical_accuracy: 0.6951 - val_loss: 0.1066 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 53/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1008 - accuracy: 0.6890 - categorical_accuracy: 0.6890 - val_loss: 0.1042 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 54/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1015 - accuracy: 0.6947 - categorical_accuracy: 0.6947 - val_loss: 0.1022 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 55/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.1028 - accuracy: 0.6876 - categorical_accuracy: 0.6876 - val_loss: 0.1006 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 56/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.1013 - accuracy: 0.6899 - categorical_accuracy: 0.6899 - val_loss: 0.0993 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 57/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0999 - accuracy: 0.6759 - categorical_accuracy: 0.6759 - val_loss: 0.0983 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 58/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0840 - accuracy: 0.7035 - categorical_accuracy: 0.7035 - val_loss: 0.0974 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 59/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0769 - accuracy: 0.7012 - categorical_accuracy: 0.7012 - val_loss: 0.0966 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 60/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0883 - accuracy: 0.6968 - categorical_accuracy: 0.6968 - val_loss: 0.0959 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 61/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0908 - accuracy: 0.7069 - categorical_accuracy: 0.7069 - val_loss: 0.0952 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 62/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0868 - accuracy: 0.6875 - categorical_accuracy: 0.6875 - val_loss: 0.0946 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 63/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0784 - accuracy: 0.6898 - categorical_accuracy: 0.6898 - val_loss: 0.0940 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 64/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0897 - accuracy: 0.6970 - categorical_accuracy: 0.6970 - val_loss: 0.0935 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 65/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0790 - accuracy: 0.6901 - categorical_accuracy: 0.6901 - val_loss: 0.0930 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 66/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0892 - accuracy: 0.6873 - categorical_accuracy: 0.6873 - val_loss: 0.0925 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 67/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0891 - accuracy: 0.6943 - categorical_accuracy: 0.6943 - val_loss: 0.0920 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 68/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0825 - accuracy: 0.6805 - categorical_accuracy: 0.6805 - val_loss: 0.0914 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 69/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0827 - accuracy: 0.6835 - categorical_accuracy: 0.6835 - val_loss: 0.0909 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 70/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0861 - accuracy: 0.6856 - categorical_accuracy: 0.6856 - val_loss: 0.0904 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 71/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0964 - accuracy: 0.6814 - categorical_accuracy: 0.6814 - val_loss: 0.0898 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 72/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0744 - accuracy: 0.6905 - categorical_accuracy: 0.6905 - val_loss: 0.0892 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 73/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0868 - accuracy: 0.6926 - categorical_accuracy: 0.6926 - val_loss: 0.0884 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 74/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0881 - accuracy: 0.6919 - categorical_accuracy: 0.6919 - val_loss: 0.0876 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 75/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0743 - accuracy: 0.6915 - categorical_accuracy: 0.6915 - val_loss: 0.0866 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 76/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0884 - accuracy: 0.6792 - categorical_accuracy: 0.6792 - val_loss: 0.0855 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 77/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0851 - accuracy: 0.6809 - categorical_accuracy: 0.6809 - val_loss: 0.0842 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 78/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0759 - accuracy: 0.7000 - categorical_accuracy: 0.7000 - val_loss: 0.0826 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 79/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0627 - accuracy: 0.6896 - categorical_accuracy: 0.6896 - val_loss: 0.0809 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 80/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0666 - accuracy: 0.6880 - categorical_accuracy: 0.6880 - val_loss: 0.0791 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 81/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0614 - accuracy: 0.6927 - categorical_accuracy: 0.6927 - val_loss: 0.0775 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 82/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0684 - accuracy: 0.6884 - categorical_accuracy: 0.6884 - val_loss: 0.0762 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 83/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0641 - accuracy: 0.6836 - categorical_accuracy: 0.6836 - val_loss: 0.0751 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 84/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0733 - accuracy: 0.6885 - categorical_accuracy: 0.6885 - val_loss: 0.0742 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 85/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0632 - accuracy: 0.6860 - categorical_accuracy: 0.6860 - val_loss: 0.0735 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 86/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0549 - accuracy: 0.6932 - categorical_accuracy: 0.6932 - val_loss: 0.0729 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 87/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0615 - accuracy: 0.6862 - categorical_accuracy: 0.6862 - val_loss: 0.0725 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 88/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0545 - accuracy: 0.6960 - categorical_accuracy: 0.6960 - val_loss: 0.0720 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 89/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0644 - accuracy: 0.7006 - categorical_accuracy: 0.7006 - val_loss: 0.0717 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 90/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0623 - accuracy: 0.6826 - categorical_accuracy: 0.6826 - val_loss: 0.0714 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 91/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0573 - accuracy: 0.6841 - categorical_accuracy: 0.6841 - val_loss: 0.0711 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 92/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0582 - accuracy: 0.6988 - categorical_accuracy: 0.6988 - val_loss: 0.0708 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 93/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0515 - accuracy: 0.6842 - categorical_accuracy: 0.6842 - val_loss: 0.0706 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 94/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0514 - accuracy: 0.7042 - categorical_accuracy: 0.7042 - val_loss: 0.0703 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 95/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0592 - accuracy: 0.6807 - categorical_accuracy: 0.6807 - val_loss: 0.0701 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 96/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0622 - accuracy: 0.6866 - categorical_accuracy: 0.6866 - val_loss: 0.0699 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 97/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0551 - accuracy: 0.6880 - categorical_accuracy: 0.6880 - val_loss: 0.0697 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 98/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0492 - accuracy: 0.6966 - categorical_accuracy: 0.6966 - val_loss: 0.0695 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 99/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0612 - accuracy: 0.6836 - categorical_accuracy: 0.6836 - val_loss: 0.0694 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 100/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0529 - accuracy: 0.7023 - categorical_accuracy: 0.7023 - val_loss: 0.0692 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 101/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0518 - accuracy: 0.6939 - categorical_accuracy: 0.6939 - val_loss: 0.0690 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 102/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0570 - accuracy: 0.6862 - categorical_accuracy: 0.6862 - val_loss: 0.0689 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 103/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0564 - accuracy: 0.6845 - categorical_accuracy: 0.6845 - val_loss: 0.0687 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 104/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0621 - accuracy: 0.6810 - categorical_accuracy: 0.6810 - val_loss: 0.0686 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 105/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0575 - accuracy: 0.7044 - categorical_accuracy: 0.7044 - val_loss: 0.0684 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 106/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0624 - accuracy: 0.6890 - categorical_accuracy: 0.6890 - val_loss: 0.0683 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 107/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0548 - accuracy: 0.6925 - categorical_accuracy: 0.6925 - val_loss: 0.0681 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 108/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0586 - accuracy: 0.6937 - categorical_accuracy: 0.6937 - val_loss: 0.0680 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 109/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0534 - accuracy: 0.6902 - categorical_accuracy: 0.6902 - val_loss: 0.0678 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 110/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0589 - accuracy: 0.6882 - categorical_accuracy: 0.6882 - val_loss: 0.0677 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 111/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0600 - accuracy: 0.6999 - categorical_accuracy: 0.6999 - val_loss: 0.0675 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 112/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0539 - accuracy: 0.6916 - categorical_accuracy: 0.6916 - val_loss: 0.0674 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 113/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0510 - accuracy: 0.6901 - categorical_accuracy: 0.6901 - val_loss: 0.0672 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 114/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0612 - accuracy: 0.6918 - categorical_accuracy: 0.6918 - val_loss: 0.0671 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 115/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0587 - accuracy: 0.6851 - categorical_accuracy: 0.6851 - val_loss: 0.0669 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 116/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0596 - accuracy: 0.6930 - categorical_accuracy: 0.6930 - val_loss: 0.0668 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 117/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0575 - accuracy: 0.6878 - categorical_accuracy: 0.6878 - val_loss: 0.0667 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 118/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0603 - accuracy: 0.6956 - categorical_accuracy: 0.6956 - val_loss: 0.0665 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 119/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0450 - accuracy: 0.6862 - categorical_accuracy: 0.6862 - val_loss: 0.0664 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 120/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0556 - accuracy: 0.6930 - categorical_accuracy: 0.6930 - val_loss: 0.0663 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 121/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0540 - accuracy: 0.7015 - categorical_accuracy: 0.7015 - val_loss: 0.0661 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 122/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0555 - accuracy: 0.6910 - categorical_accuracy: 0.6910 - val_loss: 0.0660 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 123/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0619 - accuracy: 0.6955 - categorical_accuracy: 0.6955 - val_loss: 0.0659 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 124/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0695 - accuracy: 0.6855 - categorical_accuracy: 0.6855 - val_loss: 0.0657 - val_accuracy: 0.6906 - val_categorical_accuracy: 0.6906\n",
            "Epoch 125/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0544 - accuracy: 0.6950 - categorical_accuracy: 0.6950 - val_loss: 0.0656 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 126/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0532 - accuracy: 0.6857 - categorical_accuracy: 0.6857 - val_loss: 0.0655 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 127/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0566 - accuracy: 0.6874 - categorical_accuracy: 0.6874 - val_loss: 0.0653 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 128/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0628 - accuracy: 0.6860 - categorical_accuracy: 0.6860 - val_loss: 0.0652 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 129/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0494 - accuracy: 0.7021 - categorical_accuracy: 0.7021 - val_loss: 0.0651 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 130/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0523 - accuracy: 0.6962 - categorical_accuracy: 0.6962 - val_loss: 0.0651 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 131/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0458 - accuracy: 0.6835 - categorical_accuracy: 0.6835 - val_loss: 0.0649 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 132/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0460 - accuracy: 0.6916 - categorical_accuracy: 0.6916 - val_loss: 0.0648 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 133/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0528 - accuracy: 0.6985 - categorical_accuracy: 0.6985 - val_loss: 0.0648 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 134/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0558 - accuracy: 0.7053 - categorical_accuracy: 0.7053 - val_loss: 0.0647 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 135/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0567 - accuracy: 0.6822 - categorical_accuracy: 0.6822 - val_loss: 0.0646 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 136/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0634 - accuracy: 0.7045 - categorical_accuracy: 0.7045 - val_loss: 0.0644 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 137/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0500 - accuracy: 0.6980 - categorical_accuracy: 0.6980 - val_loss: 0.0644 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 138/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0505 - accuracy: 0.6978 - categorical_accuracy: 0.6978 - val_loss: 0.0643 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 139/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0496 - accuracy: 0.6861 - categorical_accuracy: 0.6861 - val_loss: 0.0643 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 140/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0480 - accuracy: 0.6857 - categorical_accuracy: 0.6857 - val_loss: 0.0641 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 141/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0601 - accuracy: 0.7001 - categorical_accuracy: 0.7001 - val_loss: 0.0641 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 142/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0548 - accuracy: 0.6841 - categorical_accuracy: 0.6841 - val_loss: 0.0640 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 143/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0611 - accuracy: 0.6853 - categorical_accuracy: 0.6853 - val_loss: 0.0639 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 144/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0591 - accuracy: 0.6970 - categorical_accuracy: 0.6970 - val_loss: 0.0638 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 145/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0502 - accuracy: 0.6952 - categorical_accuracy: 0.6952 - val_loss: 0.0637 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 146/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0547 - accuracy: 0.6921 - categorical_accuracy: 0.6921 - val_loss: 0.0636 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 147/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0541 - accuracy: 0.6924 - categorical_accuracy: 0.6924 - val_loss: 0.0636 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 148/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0512 - accuracy: 0.7037 - categorical_accuracy: 0.7037 - val_loss: 0.0636 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 149/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0579 - accuracy: 0.6956 - categorical_accuracy: 0.6956 - val_loss: 0.0635 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 150/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0504 - accuracy: 0.7035 - categorical_accuracy: 0.7035 - val_loss: 0.0634 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 151/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0575 - accuracy: 0.6856 - categorical_accuracy: 0.6856 - val_loss: 0.0633 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 152/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0562 - accuracy: 0.6959 - categorical_accuracy: 0.6959 - val_loss: 0.0632 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 153/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0471 - accuracy: 0.6939 - categorical_accuracy: 0.6939 - val_loss: 0.0632 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 154/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0537 - accuracy: 0.7044 - categorical_accuracy: 0.7044 - val_loss: 0.0631 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 155/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0670 - accuracy: 0.6729 - categorical_accuracy: 0.6729 - val_loss: 0.0631 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 156/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0511 - accuracy: 0.6998 - categorical_accuracy: 0.6998 - val_loss: 0.0630 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 157/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0515 - accuracy: 0.6901 - categorical_accuracy: 0.6901 - val_loss: 0.0629 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 158/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0482 - accuracy: 0.6970 - categorical_accuracy: 0.6970 - val_loss: 0.0629 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 159/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0477 - accuracy: 0.7028 - categorical_accuracy: 0.7028 - val_loss: 0.0628 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 160/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0497 - accuracy: 0.6972 - categorical_accuracy: 0.6972 - val_loss: 0.0628 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 161/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0428 - accuracy: 0.7000 - categorical_accuracy: 0.7000 - val_loss: 0.0627 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 162/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0560 - accuracy: 0.6868 - categorical_accuracy: 0.6868 - val_loss: 0.0627 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 163/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0582 - accuracy: 0.6842 - categorical_accuracy: 0.6842 - val_loss: 0.0626 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 164/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0547 - accuracy: 0.6883 - categorical_accuracy: 0.6883 - val_loss: 0.0626 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 165/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0520 - accuracy: 0.6922 - categorical_accuracy: 0.6922 - val_loss: 0.0625 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 166/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0526 - accuracy: 0.6911 - categorical_accuracy: 0.6911 - val_loss: 0.0625 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 167/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0589 - accuracy: 0.6946 - categorical_accuracy: 0.6946 - val_loss: 0.0624 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 168/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0435 - accuracy: 0.6934 - categorical_accuracy: 0.6934 - val_loss: 0.0624 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 169/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0551 - accuracy: 0.6906 - categorical_accuracy: 0.6906 - val_loss: 0.0623 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 170/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0534 - accuracy: 0.6979 - categorical_accuracy: 0.6979 - val_loss: 0.0623 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 171/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0596 - accuracy: 0.6932 - categorical_accuracy: 0.6932 - val_loss: 0.0622 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 172/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0559 - accuracy: 0.6867 - categorical_accuracy: 0.6867 - val_loss: 0.0622 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 173/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0502 - accuracy: 0.6969 - categorical_accuracy: 0.6969 - val_loss: 0.0621 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 174/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0489 - accuracy: 0.7024 - categorical_accuracy: 0.7024 - val_loss: 0.0621 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 175/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0520 - accuracy: 0.7008 - categorical_accuracy: 0.7008 - val_loss: 0.0621 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 176/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0492 - accuracy: 0.6864 - categorical_accuracy: 0.6864 - val_loss: 0.0620 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 177/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0539 - accuracy: 0.6891 - categorical_accuracy: 0.6891 - val_loss: 0.0620 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 178/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0490 - accuracy: 0.6909 - categorical_accuracy: 0.6909 - val_loss: 0.0619 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 179/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0590 - accuracy: 0.6812 - categorical_accuracy: 0.6812 - val_loss: 0.0619 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 180/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0528 - accuracy: 0.7013 - categorical_accuracy: 0.7013 - val_loss: 0.0618 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 181/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0462 - accuracy: 0.6992 - categorical_accuracy: 0.6992 - val_loss: 0.0618 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 182/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0567 - accuracy: 0.6872 - categorical_accuracy: 0.6872 - val_loss: 0.0618 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 183/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0567 - accuracy: 0.6922 - categorical_accuracy: 0.6922 - val_loss: 0.0617 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 184/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0591 - accuracy: 0.6929 - categorical_accuracy: 0.6929 - val_loss: 0.0617 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 185/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0584 - accuracy: 0.6905 - categorical_accuracy: 0.6905 - val_loss: 0.0617 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 186/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0526 - accuracy: 0.7088 - categorical_accuracy: 0.7088 - val_loss: 0.0616 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 187/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0462 - accuracy: 0.7008 - categorical_accuracy: 0.7008 - val_loss: 0.0616 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 188/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0594 - accuracy: 0.6879 - categorical_accuracy: 0.6879 - val_loss: 0.0616 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 189/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0519 - accuracy: 0.6895 - categorical_accuracy: 0.6895 - val_loss: 0.0615 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 190/200\n",
            "351/351 [==============================] - 2s 4ms/step - loss: 0.0508 - accuracy: 0.6852 - categorical_accuracy: 0.6852 - val_loss: 0.0615 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 191/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0566 - accuracy: 0.6946 - categorical_accuracy: 0.6946 - val_loss: 0.0615 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 192/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0538 - accuracy: 0.7034 - categorical_accuracy: 0.7034 - val_loss: 0.0615 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 193/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0452 - accuracy: 0.7017 - categorical_accuracy: 0.7017 - val_loss: 0.0614 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 194/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0406 - accuracy: 0.7014 - categorical_accuracy: 0.7014 - val_loss: 0.0614 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 195/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0466 - accuracy: 0.6977 - categorical_accuracy: 0.6977 - val_loss: 0.0614 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 196/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0518 - accuracy: 0.6924 - categorical_accuracy: 0.6924 - val_loss: 0.0613 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 197/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0494 - accuracy: 0.6867 - categorical_accuracy: 0.6867 - val_loss: 0.0613 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 198/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0519 - accuracy: 0.6815 - categorical_accuracy: 0.6815 - val_loss: 0.0613 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 199/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.0462 - accuracy: 0.6848 - categorical_accuracy: 0.6848 - val_loss: 0.0612 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "Epoch 200/200\n",
            "351/351 [==============================] - 1s 4ms/step - loss: 0.0569 - accuracy: 0.6928 - categorical_accuracy: 0.6928 - val_loss: 0.0612 - val_accuracy: 0.6932 - val_categorical_accuracy: 0.6932\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.6932 - categorical_accuracy: 0.6932\n",
            "1102\n",
            "Generation-9 Chromosome-6:\n",
            "Middle layers: 1 | Activation: selu | Optimization: SGD | Loss: categorical_hinge | LR: 0.001 | Dropout: 0.15 |\n",
            "\tScore 0.62  | Accuracy: 0.69\n",
            "Epoch 1/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.9812 - accuracy: 0.0042 - categorical_accuracy: 0.0042 - val_loss: 0.9768 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9811 - accuracy: 0.0029 - categorical_accuracy: 0.0029 - val_loss: 0.9768 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 3/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9809 - accuracy: 0.0044 - categorical_accuracy: 0.0044 - val_loss: 0.9767 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 4/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9810 - accuracy: 0.0042 - categorical_accuracy: 0.0042 - val_loss: 0.9767 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 5/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9807 - accuracy: 0.0049 - categorical_accuracy: 0.0049 - val_loss: 0.9767 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 6/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9805 - accuracy: 0.0063 - categorical_accuracy: 0.0063 - val_loss: 0.9767 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 7/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9807 - accuracy: 0.0052 - categorical_accuracy: 0.0052 - val_loss: 0.9766 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 8/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9814 - accuracy: 0.0053 - categorical_accuracy: 0.0053 - val_loss: 0.9766 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 9/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9808 - accuracy: 0.0037 - categorical_accuracy: 0.0037 - val_loss: 0.9766 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 10/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9800 - accuracy: 0.0051 - categorical_accuracy: 0.0051 - val_loss: 0.9766 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 11/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9814 - accuracy: 0.0044 - categorical_accuracy: 0.0044 - val_loss: 0.9766 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 12/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9804 - accuracy: 0.0072 - categorical_accuracy: 0.0072 - val_loss: 0.9765 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 13/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9809 - accuracy: 0.0046 - categorical_accuracy: 0.0046 - val_loss: 0.9765 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 14/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9811 - accuracy: 0.0034 - categorical_accuracy: 0.0034 - val_loss: 0.9765 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 15/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9809 - accuracy: 0.0045 - categorical_accuracy: 0.0045 - val_loss: 0.9765 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 16/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9806 - accuracy: 0.0057 - categorical_accuracy: 0.0057 - val_loss: 0.9764 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 17/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9806 - accuracy: 0.0033 - categorical_accuracy: 0.0033 - val_loss: 0.9764 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 18/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9811 - accuracy: 0.0067 - categorical_accuracy: 0.0067 - val_loss: 0.9764 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 19/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9810 - accuracy: 0.0044 - categorical_accuracy: 0.0044 - val_loss: 0.9764 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 20/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9808 - accuracy: 0.0059 - categorical_accuracy: 0.0059 - val_loss: 0.9763 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 21/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9804 - accuracy: 0.0071 - categorical_accuracy: 0.0071 - val_loss: 0.9763 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 22/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9805 - accuracy: 0.0049 - categorical_accuracy: 0.0049 - val_loss: 0.9763 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 23/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9804 - accuracy: 0.0067 - categorical_accuracy: 0.0067 - val_loss: 0.9763 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 24/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9809 - accuracy: 0.0086 - categorical_accuracy: 0.0086 - val_loss: 0.9762 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 25/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9807 - accuracy: 0.0025 - categorical_accuracy: 0.0025 - val_loss: 0.9762 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 26/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9803 - accuracy: 0.0039 - categorical_accuracy: 0.0039 - val_loss: 0.9762 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 27/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9802 - accuracy: 0.0039 - categorical_accuracy: 0.0039 - val_loss: 0.9762 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 28/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9810 - accuracy: 0.0048 - categorical_accuracy: 0.0048 - val_loss: 0.9761 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 29/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9805 - accuracy: 0.0083 - categorical_accuracy: 0.0083 - val_loss: 0.9761 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 30/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9809 - accuracy: 0.0056 - categorical_accuracy: 0.0056 - val_loss: 0.9761 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 31/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9808 - accuracy: 0.0048 - categorical_accuracy: 0.0048 - val_loss: 0.9761 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 32/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9797 - accuracy: 0.0068 - categorical_accuracy: 0.0068 - val_loss: 0.9760 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 33/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9797 - accuracy: 0.0037 - categorical_accuracy: 0.0037 - val_loss: 0.9760 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 34/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9803 - accuracy: 0.0071 - categorical_accuracy: 0.0071 - val_loss: 0.9760 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 35/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9800 - accuracy: 0.0058 - categorical_accuracy: 0.0058 - val_loss: 0.9760 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 36/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9798 - accuracy: 0.0042 - categorical_accuracy: 0.0042 - val_loss: 0.9759 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 37/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9804 - accuracy: 0.0064 - categorical_accuracy: 0.0064 - val_loss: 0.9759 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 38/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9799 - accuracy: 0.0036 - categorical_accuracy: 0.0036 - val_loss: 0.9759 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 39/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9801 - accuracy: 0.0052 - categorical_accuracy: 0.0052 - val_loss: 0.9759 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 40/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9794 - accuracy: 0.0071 - categorical_accuracy: 0.0071 - val_loss: 0.9758 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 41/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9801 - accuracy: 0.0066 - categorical_accuracy: 0.0066 - val_loss: 0.9758 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 42/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9802 - accuracy: 0.0038 - categorical_accuracy: 0.0038 - val_loss: 0.9758 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 43/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9802 - accuracy: 0.0059 - categorical_accuracy: 0.0059 - val_loss: 0.9758 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 44/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9804 - accuracy: 0.0065 - categorical_accuracy: 0.0065 - val_loss: 0.9757 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 45/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9803 - accuracy: 0.0080 - categorical_accuracy: 0.0080 - val_loss: 0.9757 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 46/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9804 - accuracy: 0.0055 - categorical_accuracy: 0.0055 - val_loss: 0.9757 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 47/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9800 - accuracy: 0.0080 - categorical_accuracy: 0.0080 - val_loss: 0.9757 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 48/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9798 - accuracy: 0.0086 - categorical_accuracy: 0.0086 - val_loss: 0.9756 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 49/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9800 - accuracy: 0.0028 - categorical_accuracy: 0.0028 - val_loss: 0.9756 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 50/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9800 - accuracy: 0.0072 - categorical_accuracy: 0.0072 - val_loss: 0.9756 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 51/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9803 - accuracy: 0.0079 - categorical_accuracy: 0.0079 - val_loss: 0.9756 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 52/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9798 - accuracy: 0.0087 - categorical_accuracy: 0.0087 - val_loss: 0.9755 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 53/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9798 - accuracy: 0.0068 - categorical_accuracy: 0.0068 - val_loss: 0.9755 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 54/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9797 - accuracy: 0.0084 - categorical_accuracy: 0.0084 - val_loss: 0.9755 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 55/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9798 - accuracy: 0.0070 - categorical_accuracy: 0.0070 - val_loss: 0.9755 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 56/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9804 - accuracy: 0.0069 - categorical_accuracy: 0.0069 - val_loss: 0.9754 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 57/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9799 - accuracy: 0.0045 - categorical_accuracy: 0.0045 - val_loss: 0.9754 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 58/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9797 - accuracy: 0.0056 - categorical_accuracy: 0.0056 - val_loss: 0.9754 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 59/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9798 - accuracy: 0.0061 - categorical_accuracy: 0.0061 - val_loss: 0.9754 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 60/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9797 - accuracy: 0.0025 - categorical_accuracy: 0.0025 - val_loss: 0.9753 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 61/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9803 - accuracy: 0.0087 - categorical_accuracy: 0.0087 - val_loss: 0.9753 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 62/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9792 - accuracy: 0.0095 - categorical_accuracy: 0.0095 - val_loss: 0.9753 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 63/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9804 - accuracy: 0.0050 - categorical_accuracy: 0.0050 - val_loss: 0.9753 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 64/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9791 - accuracy: 0.0052 - categorical_accuracy: 0.0052 - val_loss: 0.9752 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 65/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9794 - accuracy: 0.0071 - categorical_accuracy: 0.0071 - val_loss: 0.9752 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 66/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9796 - accuracy: 0.0043 - categorical_accuracy: 0.0043 - val_loss: 0.9752 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 67/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9792 - accuracy: 0.0097 - categorical_accuracy: 0.0097 - val_loss: 0.9752 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 68/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9798 - accuracy: 0.0091 - categorical_accuracy: 0.0091 - val_loss: 0.9751 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 69/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9798 - accuracy: 0.0054 - categorical_accuracy: 0.0054 - val_loss: 0.9751 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 70/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9786 - accuracy: 0.0055 - categorical_accuracy: 0.0055 - val_loss: 0.9751 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 71/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9802 - accuracy: 0.0062 - categorical_accuracy: 0.0062 - val_loss: 0.9751 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 72/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9793 - accuracy: 0.0097 - categorical_accuracy: 0.0097 - val_loss: 0.9750 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 73/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9795 - accuracy: 0.0069 - categorical_accuracy: 0.0069 - val_loss: 0.9750 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 74/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9796 - accuracy: 0.0063 - categorical_accuracy: 0.0063 - val_loss: 0.9750 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 75/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9791 - accuracy: 0.0104 - categorical_accuracy: 0.0104 - val_loss: 0.9750 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 76/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9790 - accuracy: 0.0081 - categorical_accuracy: 0.0081 - val_loss: 0.9749 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 77/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9792 - accuracy: 0.0066 - categorical_accuracy: 0.0066 - val_loss: 0.9749 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 78/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9793 - accuracy: 0.0104 - categorical_accuracy: 0.0104 - val_loss: 0.9749 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 79/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9791 - accuracy: 0.0058 - categorical_accuracy: 0.0058 - val_loss: 0.9749 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 80/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9795 - accuracy: 0.0039 - categorical_accuracy: 0.0039 - val_loss: 0.9748 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 81/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9786 - accuracy: 0.0084 - categorical_accuracy: 0.0084 - val_loss: 0.9748 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 82/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9794 - accuracy: 0.0055 - categorical_accuracy: 0.0055 - val_loss: 0.9748 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 83/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9793 - accuracy: 0.0030 - categorical_accuracy: 0.0030 - val_loss: 0.9748 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 84/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9793 - accuracy: 0.0056 - categorical_accuracy: 0.0056 - val_loss: 0.9747 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 85/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9793 - accuracy: 0.0100 - categorical_accuracy: 0.0100 - val_loss: 0.9747 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 86/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9788 - accuracy: 0.0075 - categorical_accuracy: 0.0075 - val_loss: 0.9747 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 87/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9794 - accuracy: 0.0078 - categorical_accuracy: 0.0078 - val_loss: 0.9747 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 88/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9791 - accuracy: 0.0089 - categorical_accuracy: 0.0089 - val_loss: 0.9746 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 89/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9795 - accuracy: 0.0062 - categorical_accuracy: 0.0062 - val_loss: 0.9746 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 90/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9789 - accuracy: 0.0072 - categorical_accuracy: 0.0072 - val_loss: 0.9746 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 91/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9790 - accuracy: 0.0052 - categorical_accuracy: 0.0052 - val_loss: 0.9746 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 92/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9792 - accuracy: 0.0057 - categorical_accuracy: 0.0057 - val_loss: 0.9745 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 93/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9791 - accuracy: 0.0072 - categorical_accuracy: 0.0072 - val_loss: 0.9745 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 94/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9785 - accuracy: 0.0060 - categorical_accuracy: 0.0060 - val_loss: 0.9745 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 95/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9789 - accuracy: 0.0048 - categorical_accuracy: 0.0048 - val_loss: 0.9744 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 96/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9781 - accuracy: 0.0084 - categorical_accuracy: 0.0084 - val_loss: 0.9744 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 97/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9787 - accuracy: 0.0068 - categorical_accuracy: 0.0068 - val_loss: 0.9744 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 98/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9790 - accuracy: 0.0058 - categorical_accuracy: 0.0058 - val_loss: 0.9744 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 99/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9784 - accuracy: 0.0063 - categorical_accuracy: 0.0063 - val_loss: 0.9743 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 100/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9790 - accuracy: 0.0057 - categorical_accuracy: 0.0057 - val_loss: 0.9743 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 101/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9793 - accuracy: 0.0096 - categorical_accuracy: 0.0096 - val_loss: 0.9743 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 102/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9788 - accuracy: 0.0095 - categorical_accuracy: 0.0095 - val_loss: 0.9743 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 103/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9792 - accuracy: 0.0091 - categorical_accuracy: 0.0091 - val_loss: 0.9742 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 104/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9794 - accuracy: 0.0041 - categorical_accuracy: 0.0041 - val_loss: 0.9742 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 105/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9787 - accuracy: 0.0054 - categorical_accuracy: 0.0054 - val_loss: 0.9742 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 106/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9786 - accuracy: 0.0077 - categorical_accuracy: 0.0077 - val_loss: 0.9742 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 107/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9786 - accuracy: 0.0091 - categorical_accuracy: 0.0091 - val_loss: 0.9741 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 108/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9792 - accuracy: 0.0097 - categorical_accuracy: 0.0097 - val_loss: 0.9741 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 109/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9782 - accuracy: 0.0054 - categorical_accuracy: 0.0054 - val_loss: 0.9741 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 110/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9783 - accuracy: 0.0105 - categorical_accuracy: 0.0105 - val_loss: 0.9741 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 111/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9782 - accuracy: 0.0080 - categorical_accuracy: 0.0080 - val_loss: 0.9740 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 112/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9786 - accuracy: 0.0071 - categorical_accuracy: 0.0071 - val_loss: 0.9740 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 113/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9781 - accuracy: 0.0071 - categorical_accuracy: 0.0071 - val_loss: 0.9740 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 114/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9784 - accuracy: 0.0070 - categorical_accuracy: 0.0070 - val_loss: 0.9740 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 115/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9788 - accuracy: 0.0052 - categorical_accuracy: 0.0052 - val_loss: 0.9739 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 116/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9785 - accuracy: 0.0065 - categorical_accuracy: 0.0065 - val_loss: 0.9739 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 117/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9788 - accuracy: 0.0072 - categorical_accuracy: 0.0072 - val_loss: 0.9739 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 118/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9778 - accuracy: 0.0054 - categorical_accuracy: 0.0054 - val_loss: 0.9738 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 119/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9779 - accuracy: 0.0078 - categorical_accuracy: 0.0078 - val_loss: 0.9738 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 120/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9780 - accuracy: 0.0107 - categorical_accuracy: 0.0107 - val_loss: 0.9738 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 121/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9791 - accuracy: 0.0109 - categorical_accuracy: 0.0109 - val_loss: 0.9738 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 122/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9780 - accuracy: 0.0072 - categorical_accuracy: 0.0072 - val_loss: 0.9737 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 123/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9782 - accuracy: 0.0073 - categorical_accuracy: 0.0073 - val_loss: 0.9737 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 124/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9784 - accuracy: 0.0094 - categorical_accuracy: 0.0094 - val_loss: 0.9737 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 125/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9783 - accuracy: 0.0082 - categorical_accuracy: 0.0082 - val_loss: 0.9737 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 126/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9780 - accuracy: 0.0113 - categorical_accuracy: 0.0113 - val_loss: 0.9736 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 127/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9777 - accuracy: 0.0084 - categorical_accuracy: 0.0084 - val_loss: 0.9736 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 128/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9779 - accuracy: 0.0046 - categorical_accuracy: 0.0046 - val_loss: 0.9736 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 129/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9785 - accuracy: 0.0090 - categorical_accuracy: 0.0090 - val_loss: 0.9736 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 130/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9781 - accuracy: 0.0126 - categorical_accuracy: 0.0126 - val_loss: 0.9735 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 131/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9774 - accuracy: 0.0098 - categorical_accuracy: 0.0098 - val_loss: 0.9735 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 132/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9783 - accuracy: 0.0078 - categorical_accuracy: 0.0078 - val_loss: 0.9735 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 133/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9778 - accuracy: 0.0066 - categorical_accuracy: 0.0066 - val_loss: 0.9735 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 134/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9780 - accuracy: 0.0112 - categorical_accuracy: 0.0112 - val_loss: 0.9734 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 135/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9782 - accuracy: 0.0106 - categorical_accuracy: 0.0106 - val_loss: 0.9734 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 136/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9783 - accuracy: 0.0117 - categorical_accuracy: 0.0117 - val_loss: 0.9734 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 137/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9774 - accuracy: 0.0075 - categorical_accuracy: 0.0075 - val_loss: 0.9734 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 138/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9777 - accuracy: 0.0057 - categorical_accuracy: 0.0057 - val_loss: 0.9733 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 139/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9780 - accuracy: 0.0095 - categorical_accuracy: 0.0095 - val_loss: 0.9733 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 140/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9776 - accuracy: 0.0105 - categorical_accuracy: 0.0105 - val_loss: 0.9733 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 141/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9782 - accuracy: 0.0095 - categorical_accuracy: 0.0095 - val_loss: 0.9732 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 142/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9774 - accuracy: 0.0087 - categorical_accuracy: 0.0087 - val_loss: 0.9732 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 143/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9779 - accuracy: 0.0111 - categorical_accuracy: 0.0111 - val_loss: 0.9732 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 144/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9768 - accuracy: 0.0085 - categorical_accuracy: 0.0085 - val_loss: 0.9732 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 145/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9778 - accuracy: 0.0109 - categorical_accuracy: 0.0109 - val_loss: 0.9731 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 146/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9780 - accuracy: 0.0100 - categorical_accuracy: 0.0100 - val_loss: 0.9731 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 147/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9771 - accuracy: 0.0101 - categorical_accuracy: 0.0101 - val_loss: 0.9731 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 148/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9782 - accuracy: 0.0092 - categorical_accuracy: 0.0092 - val_loss: 0.9731 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 149/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9780 - accuracy: 0.0081 - categorical_accuracy: 0.0081 - val_loss: 0.9730 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 150/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9780 - accuracy: 0.0087 - categorical_accuracy: 0.0087 - val_loss: 0.9730 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 151/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9774 - accuracy: 0.0114 - categorical_accuracy: 0.0114 - val_loss: 0.9730 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 152/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9775 - accuracy: 0.0145 - categorical_accuracy: 0.0145 - val_loss: 0.9730 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 153/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9777 - accuracy: 0.0096 - categorical_accuracy: 0.0096 - val_loss: 0.9729 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 154/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9777 - accuracy: 0.0080 - categorical_accuracy: 0.0080 - val_loss: 0.9729 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 155/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9776 - accuracy: 0.0104 - categorical_accuracy: 0.0104 - val_loss: 0.9729 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 156/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9780 - accuracy: 0.0098 - categorical_accuracy: 0.0098 - val_loss: 0.9729 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 157/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9775 - accuracy: 0.0080 - categorical_accuracy: 0.0080 - val_loss: 0.9728 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 158/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9768 - accuracy: 0.0119 - categorical_accuracy: 0.0119 - val_loss: 0.9728 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 159/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9772 - accuracy: 0.0107 - categorical_accuracy: 0.0107 - val_loss: 0.9728 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 160/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9774 - accuracy: 0.0097 - categorical_accuracy: 0.0097 - val_loss: 0.9727 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 161/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9777 - accuracy: 0.0116 - categorical_accuracy: 0.0116 - val_loss: 0.9727 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 162/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9776 - accuracy: 0.0079 - categorical_accuracy: 0.0079 - val_loss: 0.9727 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 163/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9773 - accuracy: 0.0101 - categorical_accuracy: 0.0101 - val_loss: 0.9727 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 164/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9770 - accuracy: 0.0091 - categorical_accuracy: 0.0091 - val_loss: 0.9726 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 165/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9770 - accuracy: 0.0148 - categorical_accuracy: 0.0148 - val_loss: 0.9726 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 166/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9775 - accuracy: 0.0110 - categorical_accuracy: 0.0110 - val_loss: 0.9726 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 167/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9774 - accuracy: 0.0158 - categorical_accuracy: 0.0158 - val_loss: 0.9726 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 168/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9771 - accuracy: 0.0115 - categorical_accuracy: 0.0115 - val_loss: 0.9725 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 169/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9768 - accuracy: 0.0101 - categorical_accuracy: 0.0101 - val_loss: 0.9725 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 170/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9767 - accuracy: 0.0134 - categorical_accuracy: 0.0134 - val_loss: 0.9725 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 171/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9765 - accuracy: 0.0134 - categorical_accuracy: 0.0134 - val_loss: 0.9725 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 172/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9768 - accuracy: 0.0111 - categorical_accuracy: 0.0111 - val_loss: 0.9724 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 173/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9773 - accuracy: 0.0122 - categorical_accuracy: 0.0122 - val_loss: 0.9724 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 174/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9770 - accuracy: 0.0134 - categorical_accuracy: 0.0134 - val_loss: 0.9724 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 175/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9768 - accuracy: 0.0113 - categorical_accuracy: 0.0113 - val_loss: 0.9723 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 176/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9771 - accuracy: 0.0121 - categorical_accuracy: 0.0121 - val_loss: 0.9723 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 177/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9769 - accuracy: 0.0147 - categorical_accuracy: 0.0147 - val_loss: 0.9723 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 178/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9767 - accuracy: 0.0089 - categorical_accuracy: 0.0089 - val_loss: 0.9723 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 179/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9772 - accuracy: 0.0151 - categorical_accuracy: 0.0151 - val_loss: 0.9722 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 180/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9765 - accuracy: 0.0121 - categorical_accuracy: 0.0121 - val_loss: 0.9722 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 181/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9763 - accuracy: 0.0069 - categorical_accuracy: 0.0069 - val_loss: 0.9722 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 182/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9772 - accuracy: 0.0066 - categorical_accuracy: 0.0066 - val_loss: 0.9722 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 183/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9772 - accuracy: 0.0115 - categorical_accuracy: 0.0115 - val_loss: 0.9721 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 184/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9764 - accuracy: 0.0098 - categorical_accuracy: 0.0098 - val_loss: 0.9721 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 185/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9762 - accuracy: 0.0086 - categorical_accuracy: 0.0086 - val_loss: 0.9721 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 186/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9767 - accuracy: 0.0116 - categorical_accuracy: 0.0116 - val_loss: 0.9720 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 187/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9774 - accuracy: 0.0138 - categorical_accuracy: 0.0138 - val_loss: 0.9720 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 188/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9762 - accuracy: 0.0152 - categorical_accuracy: 0.0152 - val_loss: 0.9720 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 189/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9759 - accuracy: 0.0131 - categorical_accuracy: 0.0131 - val_loss: 0.9720 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 190/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9764 - accuracy: 0.0161 - categorical_accuracy: 0.0161 - val_loss: 0.9719 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 191/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9763 - accuracy: 0.0098 - categorical_accuracy: 0.0098 - val_loss: 0.9719 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 192/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9764 - accuracy: 0.0120 - categorical_accuracy: 0.0120 - val_loss: 0.9719 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 193/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9762 - accuracy: 0.0119 - categorical_accuracy: 0.0119 - val_loss: 0.9718 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 194/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9763 - accuracy: 0.0120 - categorical_accuracy: 0.0120 - val_loss: 0.9718 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 195/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9761 - accuracy: 0.0128 - categorical_accuracy: 0.0128 - val_loss: 0.9718 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 196/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9756 - accuracy: 0.0179 - categorical_accuracy: 0.0179 - val_loss: 0.9718 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 197/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9763 - accuracy: 0.0126 - categorical_accuracy: 0.0126 - val_loss: 0.9717 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 198/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9762 - accuracy: 0.0165 - categorical_accuracy: 0.0165 - val_loss: 0.9717 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 199/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9763 - accuracy: 0.0106 - categorical_accuracy: 0.0106 - val_loss: 0.9717 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 200/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9761 - accuracy: 0.0112 - categorical_accuracy: 0.0112 - val_loss: 0.9716 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.9716 - accuracy: 0.0017 - categorical_accuracy: 0.0017\n",
            "1170\n",
            "Generation-9 Chromosome-7:\n",
            "Middle layers: 2 | Activation: tanh | Optimization: Adadelta | Loss: categorical_hinge | LR: 1e-05 | Dropout: 0.3 |\n",
            "\tScore 0.00  | Accuracy: 0.00\n",
            "Epoch 1/200\n",
            "351/351 [==============================] - 9s 24ms/step - loss: 0.4868 - accuracy: 0.6428 - categorical_accuracy: 0.6428 - val_loss: 0.5708 - val_accuracy: 0.6342 - val_categorical_accuracy: 0.6342\n",
            "Epoch 2/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.6096 - accuracy: 0.6259 - categorical_accuracy: 0.6259 - val_loss: 0.5538 - val_accuracy: 0.6444 - val_categorical_accuracy: 0.6444\n",
            "Epoch 3/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5346 - accuracy: 0.6734 - categorical_accuracy: 0.6734 - val_loss: 0.5129 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 4/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.4990 - accuracy: 0.6658 - categorical_accuracy: 0.6658 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 5/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.4957 - accuracy: 0.6737 - categorical_accuracy: 0.6737 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 6/200\n",
            "351/351 [==============================] - 8s 23ms/step - loss: 0.4825 - accuracy: 0.6774 - categorical_accuracy: 0.6774 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 7/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5069 - accuracy: 0.6679 - categorical_accuracy: 0.6679 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 8/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5278 - accuracy: 0.6519 - categorical_accuracy: 0.6519 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 9/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5310 - accuracy: 0.6600 - categorical_accuracy: 0.6600 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 10/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5255 - accuracy: 0.6560 - categorical_accuracy: 0.6560 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 11/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5067 - accuracy: 0.6640 - categorical_accuracy: 0.6640 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 12/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5233 - accuracy: 0.6625 - categorical_accuracy: 0.6625 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 13/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5082 - accuracy: 0.6608 - categorical_accuracy: 0.6608 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 14/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.4912 - accuracy: 0.6761 - categorical_accuracy: 0.6761 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 15/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5229 - accuracy: 0.6535 - categorical_accuracy: 0.6535 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 16/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5207 - accuracy: 0.6589 - categorical_accuracy: 0.6589 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 17/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.4997 - accuracy: 0.6688 - categorical_accuracy: 0.6688 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 18/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5261 - accuracy: 0.6645 - categorical_accuracy: 0.6645 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 19/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5356 - accuracy: 0.6569 - categorical_accuracy: 0.6569 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 20/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5165 - accuracy: 0.6673 - categorical_accuracy: 0.6673 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 21/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5367 - accuracy: 0.6556 - categorical_accuracy: 0.6556 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 22/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5112 - accuracy: 0.6661 - categorical_accuracy: 0.6661 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 23/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.4721 - accuracy: 0.6874 - categorical_accuracy: 0.6874 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 24/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.4869 - accuracy: 0.6816 - categorical_accuracy: 0.6816 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 25/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5425 - accuracy: 0.6524 - categorical_accuracy: 0.6524 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 26/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5014 - accuracy: 0.6664 - categorical_accuracy: 0.6664 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 27/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5214 - accuracy: 0.6578 - categorical_accuracy: 0.6578 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 28/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5362 - accuracy: 0.6511 - categorical_accuracy: 0.6511 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 29/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5107 - accuracy: 0.6597 - categorical_accuracy: 0.6597 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 30/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.4898 - accuracy: 0.6744 - categorical_accuracy: 0.6744 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 31/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5098 - accuracy: 0.6669 - categorical_accuracy: 0.6669 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 32/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5317 - accuracy: 0.6580 - categorical_accuracy: 0.6580 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 33/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5307 - accuracy: 0.6579 - categorical_accuracy: 0.6579 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 34/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5141 - accuracy: 0.6719 - categorical_accuracy: 0.6719 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 35/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5089 - accuracy: 0.6626 - categorical_accuracy: 0.6626 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 36/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5266 - accuracy: 0.6593 - categorical_accuracy: 0.6593 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 37/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5261 - accuracy: 0.6517 - categorical_accuracy: 0.6517 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 38/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5455 - accuracy: 0.6522 - categorical_accuracy: 0.6522 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 39/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5162 - accuracy: 0.6677 - categorical_accuracy: 0.6677 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 40/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5063 - accuracy: 0.6711 - categorical_accuracy: 0.6711 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 41/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5010 - accuracy: 0.6694 - categorical_accuracy: 0.6694 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 42/200\n",
            "351/351 [==============================] - 8s 23ms/step - loss: 0.5000 - accuracy: 0.6696 - categorical_accuracy: 0.6696 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 43/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5403 - accuracy: 0.6555 - categorical_accuracy: 0.6555 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 44/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.4936 - accuracy: 0.6761 - categorical_accuracy: 0.6761 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 45/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5163 - accuracy: 0.6671 - categorical_accuracy: 0.6671 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 46/200\n",
            "351/351 [==============================] - 8s 23ms/step - loss: 0.4976 - accuracy: 0.6750 - categorical_accuracy: 0.6750 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 47/200\n",
            "351/351 [==============================] - 8s 23ms/step - loss: 0.5208 - accuracy: 0.6677 - categorical_accuracy: 0.6677 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 48/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5124 - accuracy: 0.6704 - categorical_accuracy: 0.6704 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 49/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.4883 - accuracy: 0.6703 - categorical_accuracy: 0.6703 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 50/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5275 - accuracy: 0.6565 - categorical_accuracy: 0.6565 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 51/200\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.5278 - accuracy: 0.6600 - categorical_accuracy: 0.6600 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 52/200\n",
            "351/351 [==============================] - 8s 23ms/step - loss: 0.5131 - accuracy: 0.6706 - categorical_accuracy: 0.6706 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 53/200\n",
            "351/351 [==============================] - 8s 23ms/step - loss: 0.5115 - accuracy: 0.6630 - categorical_accuracy: 0.6630 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "Epoch 54/200\n",
            "351/351 [==============================] - 8s 23ms/step - loss: 0.5068 - accuracy: 0.6710 - categorical_accuracy: 0.6710 - val_loss: 0.5128 - val_accuracy: 0.6692 - val_categorical_accuracy: 0.6692\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 0.5128 - accuracy: 0.6692 - categorical_accuracy: 0.6692\n",
            "1102\n",
            "Generation-9 Chromosome-8:\n",
            "Middle layers: 5 | Activation: softsign | Optimization: Adam | Loss: categorical_hinge | LR: 0.0001 | Dropout: 0.25 |\n",
            "\tScore 0.60  | Accuracy: 0.67\n",
            "Epoch 1/200\n",
            "351/351 [==============================] - 5s 11ms/step - loss: 0.9720 - accuracy: 0.0051 - categorical_accuracy: 0.0051 - val_loss: 0.9701 - val_accuracy: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.9712 - accuracy: 0.0095 - categorical_accuracy: 0.0095 - val_loss: 0.9696 - val_accuracy: 8.5470e-04 - val_categorical_accuracy: 8.5470e-04\n",
            "Epoch 3/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.9706 - accuracy: 0.0127 - categorical_accuracy: 0.0127 - val_loss: 0.9691 - val_accuracy: 0.0017 - val_categorical_accuracy: 0.0017\n",
            "Epoch 4/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.9701 - accuracy: 0.0183 - categorical_accuracy: 0.0183 - val_loss: 0.9685 - val_accuracy: 0.0949 - val_categorical_accuracy: 0.0949\n",
            "Epoch 5/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.9699 - accuracy: 0.0373 - categorical_accuracy: 0.0373 - val_loss: 0.9680 - val_accuracy: 0.1829 - val_categorical_accuracy: 0.1829\n",
            "Epoch 6/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.9694 - accuracy: 0.0642 - categorical_accuracy: 0.0642 - val_loss: 0.9675 - val_accuracy: 0.2538 - val_categorical_accuracy: 0.2538\n",
            "Epoch 7/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.9688 - accuracy: 0.0954 - categorical_accuracy: 0.0954 - val_loss: 0.9669 - val_accuracy: 0.2880 - val_categorical_accuracy: 0.2880\n",
            "Epoch 8/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.9685 - accuracy: 0.1392 - categorical_accuracy: 0.1392 - val_loss: 0.9664 - val_accuracy: 0.3402 - val_categorical_accuracy: 0.3402\n",
            "Epoch 9/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.9674 - accuracy: 0.1647 - categorical_accuracy: 0.1647 - val_loss: 0.9658 - val_accuracy: 0.4077 - val_categorical_accuracy: 0.4077\n",
            "Epoch 10/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.9673 - accuracy: 0.2151 - categorical_accuracy: 0.2151 - val_loss: 0.9653 - val_accuracy: 0.4137 - val_categorical_accuracy: 0.4137\n",
            "Epoch 11/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.9671 - accuracy: 0.2705 - categorical_accuracy: 0.2705 - val_loss: 0.9647 - val_accuracy: 0.4171 - val_categorical_accuracy: 0.4171\n",
            "Epoch 12/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.9659 - accuracy: 0.2957 - categorical_accuracy: 0.2957 - val_loss: 0.9641 - val_accuracy: 0.4342 - val_categorical_accuracy: 0.4342\n",
            "Epoch 13/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.9652 - accuracy: 0.3468 - categorical_accuracy: 0.3468 - val_loss: 0.9635 - val_accuracy: 0.4385 - val_categorical_accuracy: 0.4385\n",
            "Epoch 14/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.9641 - accuracy: 0.3718 - categorical_accuracy: 0.3718 - val_loss: 0.9628 - val_accuracy: 0.4615 - val_categorical_accuracy: 0.4615\n",
            "Epoch 15/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.9635 - accuracy: 0.3932 - categorical_accuracy: 0.3932 - val_loss: 0.9621 - val_accuracy: 0.4675 - val_categorical_accuracy: 0.4675\n",
            "Epoch 16/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.9630 - accuracy: 0.4204 - categorical_accuracy: 0.4204 - val_loss: 0.9613 - val_accuracy: 0.4761 - val_categorical_accuracy: 0.4761\n",
            "Epoch 17/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.9619 - accuracy: 0.4453 - categorical_accuracy: 0.4453 - val_loss: 0.9604 - val_accuracy: 0.4778 - val_categorical_accuracy: 0.4778\n",
            "Epoch 18/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.9608 - accuracy: 0.4628 - categorical_accuracy: 0.4628 - val_loss: 0.9593 - val_accuracy: 0.4957 - val_categorical_accuracy: 0.4957\n",
            "Epoch 19/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.9605 - accuracy: 0.4635 - categorical_accuracy: 0.4635 - val_loss: 0.9582 - val_accuracy: 0.4974 - val_categorical_accuracy: 0.4974\n",
            "Epoch 20/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.9596 - accuracy: 0.4558 - categorical_accuracy: 0.4558 - val_loss: 0.9567 - val_accuracy: 0.4991 - val_categorical_accuracy: 0.4991\n",
            "Epoch 21/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.9591 - accuracy: 0.4553 - categorical_accuracy: 0.4553 - val_loss: 0.9549 - val_accuracy: 0.5009 - val_categorical_accuracy: 0.5009\n",
            "Epoch 22/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.9561 - accuracy: 0.4711 - categorical_accuracy: 0.4711 - val_loss: 0.9526 - val_accuracy: 0.5222 - val_categorical_accuracy: 0.5222\n",
            "Epoch 23/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.9538 - accuracy: 0.4864 - categorical_accuracy: 0.4864 - val_loss: 0.9495 - val_accuracy: 0.5282 - val_categorical_accuracy: 0.5282\n",
            "Epoch 24/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.9514 - accuracy: 0.4848 - categorical_accuracy: 0.4848 - val_loss: 0.9449 - val_accuracy: 0.5368 - val_categorical_accuracy: 0.5368\n",
            "Epoch 25/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.9466 - accuracy: 0.4889 - categorical_accuracy: 0.4889 - val_loss: 0.9378 - val_accuracy: 0.5368 - val_categorical_accuracy: 0.5368\n",
            "Epoch 26/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.9411 - accuracy: 0.5071 - categorical_accuracy: 0.5071 - val_loss: 0.9254 - val_accuracy: 0.5624 - val_categorical_accuracy: 0.5624\n",
            "Epoch 27/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.9259 - accuracy: 0.5145 - categorical_accuracy: 0.5145 - val_loss: 0.9018 - val_accuracy: 0.5684 - val_categorical_accuracy: 0.5684\n",
            "Epoch 28/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.8971 - accuracy: 0.5423 - categorical_accuracy: 0.5423 - val_loss: 0.8596 - val_accuracy: 0.5709 - val_categorical_accuracy: 0.5709\n",
            "Epoch 29/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.8611 - accuracy: 0.5486 - categorical_accuracy: 0.5486 - val_loss: 0.8069 - val_accuracy: 0.5906 - val_categorical_accuracy: 0.5906\n",
            "Epoch 30/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.8119 - accuracy: 0.5652 - categorical_accuracy: 0.5652 - val_loss: 0.7661 - val_accuracy: 0.5906 - val_categorical_accuracy: 0.5906\n",
            "Epoch 31/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.7725 - accuracy: 0.5677 - categorical_accuracy: 0.5677 - val_loss: 0.7420 - val_accuracy: 0.5906 - val_categorical_accuracy: 0.5906\n",
            "Epoch 32/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.7510 - accuracy: 0.5818 - categorical_accuracy: 0.5818 - val_loss: 0.7279 - val_accuracy: 0.5906 - val_categorical_accuracy: 0.5906\n",
            "Epoch 33/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.7414 - accuracy: 0.5711 - categorical_accuracy: 0.5711 - val_loss: 0.7189 - val_accuracy: 0.5906 - val_categorical_accuracy: 0.5906\n",
            "Epoch 34/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.7186 - accuracy: 0.5875 - categorical_accuracy: 0.5875 - val_loss: 0.7121 - val_accuracy: 0.5906 - val_categorical_accuracy: 0.5906\n",
            "Epoch 35/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.7167 - accuracy: 0.5734 - categorical_accuracy: 0.5734 - val_loss: 0.7064 - val_accuracy: 0.5906 - val_categorical_accuracy: 0.5906\n",
            "Epoch 36/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.6992 - accuracy: 0.5955 - categorical_accuracy: 0.5955 - val_loss: 0.7015 - val_accuracy: 0.5906 - val_categorical_accuracy: 0.5906\n",
            "Epoch 37/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.7062 - accuracy: 0.5803 - categorical_accuracy: 0.5803 - val_loss: 0.6970 - val_accuracy: 0.5906 - val_categorical_accuracy: 0.5906\n",
            "Epoch 38/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6973 - accuracy: 0.5997 - categorical_accuracy: 0.5997 - val_loss: 0.6929 - val_accuracy: 0.5906 - val_categorical_accuracy: 0.5906\n",
            "Epoch 39/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6961 - accuracy: 0.5933 - categorical_accuracy: 0.5933 - val_loss: 0.6891 - val_accuracy: 0.5906 - val_categorical_accuracy: 0.5906\n",
            "Epoch 40/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.7017 - accuracy: 0.5737 - categorical_accuracy: 0.5737 - val_loss: 0.6854 - val_accuracy: 0.5906 - val_categorical_accuracy: 0.5906\n",
            "Epoch 41/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.7038 - accuracy: 0.5728 - categorical_accuracy: 0.5728 - val_loss: 0.6820 - val_accuracy: 0.5957 - val_categorical_accuracy: 0.5957\n",
            "Epoch 42/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6918 - accuracy: 0.5883 - categorical_accuracy: 0.5883 - val_loss: 0.6787 - val_accuracy: 0.5983 - val_categorical_accuracy: 0.5983\n",
            "Epoch 43/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.6937 - accuracy: 0.5924 - categorical_accuracy: 0.5924 - val_loss: 0.6756 - val_accuracy: 0.5983 - val_categorical_accuracy: 0.5983\n",
            "Epoch 44/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6876 - accuracy: 0.6015 - categorical_accuracy: 0.6015 - val_loss: 0.6726 - val_accuracy: 0.5983 - val_categorical_accuracy: 0.5983\n",
            "Epoch 45/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6908 - accuracy: 0.5929 - categorical_accuracy: 0.5929 - val_loss: 0.6696 - val_accuracy: 0.5983 - val_categorical_accuracy: 0.5983\n",
            "Epoch 46/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6721 - accuracy: 0.5941 - categorical_accuracy: 0.5941 - val_loss: 0.6668 - val_accuracy: 0.5983 - val_categorical_accuracy: 0.5983\n",
            "Epoch 47/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6674 - accuracy: 0.5960 - categorical_accuracy: 0.5960 - val_loss: 0.6640 - val_accuracy: 0.5983 - val_categorical_accuracy: 0.5983\n",
            "Epoch 48/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6661 - accuracy: 0.5878 - categorical_accuracy: 0.5878 - val_loss: 0.6613 - val_accuracy: 0.5983 - val_categorical_accuracy: 0.5983\n",
            "Epoch 49/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6608 - accuracy: 0.5930 - categorical_accuracy: 0.5930 - val_loss: 0.6587 - val_accuracy: 0.5983 - val_categorical_accuracy: 0.5983\n",
            "Epoch 50/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6733 - accuracy: 0.6000 - categorical_accuracy: 0.6000 - val_loss: 0.6561 - val_accuracy: 0.5983 - val_categorical_accuracy: 0.5983\n",
            "Epoch 51/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.6748 - accuracy: 0.5978 - categorical_accuracy: 0.5978 - val_loss: 0.6536 - val_accuracy: 0.5983 - val_categorical_accuracy: 0.5983\n",
            "Epoch 52/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.6613 - accuracy: 0.6041 - categorical_accuracy: 0.6041 - val_loss: 0.6511 - val_accuracy: 0.5983 - val_categorical_accuracy: 0.5983\n",
            "Epoch 53/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.6602 - accuracy: 0.5874 - categorical_accuracy: 0.5874 - val_loss: 0.6486 - val_accuracy: 0.5983 - val_categorical_accuracy: 0.5983\n",
            "Epoch 54/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6665 - accuracy: 0.5950 - categorical_accuracy: 0.5950 - val_loss: 0.6462 - val_accuracy: 0.5983 - val_categorical_accuracy: 0.5983\n",
            "Epoch 55/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6444 - accuracy: 0.5976 - categorical_accuracy: 0.5976 - val_loss: 0.6437 - val_accuracy: 0.5983 - val_categorical_accuracy: 0.5983\n",
            "Epoch 56/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6383 - accuracy: 0.6062 - categorical_accuracy: 0.6062 - val_loss: 0.6413 - val_accuracy: 0.5983 - val_categorical_accuracy: 0.5983\n",
            "Epoch 57/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6584 - accuracy: 0.6006 - categorical_accuracy: 0.6006 - val_loss: 0.6388 - val_accuracy: 0.5983 - val_categorical_accuracy: 0.5983\n",
            "Epoch 58/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6414 - accuracy: 0.6072 - categorical_accuracy: 0.6072 - val_loss: 0.6363 - val_accuracy: 0.6043 - val_categorical_accuracy: 0.6043\n",
            "Epoch 59/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6282 - accuracy: 0.6244 - categorical_accuracy: 0.6244 - val_loss: 0.6338 - val_accuracy: 0.6043 - val_categorical_accuracy: 0.6043\n",
            "Epoch 60/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6481 - accuracy: 0.5943 - categorical_accuracy: 0.5943 - val_loss: 0.6312 - val_accuracy: 0.6051 - val_categorical_accuracy: 0.6051\n",
            "Epoch 61/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6285 - accuracy: 0.6008 - categorical_accuracy: 0.6008 - val_loss: 0.6286 - val_accuracy: 0.6051 - val_categorical_accuracy: 0.6051\n",
            "Epoch 62/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.6220 - accuracy: 0.6156 - categorical_accuracy: 0.6156 - val_loss: 0.6259 - val_accuracy: 0.6051 - val_categorical_accuracy: 0.6051\n",
            "Epoch 63/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6292 - accuracy: 0.5999 - categorical_accuracy: 0.5999 - val_loss: 0.6232 - val_accuracy: 0.6060 - val_categorical_accuracy: 0.6060\n",
            "Epoch 64/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6140 - accuracy: 0.6130 - categorical_accuracy: 0.6130 - val_loss: 0.6205 - val_accuracy: 0.6060 - val_categorical_accuracy: 0.6060\n",
            "Epoch 65/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6111 - accuracy: 0.6140 - categorical_accuracy: 0.6140 - val_loss: 0.6179 - val_accuracy: 0.6060 - val_categorical_accuracy: 0.6060\n",
            "Epoch 66/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6356 - accuracy: 0.5871 - categorical_accuracy: 0.5871 - val_loss: 0.6155 - val_accuracy: 0.6060 - val_categorical_accuracy: 0.6060\n",
            "Epoch 67/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.5958 - accuracy: 0.6182 - categorical_accuracy: 0.6182 - val_loss: 0.6132 - val_accuracy: 0.6060 - val_categorical_accuracy: 0.6060\n",
            "Epoch 68/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6063 - accuracy: 0.6038 - categorical_accuracy: 0.6038 - val_loss: 0.6110 - val_accuracy: 0.6068 - val_categorical_accuracy: 0.6068\n",
            "Epoch 69/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.6090 - accuracy: 0.6094 - categorical_accuracy: 0.6094 - val_loss: 0.6090 - val_accuracy: 0.6068 - val_categorical_accuracy: 0.6068\n",
            "Epoch 70/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6082 - accuracy: 0.6059 - categorical_accuracy: 0.6059 - val_loss: 0.6071 - val_accuracy: 0.6068 - val_categorical_accuracy: 0.6068\n",
            "Epoch 71/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5929 - accuracy: 0.6138 - categorical_accuracy: 0.6138 - val_loss: 0.6053 - val_accuracy: 0.6060 - val_categorical_accuracy: 0.6060\n",
            "Epoch 72/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5887 - accuracy: 0.6250 - categorical_accuracy: 0.6250 - val_loss: 0.6036 - val_accuracy: 0.6060 - val_categorical_accuracy: 0.6060\n",
            "Epoch 73/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6170 - accuracy: 0.5985 - categorical_accuracy: 0.5985 - val_loss: 0.6019 - val_accuracy: 0.6060 - val_categorical_accuracy: 0.6060\n",
            "Epoch 74/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5964 - accuracy: 0.6138 - categorical_accuracy: 0.6138 - val_loss: 0.6004 - val_accuracy: 0.6060 - val_categorical_accuracy: 0.6060\n",
            "Epoch 75/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.5796 - accuracy: 0.6235 - categorical_accuracy: 0.6235 - val_loss: 0.5989 - val_accuracy: 0.6060 - val_categorical_accuracy: 0.6060\n",
            "Epoch 76/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.6118 - accuracy: 0.5971 - categorical_accuracy: 0.5971 - val_loss: 0.5974 - val_accuracy: 0.6085 - val_categorical_accuracy: 0.6085\n",
            "Epoch 77/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5889 - accuracy: 0.6088 - categorical_accuracy: 0.6088 - val_loss: 0.5960 - val_accuracy: 0.6085 - val_categorical_accuracy: 0.6085\n",
            "Epoch 78/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5852 - accuracy: 0.6199 - categorical_accuracy: 0.6199 - val_loss: 0.5946 - val_accuracy: 0.6085 - val_categorical_accuracy: 0.6085\n",
            "Epoch 79/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5872 - accuracy: 0.6017 - categorical_accuracy: 0.6017 - val_loss: 0.5933 - val_accuracy: 0.6085 - val_categorical_accuracy: 0.6085\n",
            "Epoch 80/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6020 - accuracy: 0.5898 - categorical_accuracy: 0.5898 - val_loss: 0.5920 - val_accuracy: 0.6094 - val_categorical_accuracy: 0.6094\n",
            "Epoch 81/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.5923 - accuracy: 0.6162 - categorical_accuracy: 0.6162 - val_loss: 0.5906 - val_accuracy: 0.6299 - val_categorical_accuracy: 0.6299\n",
            "Epoch 82/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.5905 - accuracy: 0.6186 - categorical_accuracy: 0.6186 - val_loss: 0.5894 - val_accuracy: 0.6299 - val_categorical_accuracy: 0.6299\n",
            "Epoch 83/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5792 - accuracy: 0.6293 - categorical_accuracy: 0.6293 - val_loss: 0.5881 - val_accuracy: 0.6299 - val_categorical_accuracy: 0.6299\n",
            "Epoch 84/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.5771 - accuracy: 0.6155 - categorical_accuracy: 0.6155 - val_loss: 0.5868 - val_accuracy: 0.6299 - val_categorical_accuracy: 0.6299\n",
            "Epoch 85/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5816 - accuracy: 0.6114 - categorical_accuracy: 0.6114 - val_loss: 0.5855 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 86/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5783 - accuracy: 0.6234 - categorical_accuracy: 0.6234 - val_loss: 0.5842 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 87/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.5876 - accuracy: 0.6096 - categorical_accuracy: 0.6096 - val_loss: 0.5828 - val_accuracy: 0.6239 - val_categorical_accuracy: 0.6239\n",
            "Epoch 88/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5819 - accuracy: 0.6067 - categorical_accuracy: 0.6067 - val_loss: 0.5815 - val_accuracy: 0.6239 - val_categorical_accuracy: 0.6239\n",
            "Epoch 89/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5659 - accuracy: 0.6245 - categorical_accuracy: 0.6245 - val_loss: 0.5801 - val_accuracy: 0.6248 - val_categorical_accuracy: 0.6248\n",
            "Epoch 90/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.5925 - accuracy: 0.6050 - categorical_accuracy: 0.6050 - val_loss: 0.5786 - val_accuracy: 0.6248 - val_categorical_accuracy: 0.6248\n",
            "Epoch 91/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.5851 - accuracy: 0.6108 - categorical_accuracy: 0.6108 - val_loss: 0.5771 - val_accuracy: 0.6248 - val_categorical_accuracy: 0.6248\n",
            "Epoch 92/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.5766 - accuracy: 0.6202 - categorical_accuracy: 0.6202 - val_loss: 0.5755 - val_accuracy: 0.6453 - val_categorical_accuracy: 0.6453\n",
            "Epoch 93/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5785 - accuracy: 0.6179 - categorical_accuracy: 0.6179 - val_loss: 0.5739 - val_accuracy: 0.6453 - val_categorical_accuracy: 0.6453\n",
            "Epoch 94/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5709 - accuracy: 0.6359 - categorical_accuracy: 0.6359 - val_loss: 0.5722 - val_accuracy: 0.6462 - val_categorical_accuracy: 0.6462\n",
            "Epoch 95/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5660 - accuracy: 0.6374 - categorical_accuracy: 0.6374 - val_loss: 0.5703 - val_accuracy: 0.6479 - val_categorical_accuracy: 0.6479\n",
            "Epoch 96/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5718 - accuracy: 0.6284 - categorical_accuracy: 0.6284 - val_loss: 0.5684 - val_accuracy: 0.6479 - val_categorical_accuracy: 0.6479\n",
            "Epoch 97/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5594 - accuracy: 0.6262 - categorical_accuracy: 0.6262 - val_loss: 0.5663 - val_accuracy: 0.6479 - val_categorical_accuracy: 0.6479\n",
            "Epoch 98/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5640 - accuracy: 0.6297 - categorical_accuracy: 0.6297 - val_loss: 0.5641 - val_accuracy: 0.6479 - val_categorical_accuracy: 0.6479\n",
            "Epoch 99/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5567 - accuracy: 0.6351 - categorical_accuracy: 0.6351 - val_loss: 0.5618 - val_accuracy: 0.6479 - val_categorical_accuracy: 0.6479\n",
            "Epoch 100/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.5567 - accuracy: 0.6460 - categorical_accuracy: 0.6460 - val_loss: 0.5594 - val_accuracy: 0.6479 - val_categorical_accuracy: 0.6479\n",
            "Epoch 101/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.5543 - accuracy: 0.6247 - categorical_accuracy: 0.6247 - val_loss: 0.5569 - val_accuracy: 0.6479 - val_categorical_accuracy: 0.6479\n",
            "Epoch 102/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5569 - accuracy: 0.6332 - categorical_accuracy: 0.6332 - val_loss: 0.5543 - val_accuracy: 0.6479 - val_categorical_accuracy: 0.6479\n",
            "Epoch 103/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5539 - accuracy: 0.6270 - categorical_accuracy: 0.6270 - val_loss: 0.5518 - val_accuracy: 0.6496 - val_categorical_accuracy: 0.6496\n",
            "Epoch 104/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5498 - accuracy: 0.6317 - categorical_accuracy: 0.6317 - val_loss: 0.5492 - val_accuracy: 0.6496 - val_categorical_accuracy: 0.6496\n",
            "Epoch 105/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5530 - accuracy: 0.6257 - categorical_accuracy: 0.6257 - val_loss: 0.5467 - val_accuracy: 0.6496 - val_categorical_accuracy: 0.6496\n",
            "Epoch 106/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.5404 - accuracy: 0.6267 - categorical_accuracy: 0.6267 - val_loss: 0.5442 - val_accuracy: 0.6496 - val_categorical_accuracy: 0.6496\n",
            "Epoch 107/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.5296 - accuracy: 0.6477 - categorical_accuracy: 0.6477 - val_loss: 0.5418 - val_accuracy: 0.6496 - val_categorical_accuracy: 0.6496\n",
            "Epoch 108/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5298 - accuracy: 0.6273 - categorical_accuracy: 0.6273 - val_loss: 0.5395 - val_accuracy: 0.6496 - val_categorical_accuracy: 0.6496\n",
            "Epoch 109/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5309 - accuracy: 0.6345 - categorical_accuracy: 0.6345 - val_loss: 0.5372 - val_accuracy: 0.6496 - val_categorical_accuracy: 0.6496\n",
            "Epoch 110/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.5423 - accuracy: 0.6325 - categorical_accuracy: 0.6325 - val_loss: 0.5350 - val_accuracy: 0.6496 - val_categorical_accuracy: 0.6496\n",
            "Epoch 111/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5289 - accuracy: 0.6319 - categorical_accuracy: 0.6319 - val_loss: 0.5329 - val_accuracy: 0.6496 - val_categorical_accuracy: 0.6496\n",
            "Epoch 112/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5246 - accuracy: 0.6422 - categorical_accuracy: 0.6422 - val_loss: 0.5308 - val_accuracy: 0.6496 - val_categorical_accuracy: 0.6496\n",
            "Epoch 113/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.5188 - accuracy: 0.6511 - categorical_accuracy: 0.6511 - val_loss: 0.5289 - val_accuracy: 0.6504 - val_categorical_accuracy: 0.6504\n",
            "Epoch 114/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.5182 - accuracy: 0.6401 - categorical_accuracy: 0.6401 - val_loss: 0.5271 - val_accuracy: 0.6504 - val_categorical_accuracy: 0.6504\n",
            "Epoch 115/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5202 - accuracy: 0.6255 - categorical_accuracy: 0.6255 - val_loss: 0.5253 - val_accuracy: 0.6504 - val_categorical_accuracy: 0.6504\n",
            "Epoch 116/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.5114 - accuracy: 0.6348 - categorical_accuracy: 0.6348 - val_loss: 0.5237 - val_accuracy: 0.6504 - val_categorical_accuracy: 0.6504\n",
            "Epoch 117/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5206 - accuracy: 0.6395 - categorical_accuracy: 0.6395 - val_loss: 0.5220 - val_accuracy: 0.6718 - val_categorical_accuracy: 0.6718\n",
            "Epoch 118/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5102 - accuracy: 0.6406 - categorical_accuracy: 0.6406 - val_loss: 0.5204 - val_accuracy: 0.6718 - val_categorical_accuracy: 0.6718\n",
            "Epoch 119/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.5036 - accuracy: 0.6370 - categorical_accuracy: 0.6370 - val_loss: 0.5188 - val_accuracy: 0.6718 - val_categorical_accuracy: 0.6718\n",
            "Epoch 120/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5035 - accuracy: 0.6426 - categorical_accuracy: 0.6426 - val_loss: 0.5173 - val_accuracy: 0.6718 - val_categorical_accuracy: 0.6718\n",
            "Epoch 121/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.5230 - accuracy: 0.6298 - categorical_accuracy: 0.6298 - val_loss: 0.5156 - val_accuracy: 0.6726 - val_categorical_accuracy: 0.6726\n",
            "Epoch 122/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.5056 - accuracy: 0.6326 - categorical_accuracy: 0.6326 - val_loss: 0.5140 - val_accuracy: 0.6726 - val_categorical_accuracy: 0.6726\n",
            "Epoch 123/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.5077 - accuracy: 0.6411 - categorical_accuracy: 0.6411 - val_loss: 0.5123 - val_accuracy: 0.6726 - val_categorical_accuracy: 0.6726\n",
            "Epoch 124/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.5017 - accuracy: 0.6434 - categorical_accuracy: 0.6434 - val_loss: 0.5106 - val_accuracy: 0.6726 - val_categorical_accuracy: 0.6726\n",
            "Epoch 125/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.5016 - accuracy: 0.6355 - categorical_accuracy: 0.6355 - val_loss: 0.5088 - val_accuracy: 0.6726 - val_categorical_accuracy: 0.6726\n",
            "Epoch 126/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.5048 - accuracy: 0.6452 - categorical_accuracy: 0.6452 - val_loss: 0.5068 - val_accuracy: 0.6701 - val_categorical_accuracy: 0.6701\n",
            "Epoch 127/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.5025 - accuracy: 0.6406 - categorical_accuracy: 0.6406 - val_loss: 0.5048 - val_accuracy: 0.6701 - val_categorical_accuracy: 0.6701\n",
            "Epoch 128/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.4944 - accuracy: 0.6474 - categorical_accuracy: 0.6474 - val_loss: 0.5025 - val_accuracy: 0.6701 - val_categorical_accuracy: 0.6701\n",
            "Epoch 129/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.4917 - accuracy: 0.6300 - categorical_accuracy: 0.6300 - val_loss: 0.5001 - val_accuracy: 0.6701 - val_categorical_accuracy: 0.6701\n",
            "Epoch 130/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.4949 - accuracy: 0.6455 - categorical_accuracy: 0.6455 - val_loss: 0.4975 - val_accuracy: 0.6615 - val_categorical_accuracy: 0.6615\n",
            "Epoch 131/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.4937 - accuracy: 0.6448 - categorical_accuracy: 0.6448 - val_loss: 0.4947 - val_accuracy: 0.6650 - val_categorical_accuracy: 0.6650\n",
            "Epoch 132/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.4919 - accuracy: 0.6552 - categorical_accuracy: 0.6552 - val_loss: 0.4916 - val_accuracy: 0.6650 - val_categorical_accuracy: 0.6650\n",
            "Epoch 133/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.4739 - accuracy: 0.6705 - categorical_accuracy: 0.6705 - val_loss: 0.4882 - val_accuracy: 0.6650 - val_categorical_accuracy: 0.6650\n",
            "Epoch 134/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.4859 - accuracy: 0.6625 - categorical_accuracy: 0.6625 - val_loss: 0.4844 - val_accuracy: 0.6650 - val_categorical_accuracy: 0.6650\n",
            "Epoch 135/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.4833 - accuracy: 0.6615 - categorical_accuracy: 0.6615 - val_loss: 0.4804 - val_accuracy: 0.6821 - val_categorical_accuracy: 0.6821\n",
            "Epoch 136/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.4679 - accuracy: 0.6635 - categorical_accuracy: 0.6635 - val_loss: 0.4760 - val_accuracy: 0.6821 - val_categorical_accuracy: 0.6821\n",
            "Epoch 137/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.4631 - accuracy: 0.6679 - categorical_accuracy: 0.6679 - val_loss: 0.4713 - val_accuracy: 0.6821 - val_categorical_accuracy: 0.6821\n",
            "Epoch 138/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.4717 - accuracy: 0.6563 - categorical_accuracy: 0.6563 - val_loss: 0.4663 - val_accuracy: 0.6821 - val_categorical_accuracy: 0.6821\n",
            "Epoch 139/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.4624 - accuracy: 0.6678 - categorical_accuracy: 0.6678 - val_loss: 0.4612 - val_accuracy: 0.6821 - val_categorical_accuracy: 0.6821\n",
            "Epoch 140/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.4427 - accuracy: 0.6702 - categorical_accuracy: 0.6702 - val_loss: 0.4558 - val_accuracy: 0.6821 - val_categorical_accuracy: 0.6821\n",
            "Epoch 141/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.4519 - accuracy: 0.6618 - categorical_accuracy: 0.6618 - val_loss: 0.4504 - val_accuracy: 0.6821 - val_categorical_accuracy: 0.6821\n",
            "Epoch 142/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.4381 - accuracy: 0.6807 - categorical_accuracy: 0.6807 - val_loss: 0.4450 - val_accuracy: 0.6846 - val_categorical_accuracy: 0.6846\n",
            "Epoch 143/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.4387 - accuracy: 0.6685 - categorical_accuracy: 0.6685 - val_loss: 0.4395 - val_accuracy: 0.6846 - val_categorical_accuracy: 0.6846\n",
            "Epoch 144/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.4465 - accuracy: 0.6605 - categorical_accuracy: 0.6605 - val_loss: 0.4342 - val_accuracy: 0.6838 - val_categorical_accuracy: 0.6838\n",
            "Epoch 145/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.4229 - accuracy: 0.6778 - categorical_accuracy: 0.6778 - val_loss: 0.4289 - val_accuracy: 0.6838 - val_categorical_accuracy: 0.6838\n",
            "Epoch 146/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.4298 - accuracy: 0.6791 - categorical_accuracy: 0.6791 - val_loss: 0.4238 - val_accuracy: 0.6838 - val_categorical_accuracy: 0.6838\n",
            "Epoch 147/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.4205 - accuracy: 0.6657 - categorical_accuracy: 0.6657 - val_loss: 0.4188 - val_accuracy: 0.6838 - val_categorical_accuracy: 0.6838\n",
            "Epoch 148/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.4033 - accuracy: 0.6681 - categorical_accuracy: 0.6681 - val_loss: 0.4139 - val_accuracy: 0.6838 - val_categorical_accuracy: 0.6838\n",
            "Epoch 149/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.4121 - accuracy: 0.6627 - categorical_accuracy: 0.6627 - val_loss: 0.4091 - val_accuracy: 0.6838 - val_categorical_accuracy: 0.6838\n",
            "Epoch 150/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.4154 - accuracy: 0.6781 - categorical_accuracy: 0.6781 - val_loss: 0.4044 - val_accuracy: 0.6838 - val_categorical_accuracy: 0.6838\n",
            "Epoch 151/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.4054 - accuracy: 0.6618 - categorical_accuracy: 0.6618 - val_loss: 0.3996 - val_accuracy: 0.6838 - val_categorical_accuracy: 0.6838\n",
            "Epoch 152/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.3971 - accuracy: 0.6819 - categorical_accuracy: 0.6819 - val_loss: 0.3949 - val_accuracy: 0.6838 - val_categorical_accuracy: 0.6838\n",
            "Epoch 153/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.4031 - accuracy: 0.6600 - categorical_accuracy: 0.6600 - val_loss: 0.3900 - val_accuracy: 0.6838 - val_categorical_accuracy: 0.6838\n",
            "Epoch 154/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.3975 - accuracy: 0.6671 - categorical_accuracy: 0.6671 - val_loss: 0.3851 - val_accuracy: 0.6838 - val_categorical_accuracy: 0.6838\n",
            "Epoch 155/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.3733 - accuracy: 0.6749 - categorical_accuracy: 0.6749 - val_loss: 0.3801 - val_accuracy: 0.6838 - val_categorical_accuracy: 0.6838\n",
            "Epoch 156/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.3825 - accuracy: 0.6753 - categorical_accuracy: 0.6753 - val_loss: 0.3752 - val_accuracy: 0.6838 - val_categorical_accuracy: 0.6838\n",
            "Epoch 157/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.3777 - accuracy: 0.6789 - categorical_accuracy: 0.6789 - val_loss: 0.3703 - val_accuracy: 0.6838 - val_categorical_accuracy: 0.6838\n",
            "Epoch 158/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.3727 - accuracy: 0.6818 - categorical_accuracy: 0.6818 - val_loss: 0.3657 - val_accuracy: 0.6846 - val_categorical_accuracy: 0.6846\n",
            "Epoch 159/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.3677 - accuracy: 0.6752 - categorical_accuracy: 0.6752 - val_loss: 0.3612 - val_accuracy: 0.6846 - val_categorical_accuracy: 0.6846\n",
            "Epoch 160/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.3548 - accuracy: 0.6712 - categorical_accuracy: 0.6712 - val_loss: 0.3571 - val_accuracy: 0.6846 - val_categorical_accuracy: 0.6846\n",
            "Epoch 161/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.3613 - accuracy: 0.6706 - categorical_accuracy: 0.6706 - val_loss: 0.3531 - val_accuracy: 0.6846 - val_categorical_accuracy: 0.6846\n",
            "Epoch 162/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.3552 - accuracy: 0.6719 - categorical_accuracy: 0.6719 - val_loss: 0.3494 - val_accuracy: 0.6846 - val_categorical_accuracy: 0.6846\n",
            "Epoch 163/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.3398 - accuracy: 0.6866 - categorical_accuracy: 0.6866 - val_loss: 0.3460 - val_accuracy: 0.6846 - val_categorical_accuracy: 0.6846\n",
            "Epoch 164/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.3416 - accuracy: 0.6836 - categorical_accuracy: 0.6836 - val_loss: 0.3429 - val_accuracy: 0.6846 - val_categorical_accuracy: 0.6846\n",
            "Epoch 165/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.3545 - accuracy: 0.6742 - categorical_accuracy: 0.6742 - val_loss: 0.3398 - val_accuracy: 0.6846 - val_categorical_accuracy: 0.6846\n",
            "Epoch 166/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.3377 - accuracy: 0.6809 - categorical_accuracy: 0.6809 - val_loss: 0.3370 - val_accuracy: 0.6880 - val_categorical_accuracy: 0.6880\n",
            "Epoch 167/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.3295 - accuracy: 0.6934 - categorical_accuracy: 0.6934 - val_loss: 0.3342 - val_accuracy: 0.6940 - val_categorical_accuracy: 0.6940\n",
            "Epoch 168/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.3445 - accuracy: 0.6830 - categorical_accuracy: 0.6830 - val_loss: 0.3316 - val_accuracy: 0.6940 - val_categorical_accuracy: 0.6940\n",
            "Epoch 169/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.3470 - accuracy: 0.6740 - categorical_accuracy: 0.6740 - val_loss: 0.3290 - val_accuracy: 0.7154 - val_categorical_accuracy: 0.7154\n",
            "Epoch 170/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.3339 - accuracy: 0.6957 - categorical_accuracy: 0.6957 - val_loss: 0.3265 - val_accuracy: 0.7154 - val_categorical_accuracy: 0.7154\n",
            "Epoch 171/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.3368 - accuracy: 0.6888 - categorical_accuracy: 0.6888 - val_loss: 0.3241 - val_accuracy: 0.7154 - val_categorical_accuracy: 0.7154\n",
            "Epoch 172/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.3172 - accuracy: 0.6962 - categorical_accuracy: 0.6962 - val_loss: 0.3216 - val_accuracy: 0.7154 - val_categorical_accuracy: 0.7154\n",
            "Epoch 173/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.3246 - accuracy: 0.7016 - categorical_accuracy: 0.7016 - val_loss: 0.3193 - val_accuracy: 0.7154 - val_categorical_accuracy: 0.7154\n",
            "Epoch 174/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.3107 - accuracy: 0.6823 - categorical_accuracy: 0.6823 - val_loss: 0.3168 - val_accuracy: 0.7154 - val_categorical_accuracy: 0.7154\n",
            "Epoch 175/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.3129 - accuracy: 0.7102 - categorical_accuracy: 0.7102 - val_loss: 0.3145 - val_accuracy: 0.7179 - val_categorical_accuracy: 0.7179\n",
            "Epoch 176/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.3159 - accuracy: 0.6978 - categorical_accuracy: 0.6978 - val_loss: 0.3121 - val_accuracy: 0.7188 - val_categorical_accuracy: 0.7188\n",
            "Epoch 177/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.3137 - accuracy: 0.7110 - categorical_accuracy: 0.7110 - val_loss: 0.3098 - val_accuracy: 0.7188 - val_categorical_accuracy: 0.7188\n",
            "Epoch 178/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.3027 - accuracy: 0.7064 - categorical_accuracy: 0.7064 - val_loss: 0.3076 - val_accuracy: 0.7188 - val_categorical_accuracy: 0.7188\n",
            "Epoch 179/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.3030 - accuracy: 0.7168 - categorical_accuracy: 0.7168 - val_loss: 0.3053 - val_accuracy: 0.7188 - val_categorical_accuracy: 0.7188\n",
            "Epoch 180/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.3027 - accuracy: 0.7120 - categorical_accuracy: 0.7120 - val_loss: 0.3031 - val_accuracy: 0.7188 - val_categorical_accuracy: 0.7188\n",
            "Epoch 181/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.3142 - accuracy: 0.6973 - categorical_accuracy: 0.6973 - val_loss: 0.3008 - val_accuracy: 0.7188 - val_categorical_accuracy: 0.7188\n",
            "Epoch 182/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.2939 - accuracy: 0.7047 - categorical_accuracy: 0.7047 - val_loss: 0.2987 - val_accuracy: 0.7188 - val_categorical_accuracy: 0.7188\n",
            "Epoch 183/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.3033 - accuracy: 0.6984 - categorical_accuracy: 0.6984 - val_loss: 0.2965 - val_accuracy: 0.7188 - val_categorical_accuracy: 0.7188\n",
            "Epoch 184/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.2899 - accuracy: 0.7064 - categorical_accuracy: 0.7064 - val_loss: 0.2943 - val_accuracy: 0.7188 - val_categorical_accuracy: 0.7188\n",
            "Epoch 185/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.2943 - accuracy: 0.7212 - categorical_accuracy: 0.7212 - val_loss: 0.2921 - val_accuracy: 0.7188 - val_categorical_accuracy: 0.7188\n",
            "Epoch 186/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.2949 - accuracy: 0.7177 - categorical_accuracy: 0.7177 - val_loss: 0.2900 - val_accuracy: 0.7359 - val_categorical_accuracy: 0.7359\n",
            "Epoch 187/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.2742 - accuracy: 0.7294 - categorical_accuracy: 0.7294 - val_loss: 0.2878 - val_accuracy: 0.7359 - val_categorical_accuracy: 0.7359\n",
            "Epoch 188/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.2805 - accuracy: 0.7282 - categorical_accuracy: 0.7282 - val_loss: 0.2857 - val_accuracy: 0.7385 - val_categorical_accuracy: 0.7385\n",
            "Epoch 189/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.2569 - accuracy: 0.7320 - categorical_accuracy: 0.7320 - val_loss: 0.2836 - val_accuracy: 0.7385 - val_categorical_accuracy: 0.7385\n",
            "Epoch 190/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.2788 - accuracy: 0.7258 - categorical_accuracy: 0.7258 - val_loss: 0.2816 - val_accuracy: 0.7385 - val_categorical_accuracy: 0.7385\n",
            "Epoch 191/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.2809 - accuracy: 0.7228 - categorical_accuracy: 0.7228 - val_loss: 0.2797 - val_accuracy: 0.7410 - val_categorical_accuracy: 0.7410\n",
            "Epoch 192/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.2858 - accuracy: 0.7240 - categorical_accuracy: 0.7240 - val_loss: 0.2778 - val_accuracy: 0.7410 - val_categorical_accuracy: 0.7410\n",
            "Epoch 193/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.2821 - accuracy: 0.7218 - categorical_accuracy: 0.7218 - val_loss: 0.2761 - val_accuracy: 0.7410 - val_categorical_accuracy: 0.7410\n",
            "Epoch 194/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.2627 - accuracy: 0.7320 - categorical_accuracy: 0.7320 - val_loss: 0.2744 - val_accuracy: 0.7410 - val_categorical_accuracy: 0.7410\n",
            "Epoch 195/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.2660 - accuracy: 0.7405 - categorical_accuracy: 0.7405 - val_loss: 0.2728 - val_accuracy: 0.7410 - val_categorical_accuracy: 0.7410\n",
            "Epoch 196/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.2709 - accuracy: 0.7298 - categorical_accuracy: 0.7298 - val_loss: 0.2712 - val_accuracy: 0.7427 - val_categorical_accuracy: 0.7427\n",
            "Epoch 197/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.2678 - accuracy: 0.7284 - categorical_accuracy: 0.7284 - val_loss: 0.2697 - val_accuracy: 0.7427 - val_categorical_accuracy: 0.7427\n",
            "Epoch 198/200\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.2614 - accuracy: 0.7433 - categorical_accuracy: 0.7433 - val_loss: 0.2684 - val_accuracy: 0.7427 - val_categorical_accuracy: 0.7427\n",
            "Epoch 199/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.2652 - accuracy: 0.7396 - categorical_accuracy: 0.7396 - val_loss: 0.2671 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "Epoch 200/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 0.2763 - accuracy: 0.7288 - categorical_accuracy: 0.7288 - val_loss: 0.2658 - val_accuracy: 0.7436 - val_categorical_accuracy: 0.7436\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.2658 - accuracy: 0.7436 - categorical_accuracy: 0.7436\n",
            "1142\n",
            "Generation-9 Chromosome-9:\n",
            "Middle layers: 2 | Activation: softsign | Optimization: Adagrad | Loss: categorical_hinge | LR: 0.0001 | Dropout: 0.3 |\n",
            "\tScore 0.66  | Accuracy: 0.74\n",
            "Generation-9 Chromosome-10 scored 0.71  (Chromosome already known)\n",
            "[0.6601251418948173, 0.6601251418948173, 0.6814194995999336, 0.6814194995999336, 0.6814194995999336, 0.6814194995999336, 0.7118400106072426, 0.7118400106072426, 0.7118400106072426] Best accuracies of each generation\n",
            "[array([2.0e+00, 5.0e+00, 1.0e+00, 0.0e+00, 1.0e-04, 2.5e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01]), array([2.e+00, 6.e+00, 4.e+00, 0.e+00, 1.e-05, 3.e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01]), array([2.e+00, 6.e+00, 4.e+00, 0.e+00, 1.e-05, 3.e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01])] Best of each generation\n",
            "Generation-10 Chromosome-1 scored 0.71  (Chromosome already known)\n",
            "Generation-10 Chromosome-2 scored 0.71  (Chromosome already known)\n",
            "Generation-10 Chromosome-3 scored 0.71  (Chromosome already known)\n",
            "Generation-10 Chromosome-4 scored 0.68  (Chromosome already known)\n",
            "Generation-10 Chromosome-5 scored 0.68  (Chromosome already known)\n",
            "Generation-10 Chromosome-6 scored 0.71  (Chromosome already known)\n",
            "Generation-10 Chromosome-7 scored 0.71  (Chromosome already known)\n",
            "Epoch 1/200\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.9715 - accuracy: 0.0057 - categorical_accuracy: 0.0057 - val_loss: 0.9707 - val_accuracy: 0.0026 - val_categorical_accuracy: 0.0026\n",
            "Epoch 2/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9714 - accuracy: 0.0042 - categorical_accuracy: 0.0042 - val_loss: 0.9706 - val_accuracy: 0.0026 - val_categorical_accuracy: 0.0026\n",
            "Epoch 3/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9712 - accuracy: 0.0050 - categorical_accuracy: 0.0050 - val_loss: 0.9705 - val_accuracy: 0.0026 - val_categorical_accuracy: 0.0026\n",
            "Epoch 4/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9706 - accuracy: 0.0046 - categorical_accuracy: 0.0046 - val_loss: 0.9705 - val_accuracy: 0.0026 - val_categorical_accuracy: 0.0026\n",
            "Epoch 5/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9713 - accuracy: 0.0053 - categorical_accuracy: 0.0053 - val_loss: 0.9704 - val_accuracy: 0.0026 - val_categorical_accuracy: 0.0026\n",
            "Epoch 6/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9714 - accuracy: 0.0074 - categorical_accuracy: 0.0074 - val_loss: 0.9704 - val_accuracy: 0.0026 - val_categorical_accuracy: 0.0026\n",
            "Epoch 7/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9713 - accuracy: 0.0060 - categorical_accuracy: 0.0060 - val_loss: 0.9703 - val_accuracy: 0.0026 - val_categorical_accuracy: 0.0026\n",
            "Epoch 8/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9713 - accuracy: 0.0096 - categorical_accuracy: 0.0096 - val_loss: 0.9702 - val_accuracy: 0.0026 - val_categorical_accuracy: 0.0026\n",
            "Epoch 9/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9712 - accuracy: 0.0058 - categorical_accuracy: 0.0058 - val_loss: 0.9702 - val_accuracy: 0.0043 - val_categorical_accuracy: 0.0043\n",
            "Epoch 10/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9707 - accuracy: 0.0092 - categorical_accuracy: 0.0092 - val_loss: 0.9701 - val_accuracy: 0.0043 - val_categorical_accuracy: 0.0043\n",
            "Epoch 11/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9709 - accuracy: 0.0056 - categorical_accuracy: 0.0056 - val_loss: 0.9700 - val_accuracy: 0.0043 - val_categorical_accuracy: 0.0043\n",
            "Epoch 12/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9703 - accuracy: 0.0067 - categorical_accuracy: 0.0067 - val_loss: 0.9700 - val_accuracy: 0.0043 - val_categorical_accuracy: 0.0043\n",
            "Epoch 13/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9709 - accuracy: 0.0109 - categorical_accuracy: 0.0109 - val_loss: 0.9699 - val_accuracy: 0.0043 - val_categorical_accuracy: 0.0043\n",
            "Epoch 14/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9708 - accuracy: 0.0103 - categorical_accuracy: 0.0103 - val_loss: 0.9699 - val_accuracy: 0.0043 - val_categorical_accuracy: 0.0043\n",
            "Epoch 15/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9709 - accuracy: 0.0085 - categorical_accuracy: 0.0085 - val_loss: 0.9698 - val_accuracy: 0.0043 - val_categorical_accuracy: 0.0043\n",
            "Epoch 16/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9703 - accuracy: 0.0143 - categorical_accuracy: 0.0143 - val_loss: 0.9697 - val_accuracy: 0.0043 - val_categorical_accuracy: 0.0043\n",
            "Epoch 17/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9706 - accuracy: 0.0124 - categorical_accuracy: 0.0124 - val_loss: 0.9697 - val_accuracy: 0.0043 - val_categorical_accuracy: 0.0043\n",
            "Epoch 18/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9700 - accuracy: 0.0115 - categorical_accuracy: 0.0115 - val_loss: 0.9696 - val_accuracy: 0.0043 - val_categorical_accuracy: 0.0043\n",
            "Epoch 19/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9708 - accuracy: 0.0137 - categorical_accuracy: 0.0137 - val_loss: 0.9695 - val_accuracy: 0.0043 - val_categorical_accuracy: 0.0043\n",
            "Epoch 20/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9708 - accuracy: 0.0169 - categorical_accuracy: 0.0169 - val_loss: 0.9695 - val_accuracy: 0.0043 - val_categorical_accuracy: 0.0043\n",
            "Epoch 21/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9700 - accuracy: 0.0198 - categorical_accuracy: 0.0198 - val_loss: 0.9694 - val_accuracy: 0.0043 - val_categorical_accuracy: 0.0043\n",
            "Epoch 22/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9700 - accuracy: 0.0131 - categorical_accuracy: 0.0131 - val_loss: 0.9694 - val_accuracy: 0.0043 - val_categorical_accuracy: 0.0043\n",
            "Epoch 23/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9705 - accuracy: 0.0222 - categorical_accuracy: 0.0222 - val_loss: 0.9693 - val_accuracy: 0.0265 - val_categorical_accuracy: 0.0265\n",
            "Epoch 24/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9702 - accuracy: 0.0220 - categorical_accuracy: 0.0220 - val_loss: 0.9692 - val_accuracy: 0.0265 - val_categorical_accuracy: 0.0265\n",
            "Epoch 25/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9703 - accuracy: 0.0202 - categorical_accuracy: 0.0202 - val_loss: 0.9692 - val_accuracy: 0.0265 - val_categorical_accuracy: 0.0265\n",
            "Epoch 26/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9702 - accuracy: 0.0196 - categorical_accuracy: 0.0196 - val_loss: 0.9691 - val_accuracy: 0.0265 - val_categorical_accuracy: 0.0265\n",
            "Epoch 27/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9695 - accuracy: 0.0215 - categorical_accuracy: 0.0215 - val_loss: 0.9690 - val_accuracy: 0.0265 - val_categorical_accuracy: 0.0265\n",
            "Epoch 28/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9700 - accuracy: 0.0253 - categorical_accuracy: 0.0253 - val_loss: 0.9690 - val_accuracy: 0.0265 - val_categorical_accuracy: 0.0265\n",
            "Epoch 29/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9702 - accuracy: 0.0261 - categorical_accuracy: 0.0261 - val_loss: 0.9689 - val_accuracy: 0.0274 - val_categorical_accuracy: 0.0274\n",
            "Epoch 30/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9700 - accuracy: 0.0335 - categorical_accuracy: 0.0335 - val_loss: 0.9688 - val_accuracy: 0.0274 - val_categorical_accuracy: 0.0274\n",
            "Epoch 31/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9696 - accuracy: 0.0316 - categorical_accuracy: 0.0316 - val_loss: 0.9688 - val_accuracy: 0.0316 - val_categorical_accuracy: 0.0316\n",
            "Epoch 32/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9700 - accuracy: 0.0273 - categorical_accuracy: 0.0273 - val_loss: 0.9687 - val_accuracy: 0.0325 - val_categorical_accuracy: 0.0325\n",
            "Epoch 33/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9698 - accuracy: 0.0379 - categorical_accuracy: 0.0379 - val_loss: 0.9687 - val_accuracy: 0.0521 - val_categorical_accuracy: 0.0521\n",
            "Epoch 34/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9694 - accuracy: 0.0385 - categorical_accuracy: 0.0385 - val_loss: 0.9686 - val_accuracy: 0.0538 - val_categorical_accuracy: 0.0538\n",
            "Epoch 35/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9696 - accuracy: 0.0362 - categorical_accuracy: 0.0362 - val_loss: 0.9685 - val_accuracy: 0.0581 - val_categorical_accuracy: 0.0581\n",
            "Epoch 36/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9692 - accuracy: 0.0436 - categorical_accuracy: 0.0436 - val_loss: 0.9685 - val_accuracy: 0.0667 - val_categorical_accuracy: 0.0667\n",
            "Epoch 37/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9694 - accuracy: 0.0465 - categorical_accuracy: 0.0465 - val_loss: 0.9684 - val_accuracy: 0.0692 - val_categorical_accuracy: 0.0692\n",
            "Epoch 38/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9696 - accuracy: 0.0428 - categorical_accuracy: 0.0428 - val_loss: 0.9684 - val_accuracy: 0.1051 - val_categorical_accuracy: 0.1051\n",
            "Epoch 39/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9692 - accuracy: 0.0473 - categorical_accuracy: 0.0473 - val_loss: 0.9683 - val_accuracy: 0.1265 - val_categorical_accuracy: 0.1265\n",
            "Epoch 40/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9691 - accuracy: 0.0528 - categorical_accuracy: 0.0528 - val_loss: 0.9682 - val_accuracy: 0.1504 - val_categorical_accuracy: 0.1504\n",
            "Epoch 41/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9691 - accuracy: 0.0679 - categorical_accuracy: 0.0679 - val_loss: 0.9682 - val_accuracy: 0.1521 - val_categorical_accuracy: 0.1521\n",
            "Epoch 42/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9694 - accuracy: 0.0637 - categorical_accuracy: 0.0637 - val_loss: 0.9681 - val_accuracy: 0.1726 - val_categorical_accuracy: 0.1726\n",
            "Epoch 43/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9689 - accuracy: 0.0678 - categorical_accuracy: 0.0678 - val_loss: 0.9680 - val_accuracy: 0.1744 - val_categorical_accuracy: 0.1744\n",
            "Epoch 44/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9690 - accuracy: 0.0632 - categorical_accuracy: 0.0632 - val_loss: 0.9680 - val_accuracy: 0.1786 - val_categorical_accuracy: 0.1786\n",
            "Epoch 45/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9691 - accuracy: 0.0787 - categorical_accuracy: 0.0787 - val_loss: 0.9679 - val_accuracy: 0.1838 - val_categorical_accuracy: 0.1838\n",
            "Epoch 46/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9689 - accuracy: 0.0673 - categorical_accuracy: 0.0673 - val_loss: 0.9679 - val_accuracy: 0.1915 - val_categorical_accuracy: 0.1915\n",
            "Epoch 47/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9691 - accuracy: 0.0964 - categorical_accuracy: 0.0964 - val_loss: 0.9678 - val_accuracy: 0.1983 - val_categorical_accuracy: 0.1983\n",
            "Epoch 48/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9686 - accuracy: 0.0977 - categorical_accuracy: 0.0977 - val_loss: 0.9678 - val_accuracy: 0.2017 - val_categorical_accuracy: 0.2017\n",
            "Epoch 49/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9679 - accuracy: 0.1099 - categorical_accuracy: 0.1099 - val_loss: 0.9677 - val_accuracy: 0.2265 - val_categorical_accuracy: 0.2265\n",
            "Epoch 50/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9688 - accuracy: 0.1137 - categorical_accuracy: 0.1137 - val_loss: 0.9676 - val_accuracy: 0.2359 - val_categorical_accuracy: 0.2359\n",
            "Epoch 51/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9687 - accuracy: 0.1218 - categorical_accuracy: 0.1218 - val_loss: 0.9676 - val_accuracy: 0.2675 - val_categorical_accuracy: 0.2675\n",
            "Epoch 52/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9690 - accuracy: 0.1135 - categorical_accuracy: 0.1135 - val_loss: 0.9675 - val_accuracy: 0.2932 - val_categorical_accuracy: 0.2932\n",
            "Epoch 53/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9687 - accuracy: 0.1212 - categorical_accuracy: 0.1212 - val_loss: 0.9675 - val_accuracy: 0.3393 - val_categorical_accuracy: 0.3393\n",
            "Epoch 54/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9685 - accuracy: 0.1252 - categorical_accuracy: 0.1252 - val_loss: 0.9674 - val_accuracy: 0.3444 - val_categorical_accuracy: 0.3444\n",
            "Epoch 55/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9686 - accuracy: 0.1398 - categorical_accuracy: 0.1398 - val_loss: 0.9674 - val_accuracy: 0.3504 - val_categorical_accuracy: 0.3504\n",
            "Epoch 56/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9680 - accuracy: 0.1239 - categorical_accuracy: 0.1239 - val_loss: 0.9673 - val_accuracy: 0.3547 - val_categorical_accuracy: 0.3547\n",
            "Epoch 57/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9684 - accuracy: 0.1633 - categorical_accuracy: 0.1633 - val_loss: 0.9672 - val_accuracy: 0.3778 - val_categorical_accuracy: 0.3778\n",
            "Epoch 58/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9678 - accuracy: 0.1484 - categorical_accuracy: 0.1484 - val_loss: 0.9672 - val_accuracy: 0.4274 - val_categorical_accuracy: 0.4274\n",
            "Epoch 59/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9677 - accuracy: 0.1741 - categorical_accuracy: 0.1741 - val_loss: 0.9671 - val_accuracy: 0.4556 - val_categorical_accuracy: 0.4556\n",
            "Epoch 60/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9687 - accuracy: 0.1744 - categorical_accuracy: 0.1744 - val_loss: 0.9671 - val_accuracy: 0.5043 - val_categorical_accuracy: 0.5043\n",
            "Epoch 61/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9679 - accuracy: 0.1759 - categorical_accuracy: 0.1759 - val_loss: 0.9670 - val_accuracy: 0.5103 - val_categorical_accuracy: 0.5103\n",
            "Epoch 62/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9681 - accuracy: 0.2033 - categorical_accuracy: 0.2033 - val_loss: 0.9670 - val_accuracy: 0.5222 - val_categorical_accuracy: 0.5222\n",
            "Epoch 63/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9678 - accuracy: 0.1913 - categorical_accuracy: 0.1913 - val_loss: 0.9669 - val_accuracy: 0.5239 - val_categorical_accuracy: 0.5239\n",
            "Epoch 64/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9678 - accuracy: 0.1870 - categorical_accuracy: 0.1870 - val_loss: 0.9669 - val_accuracy: 0.5462 - val_categorical_accuracy: 0.5462\n",
            "Epoch 65/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9675 - accuracy: 0.2122 - categorical_accuracy: 0.2122 - val_loss: 0.9668 - val_accuracy: 0.5462 - val_categorical_accuracy: 0.5462\n",
            "Epoch 66/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9682 - accuracy: 0.2274 - categorical_accuracy: 0.2274 - val_loss: 0.9668 - val_accuracy: 0.5504 - val_categorical_accuracy: 0.5504\n",
            "Epoch 67/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9679 - accuracy: 0.2149 - categorical_accuracy: 0.2149 - val_loss: 0.9667 - val_accuracy: 0.5538 - val_categorical_accuracy: 0.5538\n",
            "Epoch 68/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9675 - accuracy: 0.2278 - categorical_accuracy: 0.2278 - val_loss: 0.9667 - val_accuracy: 0.5684 - val_categorical_accuracy: 0.5684\n",
            "Epoch 69/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9675 - accuracy: 0.2505 - categorical_accuracy: 0.2505 - val_loss: 0.9666 - val_accuracy: 0.5795 - val_categorical_accuracy: 0.5795\n",
            "Epoch 70/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9675 - accuracy: 0.2534 - categorical_accuracy: 0.2534 - val_loss: 0.9666 - val_accuracy: 0.5829 - val_categorical_accuracy: 0.5829\n",
            "Epoch 71/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9671 - accuracy: 0.2707 - categorical_accuracy: 0.2707 - val_loss: 0.9665 - val_accuracy: 0.5838 - val_categorical_accuracy: 0.5838\n",
            "Epoch 72/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9676 - accuracy: 0.2792 - categorical_accuracy: 0.2792 - val_loss: 0.9665 - val_accuracy: 0.5838 - val_categorical_accuracy: 0.5838\n",
            "Epoch 73/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9669 - accuracy: 0.3082 - categorical_accuracy: 0.3082 - val_loss: 0.9664 - val_accuracy: 0.5838 - val_categorical_accuracy: 0.5838\n",
            "Epoch 74/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9677 - accuracy: 0.2776 - categorical_accuracy: 0.2776 - val_loss: 0.9664 - val_accuracy: 0.5855 - val_categorical_accuracy: 0.5855\n",
            "Epoch 75/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9676 - accuracy: 0.2967 - categorical_accuracy: 0.2967 - val_loss: 0.9663 - val_accuracy: 0.6009 - val_categorical_accuracy: 0.6009\n",
            "Epoch 76/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9675 - accuracy: 0.3096 - categorical_accuracy: 0.3096 - val_loss: 0.9663 - val_accuracy: 0.6017 - val_categorical_accuracy: 0.6017\n",
            "Epoch 77/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9672 - accuracy: 0.3119 - categorical_accuracy: 0.3119 - val_loss: 0.9662 - val_accuracy: 0.6017 - val_categorical_accuracy: 0.6017\n",
            "Epoch 78/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9673 - accuracy: 0.3158 - categorical_accuracy: 0.3158 - val_loss: 0.9662 - val_accuracy: 0.6034 - val_categorical_accuracy: 0.6034\n",
            "Epoch 79/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9671 - accuracy: 0.3438 - categorical_accuracy: 0.3438 - val_loss: 0.9661 - val_accuracy: 0.6085 - val_categorical_accuracy: 0.6085\n",
            "Epoch 80/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9666 - accuracy: 0.3164 - categorical_accuracy: 0.3164 - val_loss: 0.9661 - val_accuracy: 0.6085 - val_categorical_accuracy: 0.6085\n",
            "Epoch 81/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9670 - accuracy: 0.3469 - categorical_accuracy: 0.3469 - val_loss: 0.9660 - val_accuracy: 0.6094 - val_categorical_accuracy: 0.6094\n",
            "Epoch 82/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9666 - accuracy: 0.3615 - categorical_accuracy: 0.3615 - val_loss: 0.9660 - val_accuracy: 0.6094 - val_categorical_accuracy: 0.6094\n",
            "Epoch 83/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9666 - accuracy: 0.3358 - categorical_accuracy: 0.3358 - val_loss: 0.9659 - val_accuracy: 0.6094 - val_categorical_accuracy: 0.6094\n",
            "Epoch 84/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9666 - accuracy: 0.3736 - categorical_accuracy: 0.3736 - val_loss: 0.9659 - val_accuracy: 0.6094 - val_categorical_accuracy: 0.6094\n",
            "Epoch 85/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9668 - accuracy: 0.3687 - categorical_accuracy: 0.3687 - val_loss: 0.9658 - val_accuracy: 0.6094 - val_categorical_accuracy: 0.6094\n",
            "Epoch 86/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9668 - accuracy: 0.3781 - categorical_accuracy: 0.3781 - val_loss: 0.9658 - val_accuracy: 0.6094 - val_categorical_accuracy: 0.6094\n",
            "Epoch 87/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9665 - accuracy: 0.3872 - categorical_accuracy: 0.3872 - val_loss: 0.9657 - val_accuracy: 0.6094 - val_categorical_accuracy: 0.6094\n",
            "Epoch 88/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9666 - accuracy: 0.3925 - categorical_accuracy: 0.3925 - val_loss: 0.9657 - val_accuracy: 0.6094 - val_categorical_accuracy: 0.6094\n",
            "Epoch 89/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9665 - accuracy: 0.4066 - categorical_accuracy: 0.4066 - val_loss: 0.9656 - val_accuracy: 0.6137 - val_categorical_accuracy: 0.6137\n",
            "Epoch 90/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9666 - accuracy: 0.4133 - categorical_accuracy: 0.4133 - val_loss: 0.9656 - val_accuracy: 0.6137 - val_categorical_accuracy: 0.6137\n",
            "Epoch 91/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9661 - accuracy: 0.3884 - categorical_accuracy: 0.3884 - val_loss: 0.9655 - val_accuracy: 0.6137 - val_categorical_accuracy: 0.6137\n",
            "Epoch 92/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9656 - accuracy: 0.4342 - categorical_accuracy: 0.4342 - val_loss: 0.9655 - val_accuracy: 0.6137 - val_categorical_accuracy: 0.6137\n",
            "Epoch 93/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9663 - accuracy: 0.4278 - categorical_accuracy: 0.4278 - val_loss: 0.9654 - val_accuracy: 0.6137 - val_categorical_accuracy: 0.6137\n",
            "Epoch 94/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9662 - accuracy: 0.4232 - categorical_accuracy: 0.4232 - val_loss: 0.9654 - val_accuracy: 0.6137 - val_categorical_accuracy: 0.6137\n",
            "Epoch 95/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9657 - accuracy: 0.4308 - categorical_accuracy: 0.4308 - val_loss: 0.9653 - val_accuracy: 0.6137 - val_categorical_accuracy: 0.6137\n",
            "Epoch 96/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9659 - accuracy: 0.4384 - categorical_accuracy: 0.4384 - val_loss: 0.9653 - val_accuracy: 0.6137 - val_categorical_accuracy: 0.6137\n",
            "Epoch 97/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9663 - accuracy: 0.4506 - categorical_accuracy: 0.4506 - val_loss: 0.9652 - val_accuracy: 0.6137 - val_categorical_accuracy: 0.6137\n",
            "Epoch 98/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9658 - accuracy: 0.4521 - categorical_accuracy: 0.4521 - val_loss: 0.9652 - val_accuracy: 0.6137 - val_categorical_accuracy: 0.6137\n",
            "Epoch 99/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9661 - accuracy: 0.4775 - categorical_accuracy: 0.4775 - val_loss: 0.9651 - val_accuracy: 0.6137 - val_categorical_accuracy: 0.6137\n",
            "Epoch 100/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9659 - accuracy: 0.4723 - categorical_accuracy: 0.4723 - val_loss: 0.9651 - val_accuracy: 0.6137 - val_categorical_accuracy: 0.6137\n",
            "Epoch 101/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9658 - accuracy: 0.4645 - categorical_accuracy: 0.4645 - val_loss: 0.9650 - val_accuracy: 0.6154 - val_categorical_accuracy: 0.6154\n",
            "Epoch 102/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9657 - accuracy: 0.4764 - categorical_accuracy: 0.4764 - val_loss: 0.9650 - val_accuracy: 0.6154 - val_categorical_accuracy: 0.6154\n",
            "Epoch 103/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9658 - accuracy: 0.4829 - categorical_accuracy: 0.4829 - val_loss: 0.9649 - val_accuracy: 0.6171 - val_categorical_accuracy: 0.6171\n",
            "Epoch 104/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9652 - accuracy: 0.4892 - categorical_accuracy: 0.4892 - val_loss: 0.9649 - val_accuracy: 0.6171 - val_categorical_accuracy: 0.6171\n",
            "Epoch 105/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9656 - accuracy: 0.4806 - categorical_accuracy: 0.4806 - val_loss: 0.9648 - val_accuracy: 0.6171 - val_categorical_accuracy: 0.6171\n",
            "Epoch 106/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9651 - accuracy: 0.4939 - categorical_accuracy: 0.4939 - val_loss: 0.9648 - val_accuracy: 0.6197 - val_categorical_accuracy: 0.6197\n",
            "Epoch 107/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9655 - accuracy: 0.5050 - categorical_accuracy: 0.5050 - val_loss: 0.9647 - val_accuracy: 0.6197 - val_categorical_accuracy: 0.6197\n",
            "Epoch 108/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9657 - accuracy: 0.5060 - categorical_accuracy: 0.5060 - val_loss: 0.9647 - val_accuracy: 0.6274 - val_categorical_accuracy: 0.6274\n",
            "Epoch 109/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9658 - accuracy: 0.4883 - categorical_accuracy: 0.4883 - val_loss: 0.9646 - val_accuracy: 0.6274 - val_categorical_accuracy: 0.6274\n",
            "Epoch 110/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9652 - accuracy: 0.4918 - categorical_accuracy: 0.4918 - val_loss: 0.9646 - val_accuracy: 0.6274 - val_categorical_accuracy: 0.6274\n",
            "Epoch 111/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9648 - accuracy: 0.5073 - categorical_accuracy: 0.5073 - val_loss: 0.9645 - val_accuracy: 0.6274 - val_categorical_accuracy: 0.6274\n",
            "Epoch 112/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9649 - accuracy: 0.5262 - categorical_accuracy: 0.5262 - val_loss: 0.9645 - val_accuracy: 0.6274 - val_categorical_accuracy: 0.6274\n",
            "Epoch 113/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9647 - accuracy: 0.5274 - categorical_accuracy: 0.5274 - val_loss: 0.9644 - val_accuracy: 0.6274 - val_categorical_accuracy: 0.6274\n",
            "Epoch 114/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9651 - accuracy: 0.5088 - categorical_accuracy: 0.5088 - val_loss: 0.9644 - val_accuracy: 0.6274 - val_categorical_accuracy: 0.6274\n",
            "Epoch 115/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9650 - accuracy: 0.5255 - categorical_accuracy: 0.5255 - val_loss: 0.9643 - val_accuracy: 0.6274 - val_categorical_accuracy: 0.6274\n",
            "Epoch 116/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9645 - accuracy: 0.5302 - categorical_accuracy: 0.5302 - val_loss: 0.9643 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 117/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9646 - accuracy: 0.5207 - categorical_accuracy: 0.5207 - val_loss: 0.9642 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 118/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9653 - accuracy: 0.5326 - categorical_accuracy: 0.5326 - val_loss: 0.9642 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 119/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9646 - accuracy: 0.5346 - categorical_accuracy: 0.5346 - val_loss: 0.9641 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 120/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9646 - accuracy: 0.5356 - categorical_accuracy: 0.5356 - val_loss: 0.9641 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 121/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9646 - accuracy: 0.5421 - categorical_accuracy: 0.5421 - val_loss: 0.9640 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 122/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9646 - accuracy: 0.5360 - categorical_accuracy: 0.5360 - val_loss: 0.9640 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 123/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9647 - accuracy: 0.5446 - categorical_accuracy: 0.5446 - val_loss: 0.9639 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 124/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9645 - accuracy: 0.5488 - categorical_accuracy: 0.5488 - val_loss: 0.9638 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 125/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9646 - accuracy: 0.5539 - categorical_accuracy: 0.5539 - val_loss: 0.9638 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 126/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9646 - accuracy: 0.5561 - categorical_accuracy: 0.5561 - val_loss: 0.9637 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 127/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9640 - accuracy: 0.5617 - categorical_accuracy: 0.5617 - val_loss: 0.9637 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 128/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9640 - accuracy: 0.5588 - categorical_accuracy: 0.5588 - val_loss: 0.9636 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 129/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9640 - accuracy: 0.5466 - categorical_accuracy: 0.5466 - val_loss: 0.9636 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 130/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9637 - accuracy: 0.5633 - categorical_accuracy: 0.5633 - val_loss: 0.9635 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 131/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9637 - accuracy: 0.5639 - categorical_accuracy: 0.5639 - val_loss: 0.9634 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 132/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9637 - accuracy: 0.5759 - categorical_accuracy: 0.5759 - val_loss: 0.9634 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 133/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9635 - accuracy: 0.5589 - categorical_accuracy: 0.5589 - val_loss: 0.9633 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 134/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9636 - accuracy: 0.5671 - categorical_accuracy: 0.5671 - val_loss: 0.9632 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 135/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9636 - accuracy: 0.5544 - categorical_accuracy: 0.5544 - val_loss: 0.9632 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 136/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9637 - accuracy: 0.5620 - categorical_accuracy: 0.5620 - val_loss: 0.9631 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 137/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9637 - accuracy: 0.5518 - categorical_accuracy: 0.5518 - val_loss: 0.9631 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256\n",
            "Epoch 138/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9637 - accuracy: 0.5819 - categorical_accuracy: 0.5819 - val_loss: 0.9630 - val_accuracy: 0.6248 - val_categorical_accuracy: 0.6248\n",
            "Epoch 139/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9641 - accuracy: 0.5524 - categorical_accuracy: 0.5524 - val_loss: 0.9629 - val_accuracy: 0.6248 - val_categorical_accuracy: 0.6248\n",
            "Epoch 140/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9642 - accuracy: 0.5562 - categorical_accuracy: 0.5562 - val_loss: 0.9629 - val_accuracy: 0.6248 - val_categorical_accuracy: 0.6248\n",
            "Epoch 141/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9633 - accuracy: 0.5671 - categorical_accuracy: 0.5671 - val_loss: 0.9628 - val_accuracy: 0.6248 - val_categorical_accuracy: 0.6248\n",
            "Epoch 142/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9632 - accuracy: 0.5696 - categorical_accuracy: 0.5696 - val_loss: 0.9627 - val_accuracy: 0.6248 - val_categorical_accuracy: 0.6248\n",
            "Epoch 143/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9632 - accuracy: 0.5624 - categorical_accuracy: 0.5624 - val_loss: 0.9626 - val_accuracy: 0.6248 - val_categorical_accuracy: 0.6248\n",
            "Epoch 144/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9627 - accuracy: 0.5860 - categorical_accuracy: 0.5860 - val_loss: 0.9626 - val_accuracy: 0.6248 - val_categorical_accuracy: 0.6248\n",
            "Epoch 145/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9636 - accuracy: 0.5690 - categorical_accuracy: 0.5690 - val_loss: 0.9625 - val_accuracy: 0.6248 - val_categorical_accuracy: 0.6248\n",
            "Epoch 146/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9629 - accuracy: 0.5782 - categorical_accuracy: 0.5782 - val_loss: 0.9624 - val_accuracy: 0.6248 - val_categorical_accuracy: 0.6248\n",
            "Epoch 147/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9629 - accuracy: 0.5752 - categorical_accuracy: 0.5752 - val_loss: 0.9623 - val_accuracy: 0.6248 - val_categorical_accuracy: 0.6248\n",
            "Epoch 148/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9633 - accuracy: 0.5606 - categorical_accuracy: 0.5606 - val_loss: 0.9623 - val_accuracy: 0.6188 - val_categorical_accuracy: 0.6188\n",
            "Epoch 149/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9626 - accuracy: 0.5738 - categorical_accuracy: 0.5738 - val_loss: 0.9622 - val_accuracy: 0.6171 - val_categorical_accuracy: 0.6171\n",
            "Epoch 150/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9628 - accuracy: 0.5783 - categorical_accuracy: 0.5783 - val_loss: 0.9621 - val_accuracy: 0.6171 - val_categorical_accuracy: 0.6171\n",
            "Epoch 151/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9625 - accuracy: 0.5959 - categorical_accuracy: 0.5959 - val_loss: 0.9620 - val_accuracy: 0.6171 - val_categorical_accuracy: 0.6171\n",
            "Epoch 152/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9629 - accuracy: 0.5810 - categorical_accuracy: 0.5810 - val_loss: 0.9620 - val_accuracy: 0.6171 - val_categorical_accuracy: 0.6171\n",
            "Epoch 153/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9627 - accuracy: 0.5855 - categorical_accuracy: 0.5855 - val_loss: 0.9619 - val_accuracy: 0.6171 - val_categorical_accuracy: 0.6171\n",
            "Epoch 154/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9621 - accuracy: 0.5922 - categorical_accuracy: 0.5922 - val_loss: 0.9618 - val_accuracy: 0.6171 - val_categorical_accuracy: 0.6171\n",
            "Epoch 155/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9622 - accuracy: 0.5905 - categorical_accuracy: 0.5905 - val_loss: 0.9617 - val_accuracy: 0.6171 - val_categorical_accuracy: 0.6171\n",
            "Epoch 156/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9620 - accuracy: 0.5890 - categorical_accuracy: 0.5890 - val_loss: 0.9616 - val_accuracy: 0.6171 - val_categorical_accuracy: 0.6171\n",
            "Epoch 157/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9623 - accuracy: 0.5828 - categorical_accuracy: 0.5828 - val_loss: 0.9615 - val_accuracy: 0.6171 - val_categorical_accuracy: 0.6171\n",
            "Epoch 158/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9620 - accuracy: 0.5920 - categorical_accuracy: 0.5920 - val_loss: 0.9614 - val_accuracy: 0.5957 - val_categorical_accuracy: 0.5957\n",
            "Epoch 159/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9620 - accuracy: 0.5803 - categorical_accuracy: 0.5803 - val_loss: 0.9614 - val_accuracy: 0.5957 - val_categorical_accuracy: 0.5957\n",
            "Epoch 160/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9616 - accuracy: 0.5835 - categorical_accuracy: 0.5835 - val_loss: 0.9613 - val_accuracy: 0.5957 - val_categorical_accuracy: 0.5957\n",
            "Epoch 161/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9622 - accuracy: 0.5813 - categorical_accuracy: 0.5813 - val_loss: 0.9612 - val_accuracy: 0.5957 - val_categorical_accuracy: 0.5957\n",
            "Epoch 162/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9620 - accuracy: 0.5865 - categorical_accuracy: 0.5865 - val_loss: 0.9611 - val_accuracy: 0.5957 - val_categorical_accuracy: 0.5957\n",
            "Epoch 163/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9614 - accuracy: 0.6032 - categorical_accuracy: 0.6032 - val_loss: 0.9610 - val_accuracy: 0.5957 - val_categorical_accuracy: 0.5957\n",
            "Epoch 164/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9610 - accuracy: 0.6027 - categorical_accuracy: 0.6027 - val_loss: 0.9609 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 165/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9610 - accuracy: 0.5778 - categorical_accuracy: 0.5778 - val_loss: 0.9608 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 166/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9617 - accuracy: 0.5868 - categorical_accuracy: 0.5868 - val_loss: 0.9607 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 167/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9608 - accuracy: 0.5884 - categorical_accuracy: 0.5884 - val_loss: 0.9606 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 168/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9600 - accuracy: 0.5895 - categorical_accuracy: 0.5895 - val_loss: 0.9605 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 169/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9605 - accuracy: 0.6020 - categorical_accuracy: 0.6020 - val_loss: 0.9603 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 170/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9605 - accuracy: 0.5988 - categorical_accuracy: 0.5988 - val_loss: 0.9602 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 171/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9609 - accuracy: 0.5821 - categorical_accuracy: 0.5821 - val_loss: 0.9601 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 172/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9604 - accuracy: 0.5841 - categorical_accuracy: 0.5841 - val_loss: 0.9600 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 173/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9606 - accuracy: 0.5915 - categorical_accuracy: 0.5915 - val_loss: 0.9599 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 174/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9603 - accuracy: 0.5845 - categorical_accuracy: 0.5845 - val_loss: 0.9598 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 175/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9600 - accuracy: 0.5731 - categorical_accuracy: 0.5731 - val_loss: 0.9596 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 176/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9601 - accuracy: 0.5965 - categorical_accuracy: 0.5965 - val_loss: 0.9595 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 177/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9600 - accuracy: 0.5984 - categorical_accuracy: 0.5984 - val_loss: 0.9594 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 178/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9599 - accuracy: 0.5876 - categorical_accuracy: 0.5876 - val_loss: 0.9592 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 179/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9599 - accuracy: 0.6009 - categorical_accuracy: 0.6009 - val_loss: 0.9591 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 180/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9597 - accuracy: 0.5841 - categorical_accuracy: 0.5841 - val_loss: 0.9590 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 181/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9587 - accuracy: 0.5807 - categorical_accuracy: 0.5807 - val_loss: 0.9588 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 182/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9599 - accuracy: 0.5826 - categorical_accuracy: 0.5826 - val_loss: 0.9587 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 183/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9587 - accuracy: 0.6031 - categorical_accuracy: 0.6031 - val_loss: 0.9585 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 184/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9583 - accuracy: 0.5982 - categorical_accuracy: 0.5982 - val_loss: 0.9584 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 185/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9590 - accuracy: 0.5990 - categorical_accuracy: 0.5990 - val_loss: 0.9582 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 186/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9590 - accuracy: 0.5925 - categorical_accuracy: 0.5925 - val_loss: 0.9580 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 187/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9584 - accuracy: 0.5890 - categorical_accuracy: 0.5890 - val_loss: 0.9579 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 188/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9583 - accuracy: 0.5922 - categorical_accuracy: 0.5922 - val_loss: 0.9577 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 189/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9581 - accuracy: 0.6080 - categorical_accuracy: 0.6080 - val_loss: 0.9575 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 190/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9582 - accuracy: 0.5914 - categorical_accuracy: 0.5914 - val_loss: 0.9573 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 191/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9577 - accuracy: 0.5926 - categorical_accuracy: 0.5926 - val_loss: 0.9571 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 192/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9580 - accuracy: 0.5986 - categorical_accuracy: 0.5986 - val_loss: 0.9569 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 193/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9567 - accuracy: 0.6079 - categorical_accuracy: 0.6079 - val_loss: 0.9567 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 194/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9572 - accuracy: 0.5964 - categorical_accuracy: 0.5964 - val_loss: 0.9565 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 195/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9567 - accuracy: 0.6031 - categorical_accuracy: 0.6031 - val_loss: 0.9563 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 196/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9570 - accuracy: 0.5888 - categorical_accuracy: 0.5888 - val_loss: 0.9560 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 197/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9569 - accuracy: 0.5952 - categorical_accuracy: 0.5952 - val_loss: 0.9558 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 198/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9563 - accuracy: 0.5874 - categorical_accuracy: 0.5874 - val_loss: 0.9555 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 199/200\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.9563 - accuracy: 0.5878 - categorical_accuracy: 0.5878 - val_loss: 0.9553 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "Epoch 200/200\n",
            "351/351 [==============================] - 2s 5ms/step - loss: 0.9568 - accuracy: 0.5898 - categorical_accuracy: 0.5898 - val_loss: 0.9550 - val_accuracy: 0.5932 - val_categorical_accuracy: 0.5932\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9550 - accuracy: 0.5932 - categorical_accuracy: 0.5932\n",
            "1148\n",
            "Generation-10 Chromosome-8:\n",
            "Middle layers: 2 | Activation: relu | Optimization: Adadelta | Loss: categorical_hinge | LR: 0.0001 | Dropout: 0.3 |\n",
            "\tScore 0.53  | Accuracy: 0.59\n",
            "Generation-10 Chromosome-9 scored 0.68  (Chromosome already known)\n",
            "Epoch 1/200\n",
            "351/351 [==============================] - 6s 12ms/step - loss: 190.9104 - accuracy: 0.4982 - categorical_accuracy: 0.4982 - val_loss: 610.7004 - val_accuracy: 0.4701 - val_categorical_accuracy: 0.4701\n",
            "Epoch 2/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 688.1205 - accuracy: 0.4965 - categorical_accuracy: 0.4965 - val_loss: 1085.6278 - val_accuracy: 0.3735 - val_categorical_accuracy: 0.3735\n",
            "Epoch 3/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 1183.4737 - accuracy: 0.4969 - categorical_accuracy: 0.4969 - val_loss: 1556.2058 - val_accuracy: 0.5051 - val_categorical_accuracy: 0.5051\n",
            "Epoch 4/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 1627.1995 - accuracy: 0.5034 - categorical_accuracy: 0.5034 - val_loss: 2051.7629 - val_accuracy: 0.3248 - val_categorical_accuracy: 0.3248\n",
            "Epoch 5/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 2148.8848 - accuracy: 0.4961 - categorical_accuracy: 0.4961 - val_loss: 2524.3621 - val_accuracy: 0.6641 - val_categorical_accuracy: 0.6641\n",
            "Epoch 6/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 2593.1414 - accuracy: 0.5173 - categorical_accuracy: 0.5173 - val_loss: 3007.9585 - val_accuracy: 0.4214 - val_categorical_accuracy: 0.4214\n",
            "Epoch 7/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 3020.7115 - accuracy: 0.5113 - categorical_accuracy: 0.5113 - val_loss: 3509.3850 - val_accuracy: 0.4231 - val_categorical_accuracy: 0.4231\n",
            "Epoch 8/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 3526.2778 - accuracy: 0.5138 - categorical_accuracy: 0.5138 - val_loss: 4010.4084 - val_accuracy: 0.5000 - val_categorical_accuracy: 0.5000\n",
            "Epoch 9/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 4013.6174 - accuracy: 0.5139 - categorical_accuracy: 0.5139 - val_loss: 4497.5977 - val_accuracy: 0.7462 - val_categorical_accuracy: 0.7462\n",
            "Epoch 10/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 4432.2688 - accuracy: 0.5010 - categorical_accuracy: 0.5010 - val_loss: 4956.4253 - val_accuracy: 0.4530 - val_categorical_accuracy: 0.4530\n",
            "Epoch 11/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 5006.5030 - accuracy: 0.5151 - categorical_accuracy: 0.5151 - val_loss: 5471.2773 - val_accuracy: 0.4436 - val_categorical_accuracy: 0.4436\n",
            "Epoch 12/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 5523.0205 - accuracy: 0.5042 - categorical_accuracy: 0.5042 - val_loss: 5964.8804 - val_accuracy: 0.4222 - val_categorical_accuracy: 0.4222\n",
            "Epoch 13/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 6062.4464 - accuracy: 0.5047 - categorical_accuracy: 0.5047 - val_loss: 6445.3545 - val_accuracy: 0.7068 - val_categorical_accuracy: 0.7068\n",
            "Epoch 14/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 6334.5685 - accuracy: 0.4997 - categorical_accuracy: 0.4997 - val_loss: 6933.3169 - val_accuracy: 0.6504 - val_categorical_accuracy: 0.6504\n",
            "Epoch 15/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 7057.5210 - accuracy: 0.4983 - categorical_accuracy: 0.4983 - val_loss: 7421.9648 - val_accuracy: 0.7051 - val_categorical_accuracy: 0.7051\n",
            "Epoch 16/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 7393.3275 - accuracy: 0.5070 - categorical_accuracy: 0.5070 - val_loss: 7908.1299 - val_accuracy: 0.6521 - val_categorical_accuracy: 0.6521\n",
            "Epoch 17/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 7626.5418 - accuracy: 0.5300 - categorical_accuracy: 0.5300 - val_loss: 8378.8096 - val_accuracy: 0.4513 - val_categorical_accuracy: 0.4513\n",
            "Epoch 18/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 8202.6146 - accuracy: 0.5019 - categorical_accuracy: 0.5019 - val_loss: 8890.2549 - val_accuracy: 0.6846 - val_categorical_accuracy: 0.6846\n",
            "Epoch 19/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 8618.2805 - accuracy: 0.5016 - categorical_accuracy: 0.5016 - val_loss: 9394.6797 - val_accuracy: 0.4726 - val_categorical_accuracy: 0.4726\n",
            "Epoch 20/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 9303.0003 - accuracy: 0.5183 - categorical_accuracy: 0.5183 - val_loss: 9824.8555 - val_accuracy: 0.6487 - val_categorical_accuracy: 0.6487\n",
            "Epoch 21/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 9746.6532 - accuracy: 0.5068 - categorical_accuracy: 0.5068 - val_loss: 10332.4209 - val_accuracy: 0.4991 - val_categorical_accuracy: 0.4991\n",
            "Epoch 22/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 10078.0041 - accuracy: 0.5019 - categorical_accuracy: 0.5019 - val_loss: 10813.1777 - val_accuracy: 0.4231 - val_categorical_accuracy: 0.4231\n",
            "Epoch 23/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 10803.1776 - accuracy: 0.5077 - categorical_accuracy: 0.5077 - val_loss: 11322.4209 - val_accuracy: 0.7060 - val_categorical_accuracy: 0.7060\n",
            "Epoch 24/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 10752.4833 - accuracy: 0.5126 - categorical_accuracy: 0.5126 - val_loss: 11752.6494 - val_accuracy: 0.4265 - val_categorical_accuracy: 0.4265\n",
            "Epoch 25/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 11574.9289 - accuracy: 0.5044 - categorical_accuracy: 0.5044 - val_loss: 12263.5117 - val_accuracy: 0.4231 - val_categorical_accuracy: 0.4231\n",
            "Epoch 26/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 11837.8884 - accuracy: 0.4939 - categorical_accuracy: 0.4939 - val_loss: 12742.3301 - val_accuracy: 0.4231 - val_categorical_accuracy: 0.4231\n",
            "Epoch 27/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 12719.6207 - accuracy: 0.5119 - categorical_accuracy: 0.5119 - val_loss: 13230.8633 - val_accuracy: 0.6778 - val_categorical_accuracy: 0.6778\n",
            "Epoch 28/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 13185.0740 - accuracy: 0.5197 - categorical_accuracy: 0.5197 - val_loss: 13711.3486 - val_accuracy: 0.4436 - val_categorical_accuracy: 0.4436\n",
            "Epoch 29/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 13617.8375 - accuracy: 0.5157 - categorical_accuracy: 0.5157 - val_loss: 14248.1777 - val_accuracy: 0.4513 - val_categorical_accuracy: 0.4513\n",
            "Epoch 30/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 14122.1235 - accuracy: 0.5187 - categorical_accuracy: 0.5187 - val_loss: 14729.0068 - val_accuracy: 0.4444 - val_categorical_accuracy: 0.4444\n",
            "Epoch 31/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 14885.1617 - accuracy: 0.5028 - categorical_accuracy: 0.5028 - val_loss: 15218.3076 - val_accuracy: 0.4513 - val_categorical_accuracy: 0.4513\n",
            "Epoch 32/200\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 14835.9895 - accuracy: 0.5157 - categorical_accuracy: 0.5157 - val_loss: 15708.9160 - val_accuracy: 0.5214 - val_categorical_accuracy: 0.5214\n",
            "Epoch 33/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 15396.4897 - accuracy: 0.4841 - categorical_accuracy: 0.4841 - val_loss: 16195.2549 - val_accuracy: 0.4795 - val_categorical_accuracy: 0.4795\n",
            "Epoch 34/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 15908.5631 - accuracy: 0.5065 - categorical_accuracy: 0.5065 - val_loss: 16671.1035 - val_accuracy: 0.7043 - val_categorical_accuracy: 0.7043\n",
            "Epoch 35/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 16360.0225 - accuracy: 0.5035 - categorical_accuracy: 0.5035 - val_loss: 17183.8535 - val_accuracy: 0.7248 - val_categorical_accuracy: 0.7248\n",
            "Epoch 36/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 16555.0777 - accuracy: 0.5027 - categorical_accuracy: 0.5027 - val_loss: 17677.4043 - val_accuracy: 0.5197 - val_categorical_accuracy: 0.5197\n",
            "Epoch 37/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 17080.4711 - accuracy: 0.5158 - categorical_accuracy: 0.5158 - val_loss: 18158.6582 - val_accuracy: 0.4487 - val_categorical_accuracy: 0.4487\n",
            "Epoch 38/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 17902.8859 - accuracy: 0.5116 - categorical_accuracy: 0.5116 - val_loss: 18660.2188 - val_accuracy: 0.6786 - val_categorical_accuracy: 0.6786\n",
            "Epoch 39/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 17880.6613 - accuracy: 0.5037 - categorical_accuracy: 0.5037 - val_loss: 19176.0625 - val_accuracy: 0.4513 - val_categorical_accuracy: 0.4513\n",
            "Epoch 40/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 18738.6818 - accuracy: 0.5184 - categorical_accuracy: 0.5184 - val_loss: 19667.8965 - val_accuracy: 0.4795 - val_categorical_accuracy: 0.4795\n",
            "Epoch 41/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 19216.9129 - accuracy: 0.5092 - categorical_accuracy: 0.5092 - val_loss: 20187.0195 - val_accuracy: 0.6983 - val_categorical_accuracy: 0.6983\n",
            "Epoch 42/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 20279.1697 - accuracy: 0.5135 - categorical_accuracy: 0.5135 - val_loss: 20646.7246 - val_accuracy: 0.4513 - val_categorical_accuracy: 0.4513\n",
            "Epoch 43/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 20498.8614 - accuracy: 0.5156 - categorical_accuracy: 0.5156 - val_loss: 21159.3125 - val_accuracy: 0.4479 - val_categorical_accuracy: 0.4479\n",
            "Epoch 44/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 20964.7312 - accuracy: 0.4946 - categorical_accuracy: 0.4946 - val_loss: 21640.1035 - val_accuracy: 0.6564 - val_categorical_accuracy: 0.6564\n",
            "Epoch 45/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 21313.1472 - accuracy: 0.5133 - categorical_accuracy: 0.5133 - val_loss: 22139.7363 - val_accuracy: 0.4231 - val_categorical_accuracy: 0.4231\n",
            "Epoch 46/200\n",
            "351/351 [==============================] - 4s 10ms/step - loss: 21361.1686 - accuracy: 0.4869 - categorical_accuracy: 0.4869 - val_loss: 22626.7949 - val_accuracy: 0.4795 - val_categorical_accuracy: 0.4795\n",
            "Epoch 47/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 21927.3094 - accuracy: 0.5082 - categorical_accuracy: 0.5082 - val_loss: 23127.4883 - val_accuracy: 0.4197 - val_categorical_accuracy: 0.4197\n",
            "Epoch 48/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 22186.0373 - accuracy: 0.4948 - categorical_accuracy: 0.4948 - val_loss: 23596.2832 - val_accuracy: 0.6564 - val_categorical_accuracy: 0.6564\n",
            "Epoch 49/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 22651.8850 - accuracy: 0.4990 - categorical_accuracy: 0.4990 - val_loss: 24095.8457 - val_accuracy: 0.4795 - val_categorical_accuracy: 0.4795\n",
            "Epoch 50/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 23470.2004 - accuracy: 0.4966 - categorical_accuracy: 0.4966 - val_loss: 24589.5000 - val_accuracy: 0.4547 - val_categorical_accuracy: 0.4547\n",
            "Epoch 51/200\n",
            "351/351 [==============================] - 4s 11ms/step - loss: 23891.7141 - accuracy: 0.5028 - categorical_accuracy: 0.5028 - val_loss: 25059.6504 - val_accuracy: 0.4547 - val_categorical_accuracy: 0.4547\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 25059.6230 - accuracy: 0.4547 - categorical_accuracy: 0.4547\n",
            "1102\n",
            "Generation-10 Chromosome-10:\n",
            "Middle layers: 2 | Activation: softsign | Optimization: Adam | Loss: categorical_crossentropy | LR: 0.001 | Dropout: 0.15 |\n",
            "\tScore 0.40  | Accuracy: 0.45\n",
            "[0.6601251418948173, 0.6601251418948173, 0.6814194995999336, 0.6814194995999336, 0.6814194995999336, 0.6814194995999336, 0.7118400106072426, 0.7118400106072426, 0.7118400106072426, 0.7118400106072426] Best accuracies of each generation\n",
            "[array([2.e+00, 5.e+00, 1.e+00, 0.e+00, 1.e-04, 3.e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01]), array([2.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 1.0e-03, 1.5e-01])] Best of each generation\n",
            "[0.7118400106072426, 0.7118400106072426, 0.7072769339561462, 0.6821799858570099, 0.6814194995999336, 0.7118400106072426, 0.7118400106072426, 0.5250673718929291, 0.6814194995999336, 0.4045928229153156] Last Fitness Values\n",
            "The best hyperparameters obtained are:\n",
            "Middle layers: 2 | Activation: selu | Optimization: SGD | Loss: categorical_hinge | LR: 0.001 | Dropout: 0.15 |\n",
            "with a score of 0.7118400106072426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2w5ckcO6WeQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "2735eb0a-953f-43b7-8505-e1224dade8f3"
      },
      "source": [
        "generations=[1,2,3,4,5,6,7,8,9,10]\n",
        "plt.plot(generations,performances,color='magenta')\n",
        "plt.xlabel('Generations')\n",
        "plt.xticks([1,2,3,4,5,6,7,8,9,10])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy improvement through generations')\n",
        "plt.show()"
      ],
      "id": "E2w5ckcO6WeQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km5VW7jq6WeR"
      },
      "source": [
        ""
      ],
      "id": "km5VW7jq6WeR",
      "execution_count": null,
      "outputs": []
    }
  ]
}